{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# Entity and Relationship Extraction for Threat Intelligence\n",
    "\n",
    "## Overview\n",
    "This notebook implements entity and relationship extraction from threat intelligence text using LLM-based approach.\n",
    "\n",
    "### Task Description\n",
    "- **Input**: Threat intelligence text content\n",
    "- **Output**: Named entities and relationships in structured format\n",
    "- **Entity Types**: malware, threat type, attacker, vulnerability, tool, etc.\n",
    "- **Relationship Types**: use, target, exploit, etc.\n",
    "\n",
    "### Example\n",
    "**Input**: A hitherto unknown attack group has been observed targeting a materials research organization in Asia. The group, which Symantec calls Clasiopa, is characterized by a distinct toolset, which includes one piece of custom malware (Backdoor.Atharvan).\n",
    "\n",
    "**Output**: \n",
    "- Named Entities: (Clasiopa, attacker), (custom malware, malware), (Backdoor.Atharvan, malware)\n",
    "- Relationships: (Clasiopa, use, custom malware), (custom malware, name, Backdoor.Atharvan)\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-31T09:33:17.355172Z",
     "start_time": "2025-07-31T09:33:17.332954Z"
    }
   },
   "source": [
    "import json\n",
    "import os\n",
    "import re\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple, Any\n",
    "from collections import defaultdict\n",
    "import datetime\n",
    "\n",
    "# Load environment and model setup\n",
    "from dotenv import load_dotenv\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "print(\"ğŸ”§ Setting up Entity & Relationship Extraction Pipeline\")\n",
    "print(\"=\" * 60)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”§ Setting up Entity & Relationship Extraction Pipeline\n",
      "============================================================\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-31T09:33:17.422741Z",
     "start_time": "2025-07-31T09:33:17.374315Z"
    }
   },
   "source": [
    "def load_data(input_file: str) -> list:\n",
    "    \"\"\"\n",
    "    Load threat intelligence data from JSON file.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(input_file, 'r', encoding='utf-8') as f:\n",
    "            data = json.load(f)\n",
    "        print(f\"âœ… Loaded {len(data)} records from {input_file}\")\n",
    "        return data\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error loading {input_file}: {e}\")\n",
    "        return []\n",
    "\n",
    "# Load threat intelligence data\n",
    "data_path = '../data/processed/merged_threat_intelligence.json'\n",
    "data = load_data(data_path)\n",
    "\n",
    "if data:\n",
    "    print(f\"ğŸ“Š Sample data structure:\")\n",
    "    print(f\"   Keys: {list(data[0].keys())}\")\n",
    "    print(f\"   Title: {data[0]['title'][:100]}...\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Loaded 427 records from ../data/processed/merged_threat_intelligence.json\n",
      "ğŸ“Š Sample data structure:\n",
      "   Keys: ['title', 'content', 'link']\n",
      "   Title: FortiGuard Labs Threat Research...\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-31T09:33:18.395161Z",
     "start_time": "2025-07-31T09:33:17.432448Z"
    }
   },
   "source": [
    "# Device setup\n",
    "device = (\n",
    "    \"cuda\" if torch.cuda.is_available()\n",
    "    else \"mps\" if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "\n",
    "print(f\"ğŸ–¥ï¸  Using device: {device.upper()}\")\n",
    "print(f\"ğŸ”§ PyTorch version: {torch.__version__}\")\n",
    "\n",
    "# Memory cleanup\n",
    "if device == \"cuda\":\n",
    "    torch.cuda.empty_cache()\n",
    "elif device == \"mps\":\n",
    "    import gc\n",
    "    gc.collect()\n",
    "    if hasattr(torch.mps, 'empty_cache'):\n",
    "        torch.mps.empty_cache()\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ–¥ï¸  Using device: MPS\n",
      "ğŸ”§ PyTorch version: 2.7.1\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-31T09:33:33.457042Z",
     "start_time": "2025-07-31T09:33:18.405842Z"
    }
   },
   "source": [
    "def setup_model_for_extraction():\n",
    "    \"\"\"\n",
    "    Setup model specifically for entity and relationship extraction.\n",
    "    \"\"\"\n",
    "    HF_TOKEN = os.getenv('HF_TOKEN')\n",
    "    MODEL_NAME = os.getenv('DEFAULT_MODEL', 'Qwen/Qwen2.5-1.5B-Instruct')\n",
    "    \n",
    "    print(f\"ğŸ¤– Loading model: {MODEL_NAME}\")\n",
    "    print(f\"ğŸ”‘ Token: {'âœ… Found' if HF_TOKEN else 'âŒ Missing'}\")\n",
    "    \n",
    "    try:\n",
    "        tokenizer = AutoTokenizer.from_pretrained(\n",
    "            MODEL_NAME,\n",
    "            token=HF_TOKEN,\n",
    "            trust_remote_code=True\n",
    "        )\n",
    "        tokenizer.pad_token = tokenizer.pad_token or tokenizer.eos_token\n",
    "        \n",
    "        # Model settings optimized for entity extraction\n",
    "        torch_dtype = torch.float16 if device == \"cuda\" else torch.float32\n",
    "        device_map = \"auto\" if device == \"cuda\" else None\n",
    "        \n",
    "        model = AutoModelForCausalLM.from_pretrained(\n",
    "            MODEL_NAME,\n",
    "            token=HF_TOKEN,\n",
    "            trust_remote_code=True,\n",
    "            torch_dtype=torch_dtype,\n",
    "            device_map=device_map,\n",
    "            use_cache=False\n",
    "        )\n",
    "        \n",
    "        if device in [\"mps\", \"cuda\"]:\n",
    "            model.to(device)\n",
    "        \n",
    "        pipe = pipeline(\n",
    "            \"text-generation\",\n",
    "            model=model,\n",
    "            tokenizer=tokenizer,\n",
    "            device=0 if device != \"cpu\" else -1,\n",
    "            torch_dtype=torch_dtype,\n",
    "            model_kwargs={\"use_cache\": False}\n",
    "        )\n",
    "        \n",
    "        print(f\"âœ… Model loaded successfully on {device.upper()}\")\n",
    "        return pipe\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error loading model: {e}\")\n",
    "        return None\n",
    "\n",
    "# Load model\n",
    "extraction_model = setup_model_for_extraction()\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¤– Loading model: Qwen/Qwen2.5-1.5B-Instruct\n",
      "ğŸ”‘ Token: âœ… Found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Model loaded successfully on MPS\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-31T09:44:06.079195Z",
     "start_time": "2025-07-31T09:44:06.067822Z"
    }
   },
   "source": [
    "def create_entity_extraction_prompt(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Create prompt for entity and relationship extraction focusing on core cybersecurity entity types.\n",
    "    \"\"\"\n",
    "    # Truncate text to avoid token limits\n",
    "    text_truncated = (text[:1500] if text else \"\").replace('\\n', ' ').strip()\n",
    "    \n",
    "    prompt = f\"\"\"Instruction: Please identify the following types of entities and then extract the relationships between these extracted entities:\n",
    "\n",
    "Entity Types (focus on these only):\n",
    "- Malware: Malicious software (e.g., 'Stuxnet', 'Emotet', 'Backdoor.Atharvan')\n",
    "- Threat Type: Category of threats (e.g., 'Ransomware', 'APT', 'Botnet')\n",
    "- Attacker: Threat actors/groups (e.g., 'APT28', 'Lazarus Group', 'Shuckworm')\n",
    "- Technique: Attack techniques/TTPs (e.g., 'T1057: Process Discovery', 'Privilege Escalation', 'Phishing')\n",
    "- Tool: Security tools or attack tools (e.g., 'PowerShell', 'Cobalt Strike', 'EHole')\n",
    "- Vulnerability: Security weaknesses (e.g., 'CVE-2020-1472', 'CVE-2021-44228')\n",
    "- IP: IP addresses (e.g., '45.153.243.93', '192.168.1.100')\n",
    "- Domain: Domain names (e.g., 'malicious-domain[.]com', 'evil[.]example[.]com')\n",
    "- URL: URLs (e.g., 'hxxp://178.73.192[.]15/cal.exe')\n",
    "- File: File names (e.g., 'rtk.lnk', 'payload.exe', 'shtasks.exe')\n",
    "- Hash: File hashes (e.g., '2aee8bb2a953124803bc42e5c42935c9', MD5/SHA1/SHA256)\n",
    "\n",
    "Relationship Types:\n",
    "- use, hash, aka, execute, used by, download, resolved to, IP, drop, associated with, deploy, communicate with, connect to, install, exploit, contain, run, launch, target, linked to\n",
    "\n",
    "If there are no entities and relationships pertaining to the specified types, please state 'No related entities and relations'. Make sure to follow the output format shown in the following examples.\n",
    "\n",
    "Example 1:\n",
    "Input: A hitherto unknown attack group has been observed targeting a materials research organization in Asia. The group, which Symantec calls Clasiopa, is characterized by a distinct toolset, which includes one piece of custom malware (Backdoor.Atharvan).\n",
    "Output: Named Entities: (Clasiopa, Attacker), (Backdoor.Atharvan, Malware)\\\\nRelationships: (Clasiopa, uses, Backdoor.Atharvan)\n",
    "\n",
    "Example 2:\n",
    "Input: The Emotet malware has been observed using new phishing techniques to target banking institutions. The malware exploits CVE-2021-1234 vulnerability in Microsoft Office.\n",
    "Output: Named Entities: (Emotet, Malware), (phishing, Technique), (CVE-2021-1234, Vulnerability), (Microsoft Office, Tool)\\\\nRelationships: (Emotet, uses, phishing), (Emotet, exploits, CVE-2021-1234)\n",
    "\n",
    "Example 3:\n",
    "Input: The threat actor downloaded malicious payload from hxxp://malicious-domain[.]com/payload.exe and used hash 2aee8bb2a953124803bc42e5c42935c9 to verify file integrity. The attack targeted IP address 192.168.1.100.\n",
    "Output: Named Entities: (threat actor, Attacker), (malicious payload, File), (hxxp://malicious-domain[.]com/payload.exe, URL), (2aee8bb2a953124803bc42e5c42935c9, Hash), (192.168.1.100, IP)\\\\nRelationships: (threat actor, uses, hxxp://malicious-domain[.]com/payload.exe), (threat actor, targets, 192.168.1.100)\n",
    "\n",
    "Example 4:\n",
    "Input: H2Miner botnet uses Kinsing malware and Cobalt Strike to deploy XMRig miners. The campaign communicates with C2 server at evil[.]domain[.]com and is attributed to APT group.\n",
    "Output: Named Entities: (H2Miner, Threat Type), (Kinsing, Malware), (Cobalt Strike, Tool), (XMRig, Tool), (evil[.]domain[.]com, Domain), (APT group, Attacker)\\\\nRelationships: (H2Miner, uses, Kinsing), (H2Miner, uses, Cobalt Strike), (H2Miner, uses, XMRig), (Kinsing, communicatesWith, evil[.]domain[.]com), (H2Miner, attributedTo, APT group)\n",
    "\n",
    "Example 5:\n",
    "Input: The weather forecast shows sunny skies and moderate temperatures for the weekend.\n",
    "Output: No related entities and relations\n",
    "\n",
    "Now extract entities and relationships from the following text:\n",
    "Input: {text_truncated}\n",
    "Output:\"\"\"\n",
    "    \n",
    "    return prompt\n",
    "\n",
    "# Test the prompt creation\n",
    "if data:\n",
    "    sample_prompt = create_entity_extraction_prompt(data[0]['content'])\n",
    "    print(\"ğŸ“ Sample prompt (first 500 chars):\")\n",
    "    print(sample_prompt[:500] + \"...\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“ Sample prompt (first 500 chars):\n",
      "Instruction: Please identify the following types of entities and then extract the relationships between these extracted entities:\n",
      "\n",
      "Entity Types (focus on these only):\n",
      "- Malware: Malicious software (e.g., 'Stuxnet', 'Emotet', 'Backdoor.Atharvan')\n",
      "- Threat Type: Category of threats (e.g., 'Ransomware', 'APT', 'Botnet')\n",
      "- Attacker: Threat actors/groups (e.g., 'APT28', 'Lazarus Group', 'Shuckworm')\n",
      "- Technique: Attack techniques/TTPs (e.g., 'T1057: Process Discovery', 'Privilege Escalation', 'Phishi...\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-31T09:46:57.550593Z",
     "start_time": "2025-07-31T09:45:12.675272Z"
    }
   },
   "source": [
    "def extract_entities_and_relationships(pipe, text: str) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Extract entities and relationships from text using the LLM.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        prompt = create_entity_extraction_prompt(text)\n",
    "        \n",
    "        # Generate response\n",
    "        response = pipe(\n",
    "            prompt,\n",
    "            max_new_tokens=300,\n",
    "            do_sample=False,\n",
    "            temperature=0.1,\n",
    "            pad_token_id=pipe.tokenizer.eos_token_id,\n",
    "        )\n",
    "        \n",
    "        # Extract generated text\n",
    "        generated_text = response[0]['generated_text']\n",
    "        answer = generated_text[len(prompt):].strip()\n",
    "        \n",
    "        print(f\"ğŸ” Raw model output: {answer[:200]}...\")\n",
    "        \n",
    "        # Parse the response\n",
    "        entities, relationships = parse_extraction_output(answer)\n",
    "        \n",
    "        return {\n",
    "            \"raw_output\": answer,\n",
    "            \"entities\": entities,\n",
    "            \"relationships\": relationships,\n",
    "            \"has_entities\": len(entities) > 0\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error in extraction: {e}\")\n",
    "        return {\n",
    "            \"raw_output\": \"\",\n",
    "            \"entities\": [],\n",
    "            \"relationships\": [],\n",
    "            \"has_entities\": False,\n",
    "            \"error\": str(e)\n",
    "        }\n",
    "\n",
    "def parse_extraction_output(output: str) -> Tuple[List[Tuple], List[Tuple]]:\n",
    "    \"\"\"\n",
    "    Parse the model output to extract entities and relationships.\n",
    "    \"\"\"\n",
    "    entities = []\n",
    "    relationships = []\n",
    "    \n",
    "    # Check for \"No related entities\" case\n",
    "    if \"no related entities\" in output.lower():\n",
    "        return entities, relationships\n",
    "    \n",
    "    try:\n",
    "        # Split output into lines\n",
    "        lines = [line.strip() for line in output.split('\\n') if line.strip()]\n",
    "        \n",
    "        current_section = None\n",
    "        for line in lines:\n",
    "            line_lower = line.lower()\n",
    "            \n",
    "            if \"named entities:\" in line_lower:\n",
    "                current_section = \"entities\"\n",
    "                # Extract entities from the same line\n",
    "                entity_part = line.split(\":\", 1)[1] if \":\" in line else \"\"\n",
    "                entities.extend(extract_tuples_from_text(entity_part))\n",
    "                \n",
    "            elif \"relationships:\" in line_lower:\n",
    "                current_section = \"relationships\"\n",
    "                # Extract relationships from the same line\n",
    "                rel_part = line.split(\":\", 1)[1] if \":\" in line else \"\"\n",
    "                relationships.extend(extract_tuples_from_text(rel_part))\n",
    "                \n",
    "            elif current_section == \"entities\":\n",
    "                entities.extend(extract_tuples_from_text(line))\n",
    "                \n",
    "            elif current_section == \"relationships\":\n",
    "                relationships.extend(extract_tuples_from_text(line))\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸  Error parsing output: {e}\")\n",
    "    \n",
    "    return entities, relationships\n",
    "\n",
    "def extract_tuples_from_text(text: str) -> List[Tuple]:\n",
    "    \"\"\"\n",
    "    Extract tuples from text using regex pattern matching.\n",
    "    \"\"\"\n",
    "    tuples = []\n",
    "    \n",
    "    # Pattern to match (item1, item2) or (item1, item2, item3)\n",
    "    pattern = r'\\(([^)]+)\\)'\n",
    "    matches = re.findall(pattern, text)\n",
    "    \n",
    "    for match in matches:\n",
    "        # Split by comma and clean up\n",
    "        parts = [part.strip() for part in match.split(',')]\n",
    "        if len(parts) >= 2:\n",
    "            tuples.append(tuple(parts))\n",
    "    \n",
    "    return tuples\n",
    "\n",
    "# Test the extraction function\n",
    "if extraction_model and data:\n",
    "    print(\"\\nğŸ§ª Testing entity extraction on sample data...\")\n",
    "    test_result = extract_entities_and_relationships(extraction_model, data[0]['content'])\n",
    "    \n",
    "    print(f\"\\nğŸ“Š Extraction Results:\")\n",
    "    print(f\"   Entities found: {len(test_result['entities'])}\")\n",
    "    print(f\"   Relationships found: {len(test_result['relationships'])}\")\n",
    "    \n",
    "    if test_result['entities']:\n",
    "        print(\"\\nğŸ·ï¸  Sample Entities:\")\n",
    "        for entity in test_result['entities'][:5]:\n",
    "            print(f\"     {entity}\")\n",
    "    \n",
    "    if test_result['relationships']:\n",
    "        print(\"\\nğŸ”— Sample Relationships:\")\n",
    "        for rel in test_result['relationships'][:5]:\n",
    "            print(f\"     {rel}\")\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ§ª Testing entity extraction on sample data...\n",
      "ğŸ” Raw model output: Named Entities: (NailaoLocker, Malware), (SM2, Technique), (Lcrypt0rx, Malware), (Dark 101, Malware), (FortiCNAPP Composite Alerts, Tool), (Lcrypt0rx, Malware), (FortiCNAPP Labs, Tool), (FortiSandbox ...\n",
      "\n",
      "ğŸ“Š Extraction Results:\n",
      "   Entities found: 12\n",
      "   Relationships found: 9\n",
      "\n",
      "ğŸ·ï¸  Sample Entities:\n",
      "     ('NailaoLocker', 'Malware')\n",
      "     ('SM2', 'Technique')\n",
      "     ('Lcrypt0rx', 'Malware')\n",
      "     ('Dark 101', 'Malware')\n",
      "     ('FortiCNAPP Composite Alerts', 'Tool')\n",
      "\n",
      "ğŸ”— Sample Relationships:\n",
      "     ('NailaoLocker', 'uses', 'SM2')\n",
      "     ('NailaoLocker', 'contains', 'Lcrypt0rx')\n",
      "     ('Lcrypt0rx', 'uses', 'Dark 101')\n",
      "     ('FortiCNAPP Composite Alerts', 'linksWeakSignalsIntoClearTimelines')\n",
      "     ('Lcrypt0rx', 'uses', 'FortiCNAPP Labs')\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-31T09:56:06.952005Z",
     "start_time": "2025-07-31T09:51:02.807926Z"
    }
   },
   "source": [
    "def process_articles_for_extraction(data: List[Dict], pipe, max_articles: int = None) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Process multiple articles for entity and relationship extraction.\n",
    "    \"\"\"\n",
    "    articles_to_process = data[:max_articles] if max_articles else data\n",
    "    results = []\n",
    "    \n",
    "    print(f\"ğŸ” Processing {len(articles_to_process)} articles for entity extraction...\")\n",
    "    \n",
    "    for i, article in enumerate(articles_to_process):\n",
    "        print(f\"\\nProcessing {i+1}/{len(articles_to_process)}: {article.get('title', 'Unknown')[:60]}...\")\n",
    "        \n",
    "        # Extract entities and relationships\n",
    "        extraction_result = extract_entities_and_relationships(pipe, article.get('content', ''))\n",
    "        \n",
    "        # Combine with original article data\n",
    "        result = {\n",
    "            \"title\": article.get('title', ''),\n",
    "            \"link\": article.get('link', ''),\n",
    "            \"content\": article.get('content', ''),\n",
    "            \"extraction\": extraction_result,\n",
    "            \"entity_count\": len(extraction_result['entities']),\n",
    "            \"relationship_count\": len(extraction_result['relationships'])\n",
    "        }\n",
    "        \n",
    "        results.append(result)\n",
    "        \n",
    "        # Progress update\n",
    "        if (i + 1) % 5 == 0:\n",
    "            print(f\"  âœ… Processed {i+1}/{len(articles_to_process)} articles\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Process a small batch first for testing\n",
    "print(\"\\nğŸš€ Processing first 5 articles for entity extraction...\")\n",
    "extraction_results = process_articles_for_extraction(data, extraction_model, max_articles=5)\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸš€ Processing first 5 articles for entity extraction...\n",
      "ğŸ” Processing 5 articles for entity extraction...\n",
      "\n",
      "Processing 1/5: FortiGuard Labs Threat Research...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Raw model output: Named Entities: (NailaoLocker, Malware), (SM2, Technique), (Lcrypt0rx, Malware), (Dark 101, Malware), (FortiCNAPP Composite Alerts, Tool), (Lcrypt0rx, Malware), (FortiCNAPP Labs, Tool), (FortiSandbox ...\n",
      "\n",
      "Processing 2/5: NailaoLocker Ransomwareâ€™s â€œCheeseâ€...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Raw model output: Named Entities: (FortiGuard Labs Threat Research, Entity), (NailaoLocker, Malware), (AES-256-CBC, Technique), (SM2 cryptographic key, Vulnerability), (Windows, Platform), (user files, File), (high sev...\n",
      "\n",
      "Processing 3/5: Improving Cloud Intrusion Detection and Triage with FortiCNA...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Raw model output: Named Entities: (FortiGuard Labs Threat Research, Entity), (Cloud, Entity), (Multi-stage technique, Technique), (Authentication abuse, Technique), (Privilege escalation, Technique), (Command execution...\n",
      "\n",
      "Processing 4/5: Old Miner, New Tricks...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Raw model output: Named Entities: (FortiCNAPP team, Attacker), (H2miner, Threat Type), (Lcrypt0rx, Malware), (Linux, OS), (Windows, OS), (Containers, OS), (KinSing, Tool), (Xmrig miners, Tool), (Lcrypt0rx, Malware), (L...\n",
      "\n",
      "Processing 5/5: How FortiSandbox 5.0 Detects Dark 101 Ransomware Despite Eva...\n",
      "ğŸ” Raw model output: Named Entities: (FortiGuard Labs, Organization), (Dark 101, Malware Family), (ransomware, Threat Type), (ransomnote, Threat Type), (Bitcoin, Currency), (Task Manager, Tool), (backupcatalog, Object), (...\n",
      "  âœ… Processed 5/5 articles\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-31T09:56:07.587322Z",
     "start_time": "2025-07-31T09:56:07.551045Z"
    }
   },
   "source": [
    "def save_extraction_results(results: List[Dict], output_dir: str = \"../data/entity-extraction\"):\n",
    "    \"\"\"\n",
    "    Save extraction results to files.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Create output directory\n",
    "        output_path = Path(output_dir)\n",
    "        output_path.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        timestamp = datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "        \n",
    "        # Save detailed results\n",
    "        results_file = output_path / f\"entity_extraction_results_{timestamp}.json\"\n",
    "        with open(results_file, 'w', encoding='utf-8') as f:\n",
    "            json.dump(results, f, ensure_ascii=False, indent=2)\n",
    "        \n",
    "        print(f\"\\nğŸ’¾ SAVED EXTRACTION RESULTS:\")\n",
    "        print(f\"   ğŸ“„ Detailed results: {results_file}\")\n",
    "        \n",
    "        return str(results_file)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error saving results: {e}\")\n",
    "        return None\n",
    "\n",
    "# Save results\n",
    "saved_file = save_extraction_results(extraction_results)\n",
    "\n",
    "# Display sample extraction results for review\n",
    "print(\"\\nğŸ” SAMPLE EXTRACTION RESULTS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for i, result in enumerate(extraction_results[:2]):\n",
    "    print(f\"\\nğŸ“„ Article {i+1}: {result['title'][:80]}...\")\n",
    "    print(f\"ğŸ·ï¸  Entities ({result['entity_count']}):\")\n",
    "    \n",
    "    for entity in result['extraction']['entities'][:5]:\n",
    "        print(f\"   â€¢ {entity}\")\n",
    "    \n",
    "    if result['entity_count'] > 5:\n",
    "        print(f\"   ... and {result['entity_count'] - 5} more entities\")\n",
    "    \n",
    "    print(f\"\\nğŸ”— Relationships ({result['relationship_count']}):\")\n",
    "    for rel in result['extraction']['relationships'][:3]:\n",
    "        print(f\"   â€¢ {rel}\")\n",
    "    \n",
    "    if result['relationship_count'] > 3:\n",
    "        print(f\"   ... and {result['relationship_count'] - 3} more relationships\")\n",
    "    \n",
    "    print(\"-\" * 40)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ’¾ SAVED EXTRACTION RESULTS:\n",
      "   ğŸ“„ Detailed results: ../data/entity-extraction/entity_extraction_results_2025-07-31_16-56-07.json\n",
      "\n",
      "ğŸ” SAMPLE EXTRACTION RESULTS\n",
      "============================================================\n",
      "\n",
      "ğŸ“„ Article 1: FortiGuard Labs Threat Research...\n",
      "ğŸ·ï¸  Entities (12):\n",
      "   â€¢ ('NailaoLocker', 'Malware')\n",
      "   â€¢ ('SM2', 'Technique')\n",
      "   â€¢ ('Lcrypt0rx', 'Malware')\n",
      "   â€¢ ('Dark 101', 'Malware')\n",
      "   â€¢ ('FortiCNAPP Composite Alerts', 'Tool')\n",
      "   ... and 7 more entities\n",
      "\n",
      "ğŸ”— Relationships (9):\n",
      "   â€¢ ('NailaoLocker', 'uses', 'SM2')\n",
      "   â€¢ ('NailaoLocker', 'contains', 'Lcrypt0rx')\n",
      "   â€¢ ('Lcrypt0rx', 'uses', 'Dark 101')\n",
      "   ... and 6 more relationships\n",
      "----------------------------------------\n",
      "\n",
      "ğŸ“„ Article 2: NailaoLocker Ransomwareâ€™s â€œCheeseâ€...\n",
      "ğŸ·ï¸  Entities (7):\n",
      "   â€¢ ('FortiGuard Labs Threat Research', 'Entity')\n",
      "   â€¢ ('NailaoLocker', 'Malware')\n",
      "   â€¢ ('AES-256-CBC', 'Technique')\n",
      "   â€¢ ('SM2 cryptographic key', 'Vulnerability')\n",
      "   â€¢ ('Windows', 'Platform')\n",
      "   ... and 2 more entities\n",
      "\n",
      "ğŸ”— Relationships (4):\n",
      "   â€¢ ('FortiGuard Labs Threat Research', 'builtInDecryption', 'NailaoLocker')\n",
      "   â€¢ ('NailaoLocker', 'uses', 'AES-256-CBC')\n",
      "   â€¢ ('NailaoLocker', 'contains', 'SM2 cryptographic key')\n",
      "   ... and 1 more relationships\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "execution_count": 20
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
