{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZvS_y9APRgd8"
      },
      "source": [
        "### Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "jsfyZc6QRgd8"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "import os\n",
        "if \"COLAB_\" not in \"\".join(os.environ.keys()):\n",
        "    !pip install unsloth\n",
        "else:\n",
        "    !pip install --no-deps bitsandbytes accelerate xformers==0.0.29.post3 peft trl triton cut_cross_entropy unsloth_zoo\n",
        "    !pip install sentencepiece protobuf \"datasets>=3.4.1\" huggingface_hub hf_transfer\n",
        "    !pip install --no-deps unsloth"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RDb7Kv7LRgd9"
      },
      "source": [
        "### Unsloth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QmUBVEnvCDJv",
        "outputId": "aaa7b4a3-505b-4d2b-9eba-f92cce2ef535"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:xformers:WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:\n",
            "    PyTorch 2.6.0+cu124 with CUDA 1204 (you have 2.8.0+cu126)\n",
            "    Python  3.12.9 (you have 3.12.11)\n",
            "  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)\n",
            "  Memory-efficient attention, SwiGLU, sparse and more won't be available.\n",
            "  Set XFORMERS_MORE_DETAILS=1 for more details\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\n",
            "==((====))==  Unsloth 2025.8.9: Fast Llama patching. Transformers: 4.55.2.\n",
            "   \\\\   /|    Tesla T4. Num GPUs = 1. Max memory: 14.741 GB. Platform: Linux.\n",
            "O^O/ \\_/ \\    Torch: 2.8.0+cu126. CUDA: 7.5. CUDA Toolkit: 12.6. Triton: 3.4.0\n",
            "\\        /    Bfloat16 = FALSE. FA [Xformers = None. FA2 = False]\n",
            " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
            "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
          ]
        }
      ],
      "source": [
        "from unsloth import FastLanguageModel\n",
        "import torch\n",
        "max_seq_length = 2048\n",
        "dtype = None\n",
        "load_in_4bit = True # Use 4bit quantization to reduce memory usage.\n",
        "\n",
        "\n",
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name = \"unsloth/llama-2-7b-bnb-4bit\",\n",
        "    max_seq_length = max_seq_length,\n",
        "    dtype = dtype,\n",
        "    load_in_4bit = load_in_4bit,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "03ttpc21mBZP",
        "outputId": "c823231a-c84a-49c0-bf3c-c5e2bd4f3930"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SXd9bTZd1aaL"
      },
      "source": [
        "We now add LoRA adapters so we only need to update 1 to 10% of all parameters!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6bZsfBuZDeCL",
        "outputId": "42ee7e36-b378-4682-c45e-13f4997e6930"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Unsloth 2025.8.9 patched 32 layers with 32 QKV layers, 32 O layers and 32 MLP layers.\n"
          ]
        }
      ],
      "source": [
        "model = FastLanguageModel.get_peft_model(\n",
        "    model,\n",
        "    r = 16,\n",
        "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
        "                      \"gate_proj\", \"up_proj\", \"down_proj\",],\n",
        "    lora_alpha = 16,\n",
        "    lora_dropout = 0,\n",
        "    bias = \"none\",\n",
        "    use_gradient_checkpointing = \"unsloth\",\n",
        "    random_state = 3407,\n",
        "    use_rslora = False,\n",
        "    loftq_config = None,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vITh0KVJ10qX"
      },
      "source": [
        "<a name=\"Data\"></a>\n",
        "### Data Prep\n",
        "We now use the Alpaca dataset from [yahma](https://huggingface.co/datasets/yahma/alpaca-cleaned), which is a filtered version of 52K of the original [Alpaca dataset](https://crfm.stanford.edu/2023/03/13/alpaca.html)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "idAEIeSQ3xdS"
      },
      "source": [
        "<a name=\"Train\"></a>\n",
        "### Train the model\n",
        "We do 60 steps to speed things up, but you can set `num_train_epochs=1` for a full run, and turn off `max_steps=None`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "LjY75GoYUCB8"
      },
      "outputs": [],
      "source": [
        "alpaca_prompt = \"\"\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
        "\n",
        "### Instruction:\n",
        "{}\n",
        "\n",
        "### Input:\n",
        "{}\n",
        "\n",
        "### Response:\n",
        "{}\"\"\"\n",
        "\n",
        "EOS_TOKEN = tokenizer.eos_token # Must add EOS_TOKEN\n",
        "def formatting_prompts_func(examples):\n",
        "    instructions = examples[\"instruction\"]\n",
        "    inputs       = examples[\"input\"]\n",
        "    outputs      = examples[\"output\"]\n",
        "    texts = []\n",
        "    for instruction, input, output in zip(instructions, inputs, outputs):\n",
        "        # Must add EOS_TOKEN, otherwise your generation will go on forever!\n",
        "        text = alpaca_prompt.format(instruction, input, output) + EOS_TOKEN\n",
        "        texts.append(text)\n",
        "    return { \"text\" : texts, }\n",
        "pass\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from datasets import load_dataset\n",
        "dataset = load_dataset(\"json\", data_files='/content/drive/MyDrive/LLM-TKIG/entity_extraction_instruction.json', split = \"train\")\n",
        "dataset = dataset.map(formatting_prompts_func, batched = True,)"
      ],
      "metadata": {
        "id": "8ENm4MFDjkaw"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7V4vkO7cikan",
        "outputId": "a948b706-b1f3-46f6-d4d3-a694be578454"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['instruction', 'input', 'output', 'text'],\n",
              "    num_rows: 423\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n",
        "\n",
        "# Get an example from the dataset\n",
        "example_input = dataset[0]\n",
        "\n",
        "inputs = tokenizer(\n",
        "[\n",
        "  alpaca_prompt.format(example_input['instruction'],\"\", \"\")\n",
        "], return_tensors = \"pt\").to(\"cuda\")\n",
        "\n",
        "from transformers import TextStreamer\n",
        "text_streamer = TextStreamer(tokenizer)\n",
        "_ = model.generate(**inputs, streamer = text_streamer, max_new_tokens = 128)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "265gbK-97JYu",
        "outputId": "4453037e-8976-4014-a1bd-3bd7d460bba8"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "An unknown attacker is using a complex and powerful new malware loader in relatively unsophisticated and low-reward attacks, indicating they may not realize the potential capabilities of the malware they are deploying. The malware, Trojan.Verblecon, is being used in attacks that appear to have installing cryptocurrency miners on infected machines as their end goal. There are some indications the attacker may also be interested in stealing access tokens for chat app Discord. However, the capabilities of this malware indicate that it could be highly dangerous if leveraged in ransomware or espionage campaigns. Verblecon was first spotted by analysts from Symantec, a division ofBroadcom Software, in January 2022. This blog will detail the capabilities of the malware. The malware is loaded as a server-side polymorphic JAR file. The fact that the file is polymorphic means that, due to encryption and obfuscation, the code of the malware payload looks different each time it is downloaded. Attackers generally pack malware in this way in an effort to evade detection by security software. The malware samples analyzed by Symantec were fully obfuscated, in the code flow, strings, and symbols. The samples themselves may be based onpublicly available code. Once started, the malware checks its command-line arguments. It requires at least one command-line argument to execute, which could be the infection or campaign ID initially e.g. \"CSIDL_SYSTEM_DRIVE\\program files\\java\\jre1.8.0_301\\bin\\javaw.exe\" -jar \"CSIDL_PROFILE\\appdata\\local\\temp\\rpvbh.jar\" masonkhonsari \"CSIDL_SYSTEM_DRIVE\\program files\\java\\jre1.8.0_301\\bin\\javaw.exe\" -jar \"CSIDL_PROFILE\\appdata\\local\\temp\\rpvbh.jar\" 923ec15ffa4474ca7bf200bfb90e782d Additionally, it also attempts to determine if its own process is being debugged by checking for the following Java command-line arguments: Next, it attempts to detect if it is being opened in a virtual or sandbox environment, which would indicate it is likely being opened on a security researcherâ€™s machine. First, it checks for the following directories: It also obtains the machine MAC address and attempts to check for the following prefixes, which may indicate the file is being opened on a virtual machine: Following those checks, it executes the following command to obtain a list of running processes: It then appears to check these processes against a set list: It then also checks for the following files: Next, it appears to check the user name against the following: Then it executes the following command: It is unclear how the output is processed, however, there are some strings that could be related to this or other registry checks: If satisfied with these checks, it may copy itself as one of the following files: And then create one of the following files to use as a loadpoint: [INFECTION_ID] is computed as follows: Then it periodically attempts to connect to the following URLs: [DGA_NAME] is apparently generated using the following method: The traffic generated by the malware looks like this: The server response appears as the below. Some of the strings in this response indicate that the attacker may be leveraging legitimate Cloudflare infrastructure to host some of their C&C infrastructure. The server response body above is an encrypted blob that contains a URL signed with an RSA key. This blob can be decrypted and validated as follows: The malware then starts communicating with the decoded URL by sending details about the infected computer: The request body contains the following information about the infected machine in encrypted form: The server has been observed to respond as follows: Where the response body can be decrypted as follows: The last term above contains the following string: Some samples of the malware are seen communicating with the following servers: Communication between the malware and servers is over HTTP or HTTPS and this communication appears to culminate with victims being directed to connect to the following: The payload is downloaded from the URL observed earlier: The payload is obfuscated in a similar way to the other samples, and also contains similar techniques to detect the virtualization environment, as well as other functionality. The core functionality is to download and execute a binary blob from the following URL: The blob is decrypted along with *.bin artifacts from the same host. The downloaded blob is then cached on the local filesystem (in re-encrypted form) and injected into %Windows%\\SysWow64\\dllhost.exe for execution. The injection is performed using com.sun.jna and doesn't use usual APIs for injection. The final payload (hardwick.bin) contains the following embedded URL pointing to a configuration file for a cryptocurrency miner: This indicates that the purpose of this activity was to install cryptocurrency mining software on victim machines. The evidence found on victim networks appears to indicate that the goal of the attacker was to install cryptocurrency mining software on victim machines. This would appear to be a relatively low-reward goal for the attacker given the level of effort that would have been required to develop this sophisticated malware. There are also indications that the attacker may be stealing Discord tokens and using these to advertise Trojanized videogame applications. We suspect they were stealing Discord tokens because some of the obfuscated strings refer to pathnames that are apparently related to Discord clients, specifically: Discord is a group chatting app that is particularly popular among the gaming community. Advertising Trojanized videogame applications via Discord is likely a redistribution channel for Trojan.Verblecon. Most of the infections we saw where this malware was used were on non-enterprise machines; we rarely see ransomware deployed on non-enterprise machines. Previous reportshave connected related domains to a single occurrence of ransomware, but the infrastructure may be shared with an unrelated actor. The similarities between that incident and the activity we observed includes: However, we do not have enough evidence to draw a definitive link between both these sets of activity. The activity we have seen carried out using this sophisticated loader indicates that it is being wielded by an individual who may not realize the capabilities of the malware they are using. However, if it fell into the hands of a more sophisticated actor the potential is there for this loader to be used for more serious attacks, including potentially ransomware and espionage campaigns. For the latest protection updates, please visit theSymantec Protection Bulletin. If an IOC is malicious and the file available to us, Symantec Endpoint products will detect and block that file. 32a9415daa7f37a93dd0b347461844673c0f5baf0c15c01ee48b147dadf28299 3688c249774cc9a28d2b9b316921cec842bb087c57f4733cf5866226fbe2aeed 5a4f6332ad08b35c055bb5e6dfddc79d2f7905e63fac7595efbedd0b27f12eb8 007f5898c52c3aa1c3dca6d3a30f28f5f72d9789fbb440ae656d88959f68e53e f3f4af5f5eae1a28ad5a01b56d71302a265bce17d2c87ce731edf440612818a6 hxxp://verble[.]software/styles.jar hxxps://jonathanhardwick[.]me/hardwick.jar hxxps://jonathanhardwick[.]me/hardwick.bin hxxps://jonathanhardwick[.]me/config.txt hxxp://test.verble[.]rocks/dorflersaladreviews.jar hxxp://test.verble[.]rocks/dorflersaladreviews.bin The Threat Hunter Team is a group of security experts within Broadcom whose mission is to investigate targeted attacks, drive enhanced protection in Symantec and Carbon Black products, and offer analysis that helps customers respond to attacks. We encourage you to share your thoughts on your favorite social platform.\n",
            "\n",
            "### Input:\n",
            "\n",
            "\n",
            "### Response:\n",
            "\n",
            "\n",
            "### Instruction:\n",
            "An unknown attacker is using a complex and powerful new malware loader in relatively unsophisticated and low-reward attacks, indicating they may not realize the potential capabilities of the malware they are deploying. The malware, Trojan.Verblecon, is being used in attacks that appear to have installing cryptocurrency miners on infected machines as their end goal. There are some indications the attacker may also be interested in stealing access tokens for chat app Discord. However, the capabilities of this malware indicate that it could be highly dangerous if leveraged\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "95_Nn-89DhsL"
      },
      "outputs": [],
      "source": [
        "from trl import SFTConfig, SFTTrainer\n",
        "trainer = SFTTrainer(\n",
        "    model = model,\n",
        "    tokenizer = tokenizer,\n",
        "    train_dataset = dataset,\n",
        "    dataset_text_field = \"text\",\n",
        "    max_seq_length = max_seq_length,\n",
        "    dataset_num_proc = 2,\n",
        "    packing = False, # Can make training 5x faster for short sequences.\n",
        "    args = SFTConfig(\n",
        "        per_device_train_batch_size = 2,\n",
        "        gradient_accumulation_steps = 4,\n",
        "        warmup_steps = 5,\n",
        "        # num_train_epochs = 1, # Set this for 1 full training run.\n",
        "        max_steps = 60,\n",
        "        learning_rate = 2e-4,\n",
        "        logging_steps = 1,\n",
        "        optim = \"adamw_8bit\",\n",
        "        weight_decay = 0.01,\n",
        "        lr_scheduler_type = \"linear\",\n",
        "        seed = 3407,\n",
        "        output_dir = \"outputs\",\n",
        "        report_to = \"none\", # Use this for WandB etc\n",
        "    ),\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ejIt2xSNKKp",
        "outputId": "5d303163-3a0f-4e40-f5bf-6acea262820a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU = Tesla T4. Max memory = 14.741 GB.\n",
            "6.369 GB of memory reserved.\n"
          ]
        }
      ],
      "source": [
        "# @title Show current memory stats\n",
        "gpu_stats = torch.cuda.get_device_properties(0)\n",
        "start_gpu_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n",
        "max_memory = round(gpu_stats.total_memory / 1024 / 1024 / 1024, 3)\n",
        "print(f\"GPU = {gpu_stats.name}. Max memory = {max_memory} GB.\")\n",
        "print(f\"{start_gpu_memory} GB of memory reserved.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "yqxqAZ7KJ4oL",
        "outputId": "2bdebf1a-98f6-4abd-d834-7899a85d814d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
            "   \\\\   /|    Num examples = 423 | Num Epochs = 2 | Total steps = 60\n",
            "O^O/ \\_/ \\    Batch size per device = 2 | Gradient accumulation steps = 4\n",
            "\\        /    Data Parallel GPUs = 1 | Total batch size (2 x 4 x 1) = 8\n",
            " \"-____-\"     Trainable parameters = 39,976,960 of 6,778,392,576 (0.59% trained)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unsloth: Will smartly offload gradients to save VRAM!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='60' max='60' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [60/60 38:28, Epoch 1/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.943100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>2.007900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.995800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.990800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>2.054700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>2.262000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>1.960400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>1.489300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>1.937100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>1.839000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>1.764000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>1.694300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>1.883400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>1.738800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>1.645200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>1.706900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>1.472000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>1.663400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>1.480800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>1.983200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21</td>\n",
              "      <td>2.118300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22</td>\n",
              "      <td>1.786000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>23</td>\n",
              "      <td>1.648500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24</td>\n",
              "      <td>1.839600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>1.883900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>26</td>\n",
              "      <td>1.592400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>27</td>\n",
              "      <td>1.583800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>28</td>\n",
              "      <td>1.803600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>29</td>\n",
              "      <td>1.934600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>1.781600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>31</td>\n",
              "      <td>1.945100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>32</td>\n",
              "      <td>1.604800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>33</td>\n",
              "      <td>1.726700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>34</td>\n",
              "      <td>2.027200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>35</td>\n",
              "      <td>1.558600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>36</td>\n",
              "      <td>1.613100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>37</td>\n",
              "      <td>1.791100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>38</td>\n",
              "      <td>1.498300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>39</td>\n",
              "      <td>1.910400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>1.911000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>41</td>\n",
              "      <td>1.647200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>42</td>\n",
              "      <td>1.848200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>43</td>\n",
              "      <td>1.668000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>44</td>\n",
              "      <td>1.767300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>45</td>\n",
              "      <td>1.884300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>46</td>\n",
              "      <td>1.745300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>47</td>\n",
              "      <td>1.680300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>48</td>\n",
              "      <td>1.525300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>49</td>\n",
              "      <td>1.745900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>1.579600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>51</td>\n",
              "      <td>1.595900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>52</td>\n",
              "      <td>1.650900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>53</td>\n",
              "      <td>1.752100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>54</td>\n",
              "      <td>1.827500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>55</td>\n",
              "      <td>1.514100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>56</td>\n",
              "      <td>1.930300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>57</td>\n",
              "      <td>1.744600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>58</td>\n",
              "      <td>1.594000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>59</td>\n",
              "      <td>1.781300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>1.363700</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "trainer_stats = trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pCqnaKmlO1U9",
        "outputId": "e2060621-8e31-4298-b3ec-56e1c6f9fcf5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2356.3396 seconds used for training.\n",
            "39.27 minutes used for training.\n",
            "Peak reserved memory = 6.369 GB.\n",
            "Peak reserved memory for training = 0.0 GB.\n",
            "Peak reserved memory % of max memory = 43.206 %.\n",
            "Peak reserved memory for training % of max memory = 0.0 %.\n"
          ]
        }
      ],
      "source": [
        "# @title Show final memory and time stats\n",
        "used_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n",
        "used_memory_for_lora = round(used_memory - start_gpu_memory, 3)\n",
        "used_percentage = round(used_memory / max_memory * 100, 3)\n",
        "lora_percentage = round(used_memory_for_lora / max_memory * 100, 3)\n",
        "print(f\"{trainer_stats.metrics['train_runtime']} seconds used for training.\")\n",
        "print(\n",
        "    f\"{round(trainer_stats.metrics['train_runtime']/60, 2)} minutes used for training.\"\n",
        ")\n",
        "print(f\"Peak reserved memory = {used_memory} GB.\")\n",
        "print(f\"Peak reserved memory for training = {used_memory_for_lora} GB.\")\n",
        "print(f\"Peak reserved memory % of max memory = {used_percentage} %.\")\n",
        "print(f\"Peak reserved memory for training % of max memory = {lora_percentage} %.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ekOmTR1hSNcr"
      },
      "source": [
        "<a name=\"Inference\"></a>\n",
        "### Inference\n",
        "Let's run the model! You can change the instruction and input - leave the output blank!\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kR3gIAX-SM2q",
        "outputId": "b5216591-d339-41a8-8e5f-9894198792d2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<s> Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nAn unknown attacker is using a complex and powerful new malware loader in relatively unsophisticated and low-reward attacks, indicating they may not realize the potential capabilities of the malware they are deploying. The malware, Trojan.Verblecon, is being used in attacks that appear to have installing cryptocurrency miners on infected machines as their end goal. There are some indications the attacker may also be interested in stealing access tokens for chat app Discord. However, the capabilities of this malware indicate that it could be highly dangerous if leveraged in ransomware or espionage campaigns. Verblecon was first spotted by analysts from Symantec, a division ofBroadcom Software, in January 2022. This blog will detail the capabilities of the malware. The malware is loaded as a server-side polymorphic JAR file. The fact that the file is polymorphic means that, due to encryption and obfuscation, the code of the malware payload looks different each time it is downloaded. Attackers generally pack malware in this way in an effort to evade detection by security software. The malware samples analyzed by Symantec were fully obfuscated, in the code flow, strings, and symbols. The samples themselves may be based onpublicly available code. Once started, the malware checks its command-line arguments. It requires at least one command-line argument to execute, which could be the infection or campaign ID initially e.g. \"CSIDL_SYSTEM_DRIVE\\\\program files\\\\java\\\\jre1.8.0_301\\\\bin\\\\javaw.exe\" -jar \"CSIDL_PROFILE\\\\appdata\\\\local\\\\temp\\\\rpvbh.jar\" masonkhonsari \"CSIDL_SYSTEM_DRIVE\\\\program files\\\\java\\\\jre1.8.0_301\\\\bin\\\\javaw.exe\" -jar \"CSIDL_PROFILE\\\\appdata\\\\local\\\\temp\\\\rpvbh.jar\" 923ec15ffa4474ca7bf200bfb90e782d Additionally, it also attempts to determine if its own process is being debugged by checking for the following Java command-line arguments: Next, it attempts to detect if it is being opened in a virtual or sandbox environment, which would indicate it is likely being opened on a security researcherâ€™s machine. First, it checks for the following directories: It also obtains the machine MAC address and attempts to check for the following prefixes, which may indicate the file is being opened on a virtual machine: Following those checks, it executes the following command to obtain a list of running processes: It then appears to check these processes against a set list: It then also checks for the following files: Next, it appears to check the user name against the following: Then it executes the following command: It is unclear how the output is processed, however, there are some strings that could be related to this or other registry checks: If satisfied with these checks, it may copy itself as one of the following files: And then create one of the following files to use as a loadpoint: [INFECTION_ID] is computed as follows: Then it periodically attempts to connect to the following URLs: [DGA_NAME] is apparently generated using the following method: The traffic generated by the malware looks like this: The server response appears as the below. Some of the strings in this response indicate that the attacker may be leveraging legitimate Cloudflare infrastructure to host some of their C&C infrastructure. The server response body above is an encrypted blob that contains a URL signed with an RSA key. This blob can be decrypted and validated as follows: The malware then starts communicating with the decoded URL by sending details about the infected computer: The request body contains the following information about the infected machine in encrypted form: The server has been observed to respond as follows: Where the response body can be decrypted as follows: The last term above contains the following string: Some samples of the malware are seen communicating with the following servers: Communication between the malware and servers is over HTTP or HTTPS and this communication appears to culminate with victims being directed to connect to the following: The payload is downloaded from the URL observed earlier: The payload is obfuscated in a similar way to the other samples, and also contains similar techniques to detect the virtualization environment, as well as other functionality. The core functionality is to download and execute a binary blob from the following URL: The blob is decrypted along with *.bin artifacts from the same host. The downloaded blob is then cached on the local filesystem (in re-encrypted form) and injected into %Windows%\\\\SysWow64\\\\dllhost.exe for execution. The injection is performed using com.sun.jna and doesn\\'t use usual APIs for injection. The final payload (hardwick.bin) contains the following embedded URL pointing to a configuration file for a cryptocurrency miner: This indicates that the purpose of this activity was to install cryptocurrency mining software on victim machines. The evidence found on victim networks appears to indicate that the goal of the attacker was to install cryptocurrency mining software on victim machines. This would appear to be a relatively low-reward goal for the attacker given the level of effort that would have been required to develop this sophisticated malware. There are also indications that the attacker may be stealing Discord tokens and using these to advertise Trojanized videogame applications. We suspect they were stealing Discord tokens because some of the obfuscated strings refer to pathnames that are apparently related to Discord clients, specifically: Discord is a group chatting app that is particularly popular among the gaming community. Advertising Trojanized videogame applications via Discord is likely a redistribution channel for Trojan.Verblecon. Most of the infections we saw where this malware was used were on non-enterprise machines; we rarely see ransomware deployed on non-enterprise machines. Previous reportshave connected related domains to a single occurrence of ransomware, but the infrastructure may be shared with an unrelated actor. The similarities between that incident and the activity we observed includes: However, we do not have enough evidence to draw a definitive link between both these sets of activity. The activity we have seen carried out using this sophisticated loader indicates that it is being wielded by an individual who may not realize the capabilities of the malware they are using. However, if it fell into the hands of a more sophisticated actor the potential is there for this loader to be used for more serious attacks, including potentially ransomware and espionage campaigns. For the latest protection updates, please visit theSymantec Protection Bulletin. If an IOC is malicious and the file available to us, Symantec Endpoint products will detect and block that file. 32a9415daa7f37a93dd0b347461844673c0f5baf0c15c01ee48b147dadf28299 3688c249774cc9a28d2b9b316921cec842bb087c57f4733cf5866226fbe2aeed 5a4f6332ad08b35c055bb5e6dfddc79d2f7905e63fac7595efbedd0b27f12eb8 007f5898c52c3aa1c3dca6d3a30f28f5f72d9789fbb440ae656d88959f68e53e f3f4af5f5eae1a28ad5a01b56d71302a265bce17d2c87ce731edf440612818a6 hxxp://verble[.]software/styles.jar hxxps://jonathanhardwick[.]me/hardwick.jar hxxps://jonathanhardwick[.]me/hardwick.bin hxxps://jonathanhardwick[.]me/config.txt hxxp://test.verble[.]rocks/dorflersaladreviews.jar hxxp://test.verble[.]rocks/dorflersaladreviews.bin The Threat Hunter Team is a group of security experts within Broadcom whose mission is to investigate targeted attacks, drive enhanced protection in Symantec and Carbon Black products, and offer analysis that helps customers respond to attacks. We encourage you to share your thoughts on your favorite social platform.\\n\\n### Input:\\n\\n\\n### Response:\\nNamed Entities: (Trojan.Verblecon, Malware), (cryptocurrency miner, Malware), (Discord, Tool), (ransomware, Malware), (espionage campaign, Malware), (polymorphic JAR file, File), (command']"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "# alpaca_prompt = Copied from above\n",
        "FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n",
        "inputs = tokenizer(\n",
        "[\n",
        "    alpaca_prompt.format(\n",
        "      example_input['instruction'], # instruction\n",
        "      \"\", # input\n",
        "      \"\", # output - leave this blank for generation!\n",
        "    )\n",
        "], return_tensors = \"pt\").to(\"cuda\")\n",
        "\n",
        "outputs = model.generate(**inputs, max_new_tokens = 64, use_cache = True)\n",
        "tokenizer.batch_decode(outputs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CrSvZObor0lY"
      },
      "source": [
        " You can also use a `TextStreamer` for continuous inference - so you can see the generation token by token, instead of waiting the whole time!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e2pEuRb1r2Vg",
        "outputId": "a042aa72-7078-4367-ca7c-5cfbbd5ef79a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "An unknown attacker is using a complex and powerful new malware loader in relatively unsophisticated and low-reward attacks, indicating they may not realize the potential capabilities of the malware they are deploying. The malware, Trojan.Verblecon, is being used in attacks that appear to have installing cryptocurrency miners on infected machines as their end goal. There are some indications the attacker may also be interested in stealing access tokens for chat app Discord. However, the capabilities of this malware indicate that it could be highly dangerous if leveraged in ransomware or espionage campaigns. Verblecon was first spotted by analysts from Symantec, a division ofBroadcom Software, in January 2022. This blog will detail the capabilities of the malware. The malware is loaded as a server-side polymorphic JAR file. The fact that the file is polymorphic means that, due to encryption and obfuscation, the code of the malware payload looks different each time it is downloaded. Attackers generally pack malware in this way in an effort to evade detection by security software. The malware samples analyzed by Symantec were fully obfuscated, in the code flow, strings, and symbols. The samples themselves may be based onpublicly available code. Once started, the malware checks its command-line arguments. It requires at least one command-line argument to execute, which could be the infection or campaign ID initially e.g. \"CSIDL_SYSTEM_DRIVE\\program files\\java\\jre1.8.0_301\\bin\\javaw.exe\" -jar \"CSIDL_PROFILE\\appdata\\local\\temp\\rpvbh.jar\" masonkhonsari \"CSIDL_SYSTEM_DRIVE\\program files\\java\\jre1.8.0_301\\bin\\javaw.exe\" -jar \"CSIDL_PROFILE\\appdata\\local\\temp\\rpvbh.jar\" 923ec15ffa4474ca7bf200bfb90e782d Additionally, it also attempts to determine if its own process is being debugged by checking for the following Java command-line arguments: Next, it attempts to detect if it is being opened in a virtual or sandbox environment, which would indicate it is likely being opened on a security researcherâ€™s machine. First, it checks for the following directories: It also obtains the machine MAC address and attempts to check for the following prefixes, which may indicate the file is being opened on a virtual machine: Following those checks, it executes the following command to obtain a list of running processes: It then appears to check these processes against a set list: It then also checks for the following files: Next, it appears to check the user name against the following: Then it executes the following command: It is unclear how the output is processed, however, there are some strings that could be related to this or other registry checks: If satisfied with these checks, it may copy itself as one of the following files: And then create one of the following files to use as a loadpoint: [INFECTION_ID] is computed as follows: Then it periodically attempts to connect to the following URLs: [DGA_NAME] is apparently generated using the following method: The traffic generated by the malware looks like this: The server response appears as the below. Some of the strings in this response indicate that the attacker may be leveraging legitimate Cloudflare infrastructure to host some of their C&C infrastructure. The server response body above is an encrypted blob that contains a URL signed with an RSA key. This blob can be decrypted and validated as follows: The malware then starts communicating with the decoded URL by sending details about the infected computer: The request body contains the following information about the infected machine in encrypted form: The server has been observed to respond as follows: Where the response body can be decrypted as follows: The last term above contains the following string: Some samples of the malware are seen communicating with the following servers: Communication between the malware and servers is over HTTP or HTTPS and this communication appears to culminate with victims being directed to connect to the following: The payload is downloaded from the URL observed earlier: The payload is obfuscated in a similar way to the other samples, and also contains similar techniques to detect the virtualization environment, as well as other functionality. The core functionality is to download and execute a binary blob from the following URL: The blob is decrypted along with *.bin artifacts from the same host. The downloaded blob is then cached on the local filesystem (in re-encrypted form) and injected into %Windows%\\SysWow64\\dllhost.exe for execution. The injection is performed using com.sun.jna and doesn't use usual APIs for injection. The final payload (hardwick.bin) contains the following embedded URL pointing to a configuration file for a cryptocurrency miner: This indicates that the purpose of this activity was to install cryptocurrency mining software on victim machines. The evidence found on victim networks appears to indicate that the goal of the attacker was to install cryptocurrency mining software on victim machines. This would appear to be a relatively low-reward goal for the attacker given the level of effort that would have been required to develop this sophisticated malware. There are also indications that the attacker may be stealing Discord tokens and using these to advertise Trojanized videogame applications. We suspect they were stealing Discord tokens because some of the obfuscated strings refer to pathnames that are apparently related to Discord clients, specifically: Discord is a group chatting app that is particularly popular among the gaming community. Advertising Trojanized videogame applications via Discord is likely a redistribution channel for Trojan.Verblecon. Most of the infections we saw where this malware was used were on non-enterprise machines; we rarely see ransomware deployed on non-enterprise machines. Previous reportshave connected related domains to a single occurrence of ransomware, but the infrastructure may be shared with an unrelated actor. The similarities between that incident and the activity we observed includes: However, we do not have enough evidence to draw a definitive link between both these sets of activity. The activity we have seen carried out using this sophisticated loader indicates that it is being wielded by an individual who may not realize the capabilities of the malware they are using. However, if it fell into the hands of a more sophisticated actor the potential is there for this loader to be used for more serious attacks, including potentially ransomware and espionage campaigns. For the latest protection updates, please visit theSymantec Protection Bulletin. If an IOC is malicious and the file available to us, Symantec Endpoint products will detect and block that file. 32a9415daa7f37a93dd0b347461844673c0f5baf0c15c01ee48b147dadf28299 3688c249774cc9a28d2b9b316921cec842bb087c57f4733cf5866226fbe2aeed 5a4f6332ad08b35c055bb5e6dfddc79d2f7905e63fac7595efbedd0b27f12eb8 007f5898c52c3aa1c3dca6d3a30f28f5f72d9789fbb440ae656d88959f68e53e f3f4af5f5eae1a28ad5a01b56d71302a265bce17d2c87ce731edf440612818a6 hxxp://verble[.]software/styles.jar hxxps://jonathanhardwick[.]me/hardwick.jar hxxps://jonathanhardwick[.]me/hardwick.bin hxxps://jonathanhardwick[.]me/config.txt hxxp://test.verble[.]rocks/dorflersaladreviews.jar hxxp://test.verble[.]rocks/dorflersaladreviews.bin The Threat Hunter Team is a group of security experts within Broadcom whose mission is to investigate targeted attacks, drive enhanced protection in Symantec and Carbon Black products, and offer analysis that helps customers respond to attacks. We encourage you to share your thoughts on your favorite social platform.\n",
            "\n",
            "### Input:\n",
            "\n",
            "\n",
            "### Response:\n",
            "Named Entities: (Trojan.Verblecon, Malware), (Symantec, Tool), (Broadcom Software, Company), (CSIDL_SYSTEM_DRIVE, Location), (CSIDL_PROFILE, Location), (CSIDL_SYSTEM_DRIVE\\program files\\java\\jre1.8.0_301\\bin\\javaw.exe, File), (CSIDL_SYSTEM_DRIVE\\program files\\java\\jre1.8.0_301\\bin\\java\n"
          ]
        }
      ],
      "source": [
        "# alpaca_prompt = Copied from above\n",
        "FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n",
        "inputs = tokenizer(\n",
        "[\n",
        "  alpaca_prompt.format(\n",
        "        example_input['instruction'], # instruction\n",
        "        \"\", # input\n",
        "        \"\", # output - leave this blank for generation!\n",
        "    )\n",
        "], return_tensors = \"pt\").to(\"cuda\")\n",
        "\n",
        "from transformers import TextStreamer\n",
        "text_streamer = TextStreamer(tokenizer)\n",
        "_ = model.generate(**inputs, streamer = text_streamer, max_new_tokens = 128)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uMuVrWbjAzhc"
      },
      "source": [
        "<a name=\"Save\"></a>\n",
        "### Saving, loading finetuned models\n",
        "To save the final model as LoRA adapters, either use Huggingface's `push_to_hub` for an online save or `save_pretrained` for a local save.\n",
        "\n",
        "**[NOTE]** This ONLY saves the LoRA adapters, and not the full model. To save to 16bit or GGUF, scroll down!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "upcOlWe7A1vc",
        "outputId": "94e93a4b-b3e5-43cc-a3c8-66ae1b13fbbf"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('/content/drive/MyDrive/LLM-TKIG/finetuned_model_entity_extractor/tokenizer_config.json',\n",
              " '/content/drive/MyDrive/LLM-TKIG/finetuned_model_entity_extractor/special_tokens_map.json',\n",
              " '/content/drive/MyDrive/LLM-TKIG/finetuned_model_entity_extractor/tokenizer.model',\n",
              " '/content/drive/MyDrive/LLM-TKIG/finetuned_model_entity_extractor/added_tokens.json',\n",
              " '/content/drive/MyDrive/LLM-TKIG/finetuned_model_entity_extractor/tokenizer.json')"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "model.save_pretrained(\"/content/drive/MyDrive/LLM-TKIG/finetuned_model_entity_extractor\")  # Local saving\n",
        "tokenizer.save_pretrained(\"/content/drive/MyDrive/LLM-TKIG/finetuned_model_entity_extractor\")\n",
        "\n",
        "\n",
        "# model.push_to_hub(\"your_name/lora_model\", token = \"...\") # Online saving\n",
        "# tokenizer.push_to_hub(\"your_name/lora_model\", token = \"...\") # Online saving"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AEEcJ4qfC7Lp"
      },
      "source": [
        "Now if you want to load the LoRA adapters we just saved for inference, set `False` to `True`:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if True:\n",
        "  from unsloth import FastLanguageModel\n",
        "  model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "      model_name = \"/content/drive/MyDrive/LLM-TKIG/finetuned_model_entity_extractor\",\n",
        "      max_seq_length = max_seq_length,\n",
        "      dtype = dtype,\n",
        "      load_in_4bit = load_in_4bit,\n",
        "      device_map=\"auto\", # Added device_map=\"auto\"\n",
        "  )\n",
        "  FastLanguageModel.for_inference(model) # Enable native 2x faster inference"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BD3RRPemAXWy",
        "outputId": "c0232201-9538-4186-dc5a-d34e40e65233"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==((====))==  Unsloth 2025.8.9: Fast Llama patching. Transformers: 4.55.2.\n",
            "   \\\\   /|    Tesla T4. Num GPUs = 1. Max memory: 14.741 GB. Platform: Linux.\n",
            "O^O/ \\_/ \\    Torch: 2.8.0+cu126. CUDA: 7.5. CUDA Toolkit: 12.6. Triton: 3.4.0\n",
            "\\        /    Bfloat16 = FALSE. FA [Xformers = None. FA2 = False]\n",
            " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
            "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MKX_XKs_BNZR",
        "outputId": "00578f11-821e-455c-fc74-2ea15e80dbc2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "An unknown attacker is using a complex and powerful new malware loader in relatively unsophisticated and low-reward attacks, indicating they may not realize the potential capabilities of the malware they are deploying. The malware, Trojan.Verblecon, is being used in attacks that appear to have installing cryptocurrency miners on infected machines as their end goal. There are some indications the attacker may also be interested in stealing access tokens for chat app Discord. However, the capabilities of this malware indicate that it could be highly dangerous if leveraged in ransomware or espionage campaigns. Verblecon was first spotted by analysts from Symantec, a division ofBroadcom Software, in January 2022. This blog will detail the capabilities of the malware. The malware is loaded as a server-side polymorphic JAR file. The fact that the file is polymorphic means that, due to encryption and obfuscation, the code of the malware payload looks different each time it is downloaded. Attackers generally pack malware in this way in an effort to evade detection by security software. The malware samples analyzed by Symantec were fully obfuscated, in the code flow, strings, and symbols. The samples themselves may be based onpublicly available code. Once started, the malware checks its command-line arguments. It requires at least one command-line argument to execute, which could be the infection or campaign ID initially e.g. \"CSIDL_SYSTEM_DRIVE\\program files\\java\\jre1.8.0_301\\bin\\javaw.exe\" -jar \"CSIDL_PROFILE\\appdata\\local\\temp\\rpvbh.jar\" masonkhonsari \"CSIDL_SYSTEM_DRIVE\\program files\\java\\jre1.8.0_301\\bin\\javaw.exe\" -jar \"CSIDL_PROFILE\\appdata\\local\\temp\\rpvbh.jar\" 923ec15ffa4474ca7bf200bfb90e782d Additionally, it also attempts to determine if its own process is being debugged by checking for the following Java command-line arguments: Next, it attempts to detect if it is being opened in a virtual or sandbox environment, which would indicate it is likely being opened on a security researcherâ€™s machine. First, it checks for the following directories: It also obtains the machine MAC address and attempts to check for the following prefixes, which may indicate the file is being opened on a virtual machine: Following those checks, it executes the following command to obtain a list of running processes: It then appears to check these processes against a set list: It then also checks for the following files: Next, it appears to check the user name against the following: Then it executes the following command: It is unclear how the output is processed, however, there are some strings that could be related to this or other registry checks: If satisfied with these checks, it may copy itself as one of the following files: And then create one of the following files to use as a loadpoint: [INFECTION_ID] is computed as follows: Then it periodically attempts to connect to the following URLs: [DGA_NAME] is apparently generated using the following method: The traffic generated by the malware looks like this: The server response appears as the below. Some of the strings in this response indicate that the attacker may be leveraging legitimate Cloudflare infrastructure to host some of their C&C infrastructure. The server response body above is an encrypted blob that contains a URL signed with an RSA key. This blob can be decrypted and validated as follows: The malware then starts communicating with the decoded URL by sending details about the infected computer: The request body contains the following information about the infected machine in encrypted form: The server has been observed to respond as follows: Where the response body can be decrypted as follows: The last term above contains the following string: Some samples of the malware are seen communicating with the following servers: Communication between the malware and servers is over HTTP or HTTPS and this communication appears to culminate with victims being directed to connect to the following: The payload is downloaded from the URL observed earlier: The payload is obfuscated in a similar way to the other samples, and also contains similar techniques to detect the virtualization environment, as well as other functionality. The core functionality is to download and execute a binary blob from the following URL: The blob is decrypted along with *.bin artifacts from the same host. The downloaded blob is then cached on the local filesystem (in re-encrypted form) and injected into %Windows%\\SysWow64\\dllhost.exe for execution. The injection is performed using com.sun.jna and doesn't use usual APIs for injection. The final payload (hardwick.bin) contains the following embedded URL pointing to a configuration file for a cryptocurrency miner: This indicates that the purpose of this activity was to install cryptocurrency mining software on victim machines. The evidence found on victim networks appears to indicate that the goal of the attacker was to install cryptocurrency mining software on victim machines. This would appear to be a relatively low-reward goal for the attacker given the level of effort that would have been required to develop this sophisticated malware. There are also indications that the attacker may be stealing Discord tokens and using these to advertise Trojanized videogame applications. We suspect they were stealing Discord tokens because some of the obfuscated strings refer to pathnames that are apparently related to Discord clients, specifically: Discord is a group chatting app that is particularly popular among the gaming community. Advertising Trojanized videogame applications via Discord is likely a redistribution channel for Trojan.Verblecon. Most of the infections we saw where this malware was used were on non-enterprise machines; we rarely see ransomware deployed on non-enterprise machines. Previous reportshave connected related domains to a single occurrence of ransomware, but the infrastructure may be shared with an unrelated actor. The similarities between that incident and the activity we observed includes: However, we do not have enough evidence to draw a definitive link between both these sets of activity. The activity we have seen carried out using this sophisticated loader indicates that it is being wielded by an individual who may not realize the capabilities of the malware they are using. However, if it fell into the hands of a more sophisticated actor the potential is there for this loader to be used for more serious attacks, including potentially ransomware and espionage campaigns. For the latest protection updates, please visit theSymantec Protection Bulletin. If an IOC is malicious and the file available to us, Symantec Endpoint products will detect and block that file. 32a9415daa7f37a93dd0b347461844673c0f5baf0c15c01ee48b147dadf28299 3688c249774cc9a28d2b9b316921cec842bb087c57f4733cf5866226fbe2aeed 5a4f6332ad08b35c055bb5e6dfddc79d2f7905e63fac7595efbedd0b27f12eb8 007f5898c52c3aa1c3dca6d3a30f28f5f72d9789fbb440ae656d88959f68e53e f3f4af5f5eae1a28ad5a01b56d71302a265bce17d2c87ce731edf440612818a6 hxxp://verble[.]software/styles.jar hxxps://jonathanhardwick[.]me/hardwick.jar hxxps://jonathanhardwick[.]me/hardwick.bin hxxps://jonathanhardwick[.]me/config.txt hxxp://test.verble[.]rocks/dorflersaladreviews.jar hxxp://test.verble[.]rocks/dorflersaladreviews.bin The Threat Hunter Team is a group of security experts within Broadcom whose mission is to investigate targeted attacks, drive enhanced protection in Symantec and Carbon Black products, and offer analysis that helps customers respond to attacks. We encourage you to share your thoughts on your favorite social platform.\n",
            "\n",
            "### Input:\n",
            "\n",
            "\n",
            "### Response:\n",
            "Named Entities: (Trojan.Verblecon, Malware), (Java, Tool), (command-line arguments, String), (csidl_profile, String), (csidl_system_drive, String), (csidl_program_files, String), (csidl_appdata, String), (csidl_local_temp, String), (rpvbh, String), (CSIDL_SYSTEM_DRIVE\\program files\\java\\jre1.8.0_301\\bin, String), (csidl_profile\n"
          ]
        }
      ],
      "source": [
        "inputs = tokenizer(\n",
        "[\n",
        "    alpaca_prompt.format(\n",
        "        example_input['instruction'], # instruction\n",
        "        \"\", # input\n",
        "        \"\", # output - leave this blank for generation!\n",
        "    )\n",
        "], return_tensors = \"pt\").to(\"cuda\")\n",
        "\n",
        "from transformers import TextStreamer\n",
        "text_streamer = TextStreamer(tokenizer)\n",
        "_ = model.generate(**inputs, streamer = text_streamer, max_new_tokens = 128)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}