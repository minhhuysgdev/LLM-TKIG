{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# TTP Classification Training with Qwen Model\n",
    "\n",
    "## Overview\n",
    "This notebook implements TTP (Tactics, Techniques, and Procedures) classification training using Qwen model with MITRE ATT&CK framework.\n",
    "\n",
    "### Task Description\n",
    "- **Input**: Threat intelligence text descriptions\n",
    "- **Output**: MITRE ATT&CK technique classification (T1xxx format)\n",
    "- **Model**: Qwen/Qwen2.5-1.5B-Instruct (fine-tuned)\n",
    "\n",
    "### Dataset Statistics\n",
    "- **Total samples**: 921 training examples\n",
    "- **Enterprise Matrix**: 691 techniques (222 main + 469 sub-techniques)\n",
    "- **Mobile Matrix**: 135 techniques (89 main + 46 sub-techniques)\n",
    "- **ICS Matrix**: 95 techniques (95 main + 0 sub-techniques)\n",
    "\n",
    "### Key Steps\n",
    "1. Load and prepare MITRE ATT&CK training data\n",
    "2. Setup Qwen model for fine-tuning\n",
    "3. Create training and validation splits\n",
    "4. Fine-tune model for TTP classification\n",
    "5. Evaluate model performance\n",
    "6. Test on real threat intelligence data\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## 1. Environment Setup and Dependencies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-23T09:00:55.967624Z",
     "start_time": "2025-08-23T09:00:55.956254Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìö Dependencies loaded successfully!\n",
      "üî• PyTorch version: 2.8.0\n",
      "ü§ñ CUDA available: False\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Any, Tuple\n",
    "import logging\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Transformers and training\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForCausalLM,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    DataCollatorForLanguageModeling\n",
    ")\n",
    "from datasets import Dataset, DatasetDict\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "print(\"üìö Dependencies loaded successfully!\")\n",
    "print(f\"üî• PyTorch version: {torch.__version__}\")\n",
    "print(f\"ü§ñ CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"üéÆ GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"üíæ GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## 2. Load MITRE ATT&CK Training Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-23T09:00:56.014376Z",
     "start_time": "2025-08-23T09:00:55.985317Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Loading MITRE ATT&CK dataset...\n",
      "‚úÖ Loaded 921 training samples\n",
      "\n",
      "üìä Dataset Analysis:\n",
      "  ‚Ä¢ Enterprise: 691 samples\n",
      "  ‚Ä¢ Mobile: 135 samples\n",
      "  ‚Ä¢ ICS: 95 samples\n",
      "  ‚Ä¢ Techniques: 406 samples\n",
      "  ‚Ä¢ Sub-techniques: 515 samples\n",
      "  ‚Ä¢ Unique technique IDs: 921\n",
      "\n",
      "üìù Sample Training Example:\n",
      "Instruction: Adversaries may inject malicious code into process via Extra Window Memory (EWM) in order to evade p...\n",
      "Technique ID: T1055.011\n",
      "Technique Name: Extra Window Memory Injection\n",
      "Matrix: enterprise\n"
     ]
    }
   ],
   "source": [
    "# Load merged MITRE ATT&CK dataset\n",
    "dataset_path = \"../data/TTP-classification/merged_mitre_attack_dataset.json\"\n",
    "\n",
    "print(\"üìÇ Loading MITRE ATT&CK dataset...\")\n",
    "with open(dataset_path, 'r', encoding='utf-8') as f:\n",
    "    mitre_data = json.load(f)\n",
    "\n",
    "# Extract training samples\n",
    "training_samples = mitre_data['dataset']\n",
    "print(f\"‚úÖ Loaded {len(training_samples):,} training samples\")\n",
    "\n",
    "# Analyze dataset structure\n",
    "print(\"\\nüìä Dataset Analysis:\")\n",
    "matrices = {'enterprise': 0, 'mobile': 0, 'ics': 0}\n",
    "techniques_count = 0\n",
    "sub_techniques_count = 0\n",
    "technique_ids = set()\n",
    "\n",
    "for sample in training_samples:\n",
    "    technique = sample['output']['techniques'][0]\n",
    "    matrix = technique['matrix']\n",
    "    technique_id = technique['id']\n",
    "\n",
    "    matrices[matrix] += 1\n",
    "    technique_ids.add(technique_id)\n",
    "\n",
    "    if '.' in technique_id:\n",
    "        sub_techniques_count += 1\n",
    "    else:\n",
    "        techniques_count += 1\n",
    "\n",
    "print(f\"  ‚Ä¢ Enterprise: {matrices['enterprise']:,} samples\")\n",
    "print(f\"  ‚Ä¢ Mobile: {matrices['mobile']:,} samples\")\n",
    "print(f\"  ‚Ä¢ ICS: {matrices['ics']:,} samples\")\n",
    "print(f\"  ‚Ä¢ Techniques: {techniques_count:,} samples\")\n",
    "print(f\"  ‚Ä¢ Sub-techniques: {sub_techniques_count:,} samples\")\n",
    "print(f\"  ‚Ä¢ Unique technique IDs: {len(technique_ids):,}\")\n",
    "\n",
    "# Show sample data\n",
    "print(\"\\nüìù Sample Training Example:\")\n",
    "sample = training_samples[0]\n",
    "print(f\"Instruction: {sample['instruction'][:100]}...\")\n",
    "print(f\"Technique ID: {sample['output']['techniques'][0]['id']}\")\n",
    "print(f\"Technique Name: {sample['output']['techniques'][0]['name']}\")\n",
    "print(f\"Matrix: {sample['output']['techniques'][0]['matrix']}\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## 3. Prepare Training Data Format\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-23T09:00:56.050632Z",
     "start_time": "2025-08-23T09:00:56.036253Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Formatting training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 921/921 [00:00<00:00, 152132.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Formatted 921 training samples\n",
      "\n",
      "üìù Formatted Training Example:\n",
      "<|im_start|>system\n",
      "You are a cybersecurity expert specializing in MITRE ATT&CK framework. Your task is to analyze threat intelligence descriptions and identify the corresponding MITRE ATT&CK techniques.\n",
      "\n",
      "Given a description of adversary behavior, identify the most relevant MITRE ATT&CK technique and provide:\n",
      "1. Technique ID (e.g., T1055.011)\n",
      "2. Technique Name\n",
      "3. Matrix (enterprise/mobile/ics)\n",
      "\n",
      "Respond in JSON format.<|im_end|>\n",
      "<|im_start|>user\n",
      "Analyze this threat behavior and identify the MITRE ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def format_training_sample(sample: Dict[str, Any]) -> Dict[str, str]:\n",
    "    \"\"\"\n",
    "    Format training sample for instruction tuning\n",
    "\n",
    "    Input format:\n",
    "    {\n",
    "        \"instruction\": \"Adversary behavior description...\",\n",
    "        \"output\": {\n",
    "            \"techniques\": [{\n",
    "                \"id\": \"T1055.011\",\n",
    "                \"name\": \"Extra Window Memory Injection\",\n",
    "                \"description\": \"...\",\n",
    "                \"matrix\": \"enterprise\"\n",
    "            }]\n",
    "        }\n",
    "    }\n",
    "\n",
    "    Output format for instruction tuning:\n",
    "    {\n",
    "        \"text\": \"<|im_start|>system\\nYou are a cybersecurity expert...\\n<|im_end|>\\n<|im_start|>user\\n...\\n<|im_end|>\\n<|im_start|>assistant\\n...\\n<|im_end|>\"\n",
    "    }\n",
    "    \"\"\"\n",
    "    instruction = sample['instruction']\n",
    "    technique = sample['output']['techniques'][0]\n",
    "\n",
    "    # Create system prompt\n",
    "    system_prompt = \"\"\"You are a cybersecurity expert specializing in MITRE ATT&CK framework. Your task is to analyze threat intelligence descriptions and identify the corresponding MITRE ATT&CK techniques.\n",
    "\n",
    "Given a description of adversary behavior, identify the most relevant MITRE ATT&CK technique and provide:\n",
    "1. Technique ID (e.g., T1055.011)\n",
    "2. Technique Name\n",
    "3. Matrix (enterprise/mobile/ics)\n",
    "\n",
    "Respond in JSON format.\"\"\"\n",
    "\n",
    "    # Create user input\n",
    "    user_input = f\"Analyze this threat behavior and identify the MITRE ATT&CK technique:\\n\\n{instruction}\"\n",
    "\n",
    "    # Create assistant response\n",
    "    assistant_response = json.dumps({\n",
    "        \"technique_id\": technique['id'],\n",
    "        \"technique_name\": technique['name'],\n",
    "        \"matrix\": technique['matrix'],\n",
    "        \"description\": technique['description']\n",
    "    }, ensure_ascii=False)\n",
    "\n",
    "    # Format for Qwen chat template\n",
    "    formatted_text = f\"\"\"<|im_start|>system\n",
    "{system_prompt}<|im_end|>\n",
    "<|im_start|>user\n",
    "{user_input}<|im_end|>\n",
    "<|im_start|>assistant\n",
    "{assistant_response}<|im_end|>\"\"\"\n",
    "\n",
    "    return {\"text\": formatted_text}\n",
    "\n",
    "# Format all training samples\n",
    "print(\"üîÑ Formatting training data...\")\n",
    "formatted_samples = []\n",
    "for sample in tqdm(training_samples):\n",
    "    formatted_sample = format_training_sample(sample)\n",
    "    formatted_samples.append(formatted_sample)\n",
    "\n",
    "print(f\"‚úÖ Formatted {len(formatted_samples):,} training samples\")\n",
    "\n",
    "# Show formatted example\n",
    "print(\"\\nüìù Formatted Training Example:\")\n",
    "print(formatted_samples[0]['text'][:500] + \"...\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## 4. Setup Qwen Model and Tokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-23T09:01:17.262943Z",
     "start_time": "2025-08-23T09:00:56.078959Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ Setting up model: Qwen/Qwen2.5-1.5B-Instruct\n",
      "üîß Using device: mps\n",
      "üìù Loading tokenizer...\n",
      "‚úÖ Tokenizer loaded\n",
      "üìä Vocab size: 151,665\n",
      "üîë Special tokens: {'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}\n",
      "ü§ñ Loading model...\n",
      "‚úÖ Model loaded\n",
      "üìä Model parameters: 1,543,714,304\n",
      "üéØ Trainable parameters: 1,543,714,304\n"
     ]
    }
   ],
   "source": [
    "# Model configuration\n",
    "MODEL_NAME = \"Qwen/Qwen2.5-1.5B-Instruct\"\n",
    "MAX_LENGTH = 2048\n",
    "BATCH_SIZE = 4\n",
    "LEARNING_RATE = 2e-5\n",
    "NUM_EPOCHS = 3\n",
    "WARMUP_STEPS = 100\n",
    "\n",
    "print(f\"ü§ñ Setting up model: {MODEL_NAME}\")\n",
    "\n",
    "import torch\n",
    "# Setup device\n",
    "# Setup device ∆∞u ti√™n: CUDA > MPS > CPU\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(f\"üîß Using device: {device}\")\n",
    "# Load tokenizer\n",
    "print(\"üìù Loading tokenizer...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    trust_remote_code=True,\n",
    "    padding_side=\"right\"\n",
    ")\n",
    "\n",
    "# Add padding token if not exists\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    print(\"üîß Set pad_token = eos_token\")\n",
    "\n",
    "print(f\"‚úÖ Tokenizer loaded\")\n",
    "print(f\"üìä Vocab size: {len(tokenizer):,}\")\n",
    "print(f\"üîë Special tokens: {tokenizer.special_tokens_map}\")\n",
    "\n",
    "# Load model\n",
    "print(\"ü§ñ Loading model...\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    trust_remote_code=True,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\",\n",
    "    low_cpu_mem_usage=True\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Model loaded\")\n",
    "print(f\"üìä Model parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "print(f\"üéØ Trainable parameters: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## 5. Create Dataset and Data Loaders\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-23T09:01:18.162798Z",
     "start_time": "2025-08-23T09:01:17.414755Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Creating train/validation split...\n",
      "üìö Training samples: 828\n",
      "üîç Validation samples: 93\n",
      "üîÑ Creating datasets...\n",
      "üî§ Tokenizing datasets...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9177f2fdb29f4bdf8c180f9264e84a3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing train data:   0%|          | 0/828 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf3ce04e99fc4d8fa633bc878a3a2a76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing validation data:   0%|          | 0/93 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Datasets prepared\n",
      "üìä Train dataset: 828 samples\n",
      "üìä Validation dataset: 93 samples\n",
      "\n",
      "üìù Sample tokenization:\n",
      "Input IDs length: 2048\n",
      "Attention mask length: 2048\n",
      "Labels length: 2048\n"
     ]
    }
   ],
   "source": [
    "def tokenize_function(examples):\n",
    "    \"\"\"\n",
    "    Tokenize training examples\n",
    "    \"\"\"\n",
    "    # Tokenize the text\n",
    "    tokenized = tokenizer(\n",
    "        examples[\"text\"],\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",  # S·ª¨A L·ªñI: Pad to max length\n",
    "        max_length=MAX_LENGTH,\n",
    "        return_tensors=None\n",
    "    )\n",
    "\n",
    "    # For causal language modeling, labels are the same as input_ids\n",
    "    tokenized[\"labels\"] = tokenized[\"input_ids\"].copy()\n",
    "\n",
    "    return tokenized\n",
    "\n",
    "# Create train/validation split\n",
    "print(\"üìä Creating train/validation split...\")\n",
    "train_samples, val_samples = train_test_split(\n",
    "    formatted_samples,\n",
    "    test_size=0.1,\n",
    "    random_state=42,\n",
    "    stratify=[sample['text'].split('\"matrix\": \"')[1].split('\"')[0] for sample in formatted_samples]\n",
    ")\n",
    "\n",
    "print(f\"üìö Training samples: {len(train_samples):,}\")\n",
    "print(f\"üîç Validation samples: {len(val_samples):,}\")\n",
    "\n",
    "# Create HuggingFace datasets\n",
    "print(\"üîÑ Creating datasets...\")\n",
    "train_dataset = Dataset.from_list(train_samples)\n",
    "val_dataset = Dataset.from_list(val_samples)\n",
    "\n",
    "# Tokenize datasets\n",
    "print(\"üî§ Tokenizing datasets...\")\n",
    "train_dataset = train_dataset.map(\n",
    "    tokenize_function,\n",
    "    batched=True,\n",
    "    remove_columns=[\"text\"],\n",
    "    desc=\"Tokenizing train data\"\n",
    ")\n",
    "\n",
    "val_dataset = val_dataset.map(\n",
    "    tokenize_function,\n",
    "    batched=True,\n",
    "    remove_columns=[\"text\"],\n",
    "    desc=\"Tokenizing validation data\"\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Datasets prepared\")\n",
    "print(f\"üìä Train dataset: {len(train_dataset):,} samples\")\n",
    "print(f\"üìä Validation dataset: {len(val_dataset):,} samples\")\n",
    "\n",
    "# Check tokenization\n",
    "sample_tokens = train_dataset[0]\n",
    "print(f\"\\nüìù Sample tokenization:\")\n",
    "print(f\"Input IDs length: {len(sample_tokens['input_ids'])}\")\n",
    "print(f\"Attention mask length: {len(sample_tokens['attention_mask'])}\")\n",
    "print(f\"Labels length: {len(sample_tokens['labels'])}\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## 6. Setup Training Configuration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-23T09:01:18.246920Z",
     "start_time": "2025-08-23T09:01:18.225848Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÅ Output directory: ../models/qwen-ttp-classification-2025-08-23_16-01-18\n",
      "‚úÖ Training arguments configured\n",
      "üéØ Batch size: 4\n",
      "üìà Learning rate: 2e-05\n",
      "üîÑ Epochs: 3\n",
      "üî• FP16: True\n",
      "üíæ Gradient checkpointing: True\n",
      "‚úÖ Data collator configured\n"
     ]
    }
   ],
   "source": [
    "# Create output directory\n",
    "timestamp = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "output_dir = f\"../models/qwen-ttp-classification-{timestamp}\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "print(f\"üìÅ Output directory: {output_dir}\")\n",
    "\n",
    "# Training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    overwrite_output_dir=True,\n",
    "\n",
    "    # Training parameters\n",
    "    num_train_epochs=NUM_EPOCHS,\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    per_device_eval_batch_size=BATCH_SIZE,\n",
    "    gradient_accumulation_steps=1,\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    weight_decay=0.01,\n",
    "    warmup_steps=WARMUP_STEPS,\n",
    "\n",
    "    # Optimization\n",
    "    fp16=True,\n",
    "    dataloader_pin_memory=False,\n",
    "    gradient_checkpointing=True,\n",
    "\n",
    "    # Logging and saving\n",
    "    logging_dir=f\"{output_dir}/logs\",\n",
    "    logging_steps=10,\n",
    "    save_steps=100,\n",
    "    save_total_limit=3,\n",
    "    eval_steps=100,\n",
    "    eval_strategy=\"steps\",  # FIXED: was evaluation_strategy\n",
    "\n",
    "    # Other settings\n",
    "    remove_unused_columns=False,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    "    greater_is_better=False,\n",
    "\n",
    "    # Report\n",
    "    report_to=None,  # Disable wandb/tensorboard\n",
    "    run_name=f\"qwen-ttp-classification-{timestamp}\"\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Training arguments configured\")\n",
    "print(f\"üéØ Batch size: {BATCH_SIZE}\")\n",
    "print(f\"üìà Learning rate: {LEARNING_RATE}\")\n",
    "print(f\"üîÑ Epochs: {NUM_EPOCHS}\")\n",
    "print(f\"üî• FP16: {training_args.fp16}\")\n",
    "print(f\"üíæ Gradient checkpointing: {training_args.gradient_checkpointing}\")\n",
    "\n",
    "# Data collator\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer,\n",
    "    mlm=False,  # No masking for causal LM\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Data collator configured\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## 7. Initialize Trainer and Start Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-23T09:01:18.335548Z",
     "start_time": "2025-08-23T09:01:18.255180Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß Initializing MPS-compatible training...\n",
      "üßπ MPS cache cleared\n",
      "üìÅ Output: ../models/qwen-ttp-mps-2025-08-23_16-01-18\n",
      "‚úÖ Configuration created!\n",
      "üî• FP16: False (ph·∫£i False)\n",
      "üçé BF16: False (ph·∫£i False)\n",
      "\n",
      "üèÉ‚Äç‚ôÇÔ∏è Creating trainer...\n",
      "‚úÖ Trainer initialized successfully!\n",
      "üçé Ready for MPS training!\n",
      "üìä Batch size: 2\n",
      "üîÑ Effective batch: 4 (v·ªõi gradient accumulation)\n",
      "üìà Learning rate: 2e-05\n",
      "\n",
      "üöÄ Ready to train! Run: trainer.train()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/lt/y_3sh6vn2mb68907rlw4xvww0000gn/T/ipykernel_59080/224522789.py:81: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    }
   ],
   "source": [
    "# ‚úÖ CODE ƒê√É S·ª¨A HO√ÄN CH·ªàNH CHO MPS (APPLE SILICON)\n",
    "print(\"üîß Initializing MPS-compatible training...\")\n",
    "\n",
    "import torch\n",
    "from transformers import TrainingArguments, Trainer, DataCollatorForLanguageModeling\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "# Clear memory\n",
    "if torch.backends.mps.is_available():\n",
    "    torch.mps.empty_cache()\n",
    "    print(\"üßπ MPS cache cleared\")\n",
    "\n",
    "# Configuration\n",
    "MODEL_NAME = \"Qwen/Qwen2.5-7B-Instruct\"\n",
    "BATCH_SIZE = 2  # Smaller for MPS\n",
    "LEARNING_RATE = 2e-5\n",
    "NUM_EPOCHS = 3\n",
    "WARMUP_STEPS = 100\n",
    "\n",
    "# Create output directory\n",
    "timestamp = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "output_dir = f\"../models/qwen-ttp-mps-{timestamp}\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "print(f\"üìÅ Output: {output_dir}\")\n",
    "\n",
    "# ‚úÖ MPS-COMPATIBLE TrainingArguments (S·ª¨A L·ªñI)\n",
    "training_args_mps = TrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    overwrite_output_dir=True,\n",
    "\n",
    "    # Training params\n",
    "    num_train_epochs=NUM_EPOCHS,\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    per_device_eval_batch_size=BATCH_SIZE,\n",
    "    gradient_accumulation_steps=2,  # TƒÉng ƒë·ªÉ b√π ƒë·∫Øp batch nh·ªè\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    weight_decay=0.01,\n",
    "    warmup_steps=WARMUP_STEPS,\n",
    "\n",
    "    # ‚ö†Ô∏è QUAN TR·ªåNG: MPS settings\n",
    "    fp16=False,              # PH·∫¢I False cho MPS\n",
    "    bf16=False,              # PH·∫¢I False cho MPS\n",
    "    dataloader_pin_memory=False,\n",
    "    gradient_checkpointing=True,\n",
    "\n",
    "    # Logging\n",
    "    logging_steps=10,\n",
    "    save_steps=100,\n",
    "    eval_steps=100,\n",
    "    eval_strategy=\"steps\",   # S·ª¨A: kh√¥ng ph·∫£i evaluation_strategy\n",
    "    save_total_limit=3,\n",
    "\n",
    "    # Evaluation\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    "    greater_is_better=False,\n",
    "\n",
    "    # Disable external services\n",
    "    report_to=None,\n",
    "    dataloader_num_workers=0,  # Single thread cho MPS\n",
    ")\n",
    "\n",
    "# ‚úÖ Data collator (S·ª¨A L·ªñI)\n",
    "data_collator_mps = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer,\n",
    "    mlm=False\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Configuration created!\")\n",
    "print(f\"üî• FP16: {training_args_mps.fp16} (ph·∫£i False)\")\n",
    "print(f\"üçé BF16: {training_args_mps.bf16} (ph·∫£i False)\")\n",
    "\n",
    "# ‚úÖ Initialize Trainer (S·ª¨A L·ªñI - KH√îNG c√≥ accelerator argument)\n",
    "print(\"\\nüèÉ‚Äç‚ôÇÔ∏è Creating trainer...\")\n",
    "\n",
    "os.environ[\"ACCELERATE_MIXED_PRECISION\"] = \"no\"\n",
    "os.environ[\"ACCELERATE_DISABLE_RICH\"] = \"1\"\n",
    "\n",
    "# Kh·ªüi t·∫°o trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args_mps,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator_mps,\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Trainer initialized successfully!\")\n",
    "print(\"üçé Ready for MPS training!\")\n",
    "print(f\"üìä Batch size: {BATCH_SIZE}\")\n",
    "print(f\"üîÑ Effective batch: {BATCH_SIZE * 2} (v·ªõi gradient accumulation)\")\n",
    "print(f\"üìà Learning rate: {LEARNING_RATE}\")\n",
    "\n",
    "# ‚úÖ B√¢y gi·ªù c√≥ th·ªÉ b·∫Øt ƒë·∫ßu training\n",
    "print(\"\\nüöÄ Ready to train! Run: trainer.train()\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## 8. Model Evaluation\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## 9. Test Model Inference\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-23T09:01:38.129776Z",
     "start_time": "2025-08-23T09:01:18.344196Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß™ Testing model inference...\n",
      "\n",
      "üìù Test Case 1:\n",
      "Input: Adversaries may inject malicious code into processes in order to evade process-based defenses or elevate privileges.\n",
      "Output: system\n",
      "You are a cybersecurity expert specializing in MITRE ATT&CK framework. Your task is to analyze threat intelligence descriptions and identify the corresponding MITRE ATT&CK techniques.\n",
      "\n",
      "Given a description of adversary behavior, identify the most relevant MITRE ATT&CK technique and provide:\n",
      "1. Technique ID (e.g., T1055.011)\n",
      "2. Technique Name\n",
      "3. Matrix (enterprise/mobile/ics)\n",
      "\n",
      "Respond in JSON format.\n",
      "user\n",
      "Analyze this threat behavior and identify the MITRE ATT&CK technique:\n",
      "\n",
      "Adversaries may inject malicious code into processes in order to evade process-based defenses or elevate privileges.\n",
      "assistant\n",
      "```json\n",
      "{\n",
      "  \"TechniqueID\": \"T1078\",\n",
      "  \"TechniqueName\": \"Elevate Privileges via Process Injection\",\n",
      "  \"Matrix\": \"enterprise\"\n",
      "}\n",
      "```\n",
      "\n",
      "Explanation:\n",
      "- **TechniqueID**: `T1078` - This technique involves elevating privileges by injecting malicious code into legitimate processes.\n",
      "- **TechniqueName**: `Elevate Privileges via Process Injection` - This describes how adversaries can manipulate system processes to gain elevated privileges without directly compromising the integrity of the operating system.\n",
      "- **Matrix**: `enterprise` - This indicates that this technique is applicable across enterprise environments where traditional security measures might be less effective due to the nature of process injection.\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "üìù Test Case 2:\n",
      "Input: Attackers send phishing emails with malicious attachments to gain initial access to the target system.\n",
      "Output: system\n",
      "You are a cybersecurity expert specializing in MITRE ATT&CK framework. Your task is to analyze threat intelligence descriptions and identify the corresponding MITRE ATT&CK techniques.\n",
      "\n",
      "Given a description of adversary behavior, identify the most relevant MITRE ATT&CK technique and provide:\n",
      "1. Technique ID (e.g., T1055.011)\n",
      "2. Technique Name\n",
      "3. Matrix (enterprise/mobile/ics)\n",
      "\n",
      "Respond in JSON format.\n",
      "user\n",
      "Analyze this threat behavior and identify the MITRE ATT&CK technique:\n",
      "\n",
      "Attackers send phishing emails with malicious attachments to gain initial access to the target system.\n",
      "assistant\n",
      "```json\n",
      "{\n",
      "  \"TechniqueID\": \"T1047\",\n",
      "  \"TechniqueName\": \"Create Phishing Campaigns\",\n",
      "  \"Matrix\": \"enterprise\"\n",
      "}\n",
      "```\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "üìù Test Case 3:\n",
      "Input: The malware establishes persistence by creating scheduled tasks that execute at system startup.\n",
      "Output: system\n",
      "You are a cybersecurity expert specializing in MITRE ATT&CK framework. Your task is to analyze threat intelligence descriptions and identify the corresponding MITRE ATT&CK techniques.\n",
      "\n",
      "Given a description of adversary behavior, identify the most relevant MITRE ATT&CK technique and provide:\n",
      "1. Technique ID (e.g., T1055.011)\n",
      "2. Technique Name\n",
      "3. Matrix (enterprise/mobile/ics)\n",
      "\n",
      "Respond in JSON format.\n",
      "user\n",
      "Analyze this threat behavior and identify the MITRE ATT&CK technique:\n",
      "\n",
      "The malware establishes persistence by creating scheduled tasks that execute at system startup.\n",
      "assistant\n",
      "```json\n",
      "{\n",
      "  \"TechniqueID\": \"T1078\",\n",
      "  \"TechniqueName\": \"Create Scheduled Tasks\",\n",
      "  \"Matrix\": \"enterprise\"\n",
      "}\n",
      "```\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "üìù Test Case 4:\n",
      "Input: Adversaries may abuse elevation control mechanisms to gain higher-level permissions on a system.\n",
      "Output: system\n",
      "You are a cybersecurity expert specializing in MITRE ATT&CK framework. Your task is to analyze threat intelligence descriptions and identify the corresponding MITRE ATT&CK techniques.\n",
      "\n",
      "Given a description of adversary behavior, identify the most relevant MITRE ATT&CK technique and provide:\n",
      "1. Technique ID (e.g., T1055.011)\n",
      "2. Technique Name\n",
      "3. Matrix (enterprise/mobile/ics)\n",
      "\n",
      "Respond in JSON format.\n",
      "user\n",
      "Analyze this threat behavior and identify the MITRE ATT&CK technique:\n",
      "\n",
      "Adversaries may abuse elevation control mechanisms to gain higher-level permissions on a system.\n",
      "assistant\n",
      "```json\n",
      "{\n",
      "  \"TechniqueID\": \"T1078\",\n",
      "  \"TechniqueName\": \"Elevation of Privilege\",\n",
      "  \"Matrix\": \"enterprise\"\n",
      "}\n",
      "```\n",
      "\n",
      "Explanation:\n",
      "- **TechniqueID**: `T1078` corresponds to the MITRE ATT&CK technique for Elevation of Privilege.\n",
      "- **TechniqueName**: This technique involves gaining elevated privileges by exploiting vulnerabilities or misconfigurations that allow an attacker to escalate their access level within a system.\n",
      "- **Matrix**: The technique is categorized under enterprise, which means it applies to both Windows and Linux environments.\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def test_ttp_classification(model, tokenizer, threat_description: str) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Test TTP classification on a threat description\n",
    "    \"\"\"\n",
    "    system_prompt = \"\"\"You are a cybersecurity expert specializing in MITRE ATT&CK framework. Your task is to analyze threat intelligence descriptions and identify the corresponding MITRE ATT&CK techniques.\n",
    "\n",
    "Given a description of adversary behavior, identify the most relevant MITRE ATT&CK technique and provide:\n",
    "1. Technique ID (e.g., T1055.011)\n",
    "2. Technique Name\n",
    "3. Matrix (enterprise/mobile/ics)\n",
    "\n",
    "Respond in JSON format.\"\"\"\n",
    "\n",
    "    user_input = f\"Analyze this threat behavior and identify the MITRE ATT&CK technique:\\n\\n{threat_description}\"\n",
    "\n",
    "    # Format input\n",
    "    prompt = f\"\"\"<|im_start|>system\n",
    "{system_prompt}<|im_end|>\n",
    "<|im_start|>user\n",
    "{user_input}<|im_end|>\n",
    "<|im_start|>assistant\n",
    "\"\"\"\n",
    "\n",
    "    # Tokenize\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=1024)\n",
    "    inputs = {k: v.to(model.device) for k, v in inputs.items()}\n",
    "\n",
    "    # Generate response\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=256,\n",
    "            temperature=0.1,\n",
    "            do_sample=True,\n",
    "            pad_token_id=tokenizer.eos_token_id\n",
    "        )\n",
    "\n",
    "    # Decode response\n",
    "    full_response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    assistant_response = full_response.split(\"<|im_start|>assistant\\n\")[-1]\n",
    "\n",
    "    return {\n",
    "        \"input\": threat_description,\n",
    "        \"response\": assistant_response,\n",
    "        \"full_prompt\": prompt\n",
    "    }\n",
    "\n",
    "# Test examples\n",
    "test_cases = [\n",
    "    \"Adversaries may inject malicious code into processes in order to evade process-based defenses or elevate privileges.\",\n",
    "    \"Attackers send phishing emails with malicious attachments to gain initial access to the target system.\",\n",
    "    \"The malware establishes persistence by creating scheduled tasks that execute at system startup.\",\n",
    "    \"Adversaries may abuse elevation control mechanisms to gain higher-level permissions on a system.\"\n",
    "]\n",
    "\n",
    "print(\"üß™ Testing model inference...\")\n",
    "for i, test_case in enumerate(test_cases, 1):\n",
    "    print(f\"\\nüìù Test Case {i}:\")\n",
    "    print(f\"Input: {test_case}\")\n",
    "\n",
    "    result = test_ttp_classification(model, tokenizer, test_case)\n",
    "    print(f\"Output: {result['response']}\")\n",
    "    print(\"-\" * 80)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## 10. Save Training Summary\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 11. Batch TTP Classification from File and Relationship Analysis\n",
    "\n",
    "This section loads a threat intelligence file, runs batch TTP classification with the (fine-tuned) Qwen model, extracts hash values, and analyzes relationships between:\n",
    "- Threat types (labels/categories in your data)\n",
    "- Techniques (MITRE ATT&CK technique IDs)\n",
    "- Hash values (MD5/SHA1/SHA256)\n",
    "\n",
    "Outputs:\n",
    "- Predictions dataset (`CSV` + `JSONL`)\n",
    "- Relationship edge list (`JSON`)\n",
    "- Knowledge graph export (`.gexf` for Gephi/NetworkX)\n",
    "\n",
    "Notes:\n",
    "- Techniques are labeled strictly by technique `id` (e.g., `T1055.011`).\n",
    "- The loader is schema-flexible; configure field mappings if needed.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-23T09:02:13.034364Z",
     "start_time": "2025-08-23T09:01:38.223102Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Loading records from: ../data/raw/threat_intelligence_multi_source_20250726_231524.json\n",
      "‚úÖ Loaded 5 records\n",
      "üß† Running TTP classification...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:34<00:00,  6.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÑ Saved predictions to: ../models/ttp_batch_analysis_2025-08-23_16-01-38/ttp_predictions.csv and ../models/ttp_batch_analysis_2025-08-23_16-01-38/ttp_predictions.jsonl\n",
      "üï∏Ô∏è Graph exported to: ../models/ttp_batch_analysis_2025-08-23_16-01-38/ttp_relations.gexf\n",
      "üîó Edge list saved to: ../models/ttp_batch_analysis_2025-08-23_16-01-38/ttp_edges.json\n",
      "‚úÖ Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import uuid\n",
    "from datetime import datetime\n",
    "from typing import Dict, Any, List, Tuple, Optional\n",
    "\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ========== Config ==========\n",
    "# Input file with threat intel. You can switch to any structured JSON/JSONL/CSV.\n",
    "INPUT_FILE = \"../data/raw/threat_intelligence_multi_source_20250726_231524.json\"  # adjust if needed\n",
    "# Optional: limit number of records for quick tests\n",
    "MAX_RECORDS: Optional[int] = 5\n",
    "\n",
    "# Field mappings (adjust to your data schema)\n",
    "FIELD_MAP = {\n",
    "    \"id\": [\"id\", \"_id\", \"uuid\"],\n",
    "    \"threat_type\": [\"threat_type\", \"type\", \"category\", \"topic\"],\n",
    "    \"title\": [\"title\", \"headline\"],\n",
    "    \"text\": [\"text\", \"content\", \"description\", \"body\"],\n",
    "    \"hashes\": [\"hashes\", \"artifacts.hashes\", \"ioc.hashes\", \"ioc\"],\n",
    "}\n",
    "\n",
    "# Output directory\n",
    "REL_TIMESTAMP = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "REL_OUT_DIR = f\"../models/ttp_batch_analysis_{REL_TIMESTAMP}\"\n",
    "os.makedirs(REL_OUT_DIR, exist_ok=True)\n",
    "\n",
    "HASH_REGEX = re.compile(r\"\\b([A-Fa-f0-9]{32}|[A-Fa-f0-9]{40}|[A-Fa-f0-9]{64})\\b\")  # MD5|SHA1|SHA256\n",
    "\n",
    "\n",
    "def _coerce_text(raw: Any) -> str:\n",
    "    \"\"\"Coerce list/dict/other into a single plain text string.\"\"\"\n",
    "    if raw is None:\n",
    "        return \"\"\n",
    "    if isinstance(raw, str):\n",
    "        return raw\n",
    "    if isinstance(raw, list):\n",
    "        return \" \".join([str(x) for x in raw if isinstance(x, (str, int, float))])\n",
    "    if isinstance(raw, dict):\n",
    "        return \" \".join([str(v) for v in raw.values() if isinstance(v, (str, int, float))])\n",
    "    return str(raw)\n",
    "\n",
    "def _first_present(d: Dict[str, Any], keys: List[str], default: Any = None):\n",
    "    for k in keys:\n",
    "        # support dotted paths like 'artifacts.hashes'\n",
    "        node = d\n",
    "        valid = True\n",
    "        for part in k.split('.'):\n",
    "            if isinstance(node, dict) and part in node:\n",
    "                node = node[part]\n",
    "            else:\n",
    "                valid = False\n",
    "                break\n",
    "        if valid:\n",
    "            return node\n",
    "    return default\n",
    "\n",
    "\n",
    "def _extract_hashes(record: Dict[str, Any]) -> List[str]:\n",
    "    # Try mapped fields first\n",
    "    hashes_field = _first_present(record, FIELD_MAP[\"hashes\"], default=None)\n",
    "    found: List[str] = []\n",
    "    if isinstance(hashes_field, list):\n",
    "        for x in hashes_field:\n",
    "            if isinstance(x, str) and HASH_REGEX.fullmatch(x):\n",
    "                found.append(x.lower())\n",
    "            elif isinstance(x, dict):\n",
    "                for v in x.values():\n",
    "                    if isinstance(v, str) and HASH_REGEX.fullmatch(v):\n",
    "                        found.append(v.lower())\n",
    "    elif isinstance(hashes_field, dict):\n",
    "        for v in hashes_field.values():\n",
    "            if isinstance(v, str) and HASH_REGEX.fullmatch(v):\n",
    "                found.append(v.lower())\n",
    "            elif isinstance(v, list):\n",
    "                for x in v:\n",
    "                    if isinstance(x, str) and HASH_REGEX.fullmatch(x):\n",
    "                        found.append(x.lower())\n",
    "    # Fallback: scan text (coerce list/dict to string)\n",
    "    raw_text = _first_present(record, FIELD_MAP[\"text\"], default=\"\")\n",
    "    text = _coerce_text(raw_text)\n",
    "    found += [h.lower() for h in HASH_REGEX.findall(text)]\n",
    "    # Normalize unique\n",
    "    uniq = sorted(set(found))\n",
    "    return uniq\n",
    "\n",
    "\n",
    "def _make_prompt(threat_text: str) -> str:\n",
    "    system_prompt = (\n",
    "        \"You are a cybersecurity expert specializing in MITRE ATT&CK framework. \"\n",
    "        \"Your task is to analyze threat intelligence descriptions and identify the corresponding MITRE ATT&CK techniques.\\n\\n\"\n",
    "        \"Given a description of adversary behavior, identify the most relevant MITRE ATT&CK technique and provide:\\n\"\n",
    "        \"1. Technique ID (e.g., T1055.011)\\n\"\n",
    "        \"2. Technique Name\\n\"\n",
    "        \"3. Matrix (enterprise/mobile/ics)\\n\\n\"\n",
    "        \"Respond in JSON format.\"\n",
    "    )\n",
    "    user_input = f\"Analyze this threat behavior and identify the MITRE ATT&CK technique:\\n\\n{threat_text}\"\n",
    "    return (\n",
    "        f\"<|im_start|>system\\n{system_prompt}<|im_end|>\\n\"\n",
    "        f\"<|im_start|>user\\n{user_input}<|im_end|>\\n\"\n",
    "        f\"<|im_start|>assistant\\n\"\n",
    "    )\n",
    "\n",
    "\n",
    "def classify_one(text_value: str) -> Tuple[Optional[str], Optional[str], Optional[str], str]:\n",
    "    \"\"\"Run model inference; return (technique_id, technique_name, matrix, raw_response).\"\"\"\n",
    "    if not text_value or not isinstance(text_value, str):\n",
    "        return None, None, None, \"\"\n",
    "\n",
    "    prompt = _make_prompt(text_value)\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=1024)\n",
    "    inputs = {k: v.to(model.device) for k, v in inputs.items()}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=128,\n",
    "            temperature=0.0,\n",
    "            do_sample=False,\n",
    "            pad_token_id=tokenizer.eos_token_id,\n",
    "        )\n",
    "\n",
    "    full_response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    assistant_response = full_response.split(\"<|im_start|>assistant\\n\")[-1]\n",
    "\n",
    "    # Try to parse JSON\n",
    "    tech_id = tech_name = matrix = None\n",
    "    try:\n",
    "        # Extract JSON block if wrapped\n",
    "        json_match = re.search(r\"\\{[\\s\\S]*\\}\", assistant_response)\n",
    "        if json_match:\n",
    "            data = json.loads(json_match.group(0))\n",
    "        else:\n",
    "            data = json.loads(assistant_response)\n",
    "        tech_id = (data.get(\"technique_id\") or data.get(\"id\") or \"\").strip() or None\n",
    "        tech_name = (data.get(\"technique_name\") or data.get(\"name\") or \"\").strip() or None\n",
    "        matrix = (data.get(\"matrix\") or \"\").strip() or None\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    # Ensure technique id label format\n",
    "    if tech_id and not re.match(r\"^T\\d{4}(?:\\.\\d{3})?$\", tech_id):\n",
    "        tech_id = None\n",
    "\n",
    "    return tech_id, tech_name, matrix, assistant_response\n",
    "\n",
    "\n",
    "def load_records(input_path: str) -> List[Dict[str, Any]]:\n",
    "    if input_path.endswith(\".jsonl\"):\n",
    "        rows = []\n",
    "        with open(input_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            for line in f:\n",
    "                if line.strip():\n",
    "                    rows.append(json.loads(line))\n",
    "        return rows\n",
    "    elif input_path.endswith(\".json\"):\n",
    "        with open(input_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            data = json.load(f)\n",
    "        # try top-level list or known keys\n",
    "        if isinstance(data, list):\n",
    "            return data\n",
    "        for key in [\"data\", \"items\", \"records\", \"dataset\", \"documents\"]:\n",
    "            if key in data and isinstance(data[key], list):\n",
    "                return data[key]\n",
    "        # fallback: single object\n",
    "        return [data]\n",
    "    elif input_path.endswith(\".csv\"):\n",
    "        df = pd.read_csv(input_path)\n",
    "        return df.to_dict(orient=\"records\")\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported file type: {input_path}\")\n",
    "\n",
    "\n",
    "print(f\"üìÇ Loading records from: {INPUT_FILE}\")\n",
    "records = load_records(INPUT_FILE)\n",
    "if MAX_RECORDS is not None:\n",
    "    records = records[:MAX_RECORDS]\n",
    "print(f\"‚úÖ Loaded {len(records)} records\")\n",
    "\n",
    "# Inference\n",
    "results: List[Dict[str, Any]] = []\n",
    "print(\"üß† Running TTP classification...\")\n",
    "for rec in tqdm(records):\n",
    "    rec_id = _first_present(rec, FIELD_MAP[\"id\"], default=str(uuid.uuid4()))\n",
    "    raw_val = _first_present(rec, FIELD_MAP[\"text\"], default=\"\")\n",
    "    text_val = _coerce_text(raw_val)\n",
    "    threat_type = _first_present(rec, FIELD_MAP[\"threat_type\"], default=None)\n",
    "    title = _first_present(rec, FIELD_MAP[\"title\"], default=None)\n",
    "\n",
    "    tech_id, tech_name, matrix, raw_resp = classify_one(text_val)\n",
    "    hashes = _extract_hashes(rec)\n",
    "\n",
    "    results.append({\n",
    "        \"record_id\": rec_id,\n",
    "        \"title\": title,\n",
    "        \"threat_type\": threat_type,\n",
    "        \"text\": text_val,\n",
    "        \"technique_id\": tech_id,      # label: technique ID\n",
    "        \"technique_name\": tech_name,\n",
    "        \"matrix\": matrix,\n",
    "        \"hashes\": hashes,\n",
    "        \"raw_response\": raw_resp,\n",
    "    })\n",
    "\n",
    "# Save predictions\n",
    "pred_df = pd.DataFrame(results)\n",
    "pred_csv = os.path.join(REL_OUT_DIR, \"ttp_predictions.csv\")\n",
    "pred_jsonl = os.path.join(REL_OUT_DIR, \"ttp_predictions.jsonl\")\n",
    "pred_df.to_csv(pred_csv, index=False)\n",
    "with open(pred_jsonl, \"w\", encoding=\"utf-8\") as f:\n",
    "    for row in results:\n",
    "        f.write(json.dumps(row, ensure_ascii=False) + \"\\n\")\n",
    "print(f\"üìÑ Saved predictions to: {pred_csv} and {pred_jsonl}\")\n",
    "\n",
    "# Build relationships graph: ThreatType -> TechniqueID, Hash -> TechniqueID\n",
    "G = nx.DiGraph()\n",
    "\n",
    "for row in results:\n",
    "    rec_id = row[\"record_id\"]\n",
    "    threat_type = row.get(\"threat_type\")\n",
    "    technique_id = row.get(\"technique_id\")\n",
    "    tech_name = row.get(\"technique_name\")\n",
    "    matrix = row.get(\"matrix\")\n",
    "    hashes = row.get(\"hashes\") or []\n",
    "\n",
    "    # Nodes\n",
    "    if threat_type:\n",
    "        G.add_node((\"threat_type\", threat_type), label=\"threat_type\", name=threat_type)\n",
    "    if technique_id:\n",
    "        G.add_node((\"technique\", technique_id), label=\"technique\", name=technique_id, tech_name=tech_name, matrix=matrix)\n",
    "    for h in hashes:\n",
    "        G.add_node((\"hash\", h), label=\"hash\", name=h)\n",
    "\n",
    "    # Edges\n",
    "    if threat_type and technique_id:\n",
    "        G.add_edge((\"threat_type\", threat_type), (\"technique\", technique_id), relation=\"HAS_TECHNIQUE\")\n",
    "    for h in hashes:\n",
    "        if technique_id:\n",
    "            G.add_edge((\"hash\", h), (\"technique\", technique_id), relation=\"INDICATES_TECHNIQUE\")\n",
    "        # Optionally link record->hash for provenance\n",
    "        G.add_edge((\"hash\", h), (\"threat_type\", threat_type) if threat_type else (\"record\", rec_id), relation=\"ASSOCIATED_WITH\")\n",
    "\n",
    "# Export graph\n",
    "gexf_path = os.path.join(REL_OUT_DIR, \"ttp_relations.gexf\")\n",
    "nx.write_gexf(G, gexf_path)\n",
    "print(f\"üï∏Ô∏è Graph exported to: {gexf_path}\")\n",
    "\n",
    "# Export edge list JSON\n",
    "edges = [\n",
    "    {\n",
    "        \"source_type\": s[0],\n",
    "        \"source\": s[1],\n",
    "        \"target_type\": t[0],\n",
    "        \"target\": t[1],\n",
    "        \"relation\": data.get(\"relation\"),\n",
    "    }\n",
    "    for s, t, data in G.edges(data=True)\n",
    "]\n",
    "edges_path = os.path.join(REL_OUT_DIR, \"ttp_edges.json\")\n",
    "with open(edges_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(edges, f, indent=2, ensure_ascii=False)\n",
    "print(f\"üîó Edge list saved to: {edges_path}\")\n",
    "\n",
    "print(\"‚úÖ Done.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "### 11.1 Relationship summaries (counts)\n",
    "\n",
    "This cell summarizes co-occurrences:\n",
    "- Threat type ‚Üî Technique ID counts\n",
    "- Hash ‚Üî Technique ID counts\n",
    "\n",
    "It saves CSV summaries alongside the predictions and graph.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-23T09:02:13.134501Z",
     "start_time": "2025-08-23T09:02:13.108730Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÑ Saved: ../models/ttp_batch_analysis_2025-08-23_16-01-38/summary_threattype_technique.csv\n",
      "üìÑ Saved: ../models/ttp_batch_analysis_2025-08-23_16-01-38/summary_hash_technique.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>threat_type</th>\n",
       "      <th>technique_id</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [threat_type, technique_id, count]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hash</th>\n",
       "      <th>technique_id</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [hash, technique_id, count]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Summaries\n",
    "from collections import Counter\n",
    "\n",
    "# Threat type ‚Üî Technique ID\n",
    "pair_counts_tt = Counter()\n",
    "for row in results:\n",
    "    threat_type = row.get(\"threat_type\")\n",
    "    technique_id = row.get(\"technique_id\")\n",
    "    if threat_type and technique_id:\n",
    "        pair_counts_tt[(threat_type, technique_id)] += 1\n",
    "\n",
    "summary_tt = pd.DataFrame(\n",
    "    [(tt, tid, c) for (tt, tid), c in pair_counts_tt.items()],\n",
    "    columns=[\"threat_type\", \"technique_id\", \"count\"],\n",
    ").sort_values(\"count\", ascending=False)\n",
    "\n",
    "# Hash ‚Üî Technique ID\n",
    "pair_counts_ht = Counter()\n",
    "for row in results:\n",
    "    technique_id = row.get(\"technique_id\")\n",
    "    for h in row.get(\"hashes\") or []:\n",
    "        if technique_id:\n",
    "            pair_counts_ht[(h, technique_id)] += 1\n",
    "\n",
    "summary_ht = pd.DataFrame(\n",
    "    [(h, tid, c) for (h, tid), c in pair_counts_ht.items()],\n",
    "    columns=[\"hash\", \"technique_id\", \"count\"],\n",
    ").sort_values(\"count\", ascending=False)\n",
    "\n",
    "# Save\n",
    "summary_tt_csv = os.path.join(REL_OUT_DIR, \"summary_threattype_technique.csv\")\n",
    "summary_ht_csv = os.path.join(REL_OUT_DIR, \"summary_hash_technique.csv\")\n",
    "summary_tt.to_csv(summary_tt_csv, index=False)\n",
    "summary_ht.to_csv(summary_ht_csv, index=False)\n",
    "\n",
    "print(f\"üìÑ Saved: {summary_tt_csv}\")\n",
    "print(f\"üìÑ Saved: {summary_ht_csv}\")\n",
    "\n",
    "# Display top rows\n",
    "display(summary_tt.head(20))\n",
    "display(summary_ht.head(20))\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "### 11.2 Build extended relationships JSON (per-record)\n",
    "\n",
    "This step:\n",
    "- Extracts multiple techniques from `content` using the model (top-k list)\n",
    "- Creates `extended_relationships` as requested\n",
    "- Produces a JSON file under `data/TTP-classification/`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-23T09:02:13.265788Z",
     "start_time": "2025-08-23T09:02:13.262508Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOP_K overridden to: 3\n"
     ]
    }
   ],
   "source": [
    "# Quick test overrides\n",
    "TOP_K = 3  # limit techniques per record\n",
    "print(f\"TOP_K overridden to: {TOP_K}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-23T09:07:57.917617Z",
     "start_time": "2025-08-23T09:04:32.472374Z"
    }
   },
   "source": [
    "from typing import Iterable\n",
    "\n",
    "# Settings for multi-technique extraction\n",
    "TOP_K = 6  # max techniques to extract per record\n",
    "SAVE_JSON_PATH = \"../data/TTP-classification/extended_relationships_output.json\"\n",
    "\n",
    "# Local fallback in case _coerce_text wasn't executed in earlier cells\n",
    "try:\n",
    "    _coerce_text\n",
    "except NameError:\n",
    "    def _coerce_text(raw):\n",
    "        if raw is None:\n",
    "            return \"\"\n",
    "        if isinstance(raw, str):\n",
    "            return raw\n",
    "        if isinstance(raw, list):\n",
    "            return \" \".join(str(x) for x in raw if isinstance(x, (str, int, float)))\n",
    "        if isinstance(raw, dict):\n",
    "            return \" \".join(str(v) for v in raw.values() if isinstance(v, (str, int, float)))\n",
    "        return str(raw)\n",
    "\n",
    "def classify_multiple_techniques(threat_text: str, top_k: int = TOP_K) -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Query the model to extract up to top_k techniques from text.\n",
    "    Returns list of {id, name, description, matrix} using technique ids as labels.\n",
    "    \"\"\"\n",
    "    if not threat_text or not isinstance(threat_text, str):\n",
    "        return []\n",
    "\n",
    "    system_prompt = (\n",
    "        \"You are a cybersecurity expert specializing in MITRE ATT&CK framework. \"\n",
    "        \"Read the text and return a JSON object with a 'techniques' array listing up to N relevant techniques. \"\n",
    "        \"Each technique must include: id, name, description, matrix. Use MITRE technique ids strictly (e.g., T1218, T1218.011).\"\n",
    "    )\n",
    "    user_input = (\n",
    "        \"Extract up to N MITRE ATT&CK techniques from the following content. \"\n",
    "        f\"N={top_k}. Return JSON with key 'techniques'.\\n\\nContent:\\n{threat_text}\"\n",
    "    )\n",
    "\n",
    "    prompt = (\n",
    "        f\"<|im_start|>system\\n{system_prompt}<|im_end|>\\n\"\n",
    "        f\"<|im_start|>user\\n{user_input}<|im_end|>\\n\"\n",
    "        f\"<|im_start|>assistant\\n\"\n",
    "    )\n",
    "\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=2048)\n",
    "    inputs = {k: v.to(model.device) for k, v in inputs.items()}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=512,\n",
    "            do_sample=False,  # T·∫Øt sampling\n",
    "            num_beams=1,      # S·ª≠ d·ª•ng greedy decoding\n",
    "            pad_token_id=tokenizer.eos_token_id,\n",
    "        )\n",
    "\n",
    "    resp = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    content = resp.split(\"<|im_start|>assistant\\n\")[-1]\n",
    "\n",
    "    # Parse JSON\n",
    "    techniques: List[Dict[str, Any]] = []\n",
    "    try:\n",
    "        json_match = re.search(r\"\\{[\\s\\S]*\\}\", content)\n",
    "        data = json.loads(json_match.group(0) if json_match else content)\n",
    "        items = data.get(\"techniques\") or data\n",
    "        if isinstance(items, dict) and \"techniques\" in items:\n",
    "            items = items[\"techniques\"]\n",
    "        if isinstance(items, list):\n",
    "            for t in items[:top_k]:\n",
    "                tid = (t.get(\"id\") or t.get(\"technique_id\") or \"\").strip()\n",
    "                if not re.match(r\"^T\\d{4}(?:\\.\\d{3})?$\", tid):\n",
    "                    continue\n",
    "                techniques.append({\n",
    "                    \"id\": tid,\n",
    "                    \"name\": t.get(\"name\"),\n",
    "                    \"description\": t.get(\"description\"),\n",
    "                    \"matrix\": t.get(\"matrix\"),\n",
    "                })\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    # Deduplicate by id\n",
    "    seen = set()\n",
    "    uniq: List[Dict[str, Any]] = []\n",
    "    for t in techniques:\n",
    "        if t[\"id\"] in seen:\n",
    "            continue\n",
    "        seen.add(t[\"id\"])\n",
    "        uniq.append(t)\n",
    "    return uniq\n",
    "\n",
    "def build_extended_relationships(record: Dict[str, Any], techniques: List[Dict[str, Any]]) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Construct extended_relationships.relationships using the requested format:\n",
    "    [ [subject, predicate, object], ... ]\n",
    "    - Map high-level threat types/entities to technique ids\n",
    "    - Also include 'associated_with' links from the main threat label to all techniques\n",
    "    \"\"\"\n",
    "    title = _first_present(record, FIELD_MAP[\"title\"], default=None)\n",
    "    link = record.get(\"link\") or record.get(\"url\")\n",
    "    raw_content = _first_present(record, FIELD_MAP[\"text\"], default=\"\")\n",
    "    content_text = _coerce_text(raw_content)\n",
    "\n",
    "    # Use existing entity extraction section if present\n",
    "    extraction = record.get(\"extraction\") or {}\n",
    "    ents = extraction.get(\"entities\") or []\n",
    "\n",
    "    # Collect subjects from entities and threat_type field\n",
    "    subjects: List[str] = []\n",
    "    if ents:\n",
    "        for item in ents:\n",
    "            if isinstance(item, (list, tuple)) and len(item) >= 2:\n",
    "                subjects.append(str(item[0]))\n",
    "    tt = _first_present(record, FIELD_MAP[\"threat_type\"], default=None)\n",
    "    if tt:\n",
    "        subjects.append(str(tt))\n",
    "\n",
    "    subjects = [s for s in {s.strip(): None for s in subjects}.keys() if s]\n",
    "\n",
    "    # Relationships\n",
    "    rels: List[List[str]] = []\n",
    "    # Example mapping rules: ransomware uses T1486 etc. We simply create generic relations here.\n",
    "    for subj in subjects:\n",
    "        for t in techniques:\n",
    "            rels.append([subj, \"associated_with\", t[\"id\"]])\n",
    "    # Add specific 'uses' if subject text suggests usage verbs in content\n",
    "    verbs = [\"use\", \"uses\", \"abuse\", \"abuses\", \"leverage\", \"leverages\", \"employ\", \"employs\"]\n",
    "    text_lower = content_text.lower() if isinstance(content_text, str) else _coerce_text(content_text).lower()\n",
    "    if any(v in text_lower for v in verbs):\n",
    "        for subj in subjects:\n",
    "            for t in techniques:\n",
    "                rels.append([subj, \"uses\", t[\"id\"]])\n",
    "\n",
    "    return {\n",
    "        \"title\": title,\n",
    "        \"link\": link,\n",
    "        \"content\": content_text,\n",
    "        \"extraction\": extraction or None,\n",
    "        \"ttp_classification\": {\n",
    "            \"instruction\": None,\n",
    "            \"input\": None,\n",
    "            \"output\": {\"techniques\": techniques},\n",
    "        },\n",
    "        \"extended_relationships\": {\"relationships\": rels},\n",
    "    }\n",
    "\n",
    "\n",
    "print(\"üß© Building extended relationships per record...\")\n",
    "extended_docs: List[Dict[str, Any]] = []\n",
    "for rec in tqdm(records):\n",
    "    raw_content = _first_present(rec, FIELD_MAP[\"text\"], default=\"\")\n",
    "    content_text = _coerce_text(raw_content)\n",
    "    techniques = classify_multiple_techniques(content_text, top_k=TOP_K)\n",
    "    extended = build_extended_relationships(rec, techniques)\n",
    "    extended_docs.append(extended)\n",
    "\n",
    "# Save to data/TTP-classification\n",
    "os.makedirs(\"../data/TTP-classification\", exist_ok=True)\n",
    "with open(SAVE_JSON_PATH, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(extended_docs, f, ensure_ascii=False, indent=2)\n",
    "print(f\"üíæ Extended relationships saved to: {SAVE_JSON_PATH}\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß© Building extended relationships per record...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [03:25<00:00, 41.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Extended relationships saved to: ../data/TTP-classification/extended_relationships_output.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 38
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-23T09:07:58.168192Z",
     "start_time": "2025-08-23T09:07:58.106078Z"
    }
   },
   "source": [
    "import os, json\n",
    "from tqdm import tqdm\n",
    "from typing import Dict, Any, List\n",
    "\n",
    "SRC_ENTITY_JSON = \"../data/raw/merged_threat_intelligence.json\"\n",
    "DST_DIR = \"../data/TTP-classification/qwen-ttp-classifiation/\"\n",
    "os.makedirs(DST_DIR, exist_ok=True)\n",
    "\n",
    "print(f\"üìÇ Loading entity-extraction file: {SRC_ENTITY_JSON}\")\n",
    "with open(SRC_ENTITY_JSON, \"r\", encoding=\"utf-8\") as f:\n",
    "    entity_records = json.load(f)\n",
    "print(f\"‚úÖ Loaded {len(entity_records)} records\")\n",
    "\n",
    "# H√†m x·ª≠ l√Ω 1 batch\n",
    "def process_batch(records: List[Dict[str, Any]], batch_id: int):\n",
    "    augmented: List[Dict[str, Any]] = []\n",
    "\n",
    "    for rec in tqdm(records, desc=f\"Batch {batch_id}\"):\n",
    "        title = rec.get(\"title\")\n",
    "        link = rec.get(\"link\") or rec.get(\"url\")\n",
    "        content_text = _coerce_text(rec.get(\"content\"))\n",
    "\n",
    "        # classify techniques\n",
    "        techniques = classify_multiple_techniques(content_text, top_k=TOP_K if 'TOP_K' in globals() else 6)\n",
    "\n",
    "        # entities ‚Üí subjects\n",
    "        extraction = rec.get(\"extraction\") or {}\n",
    "        ents = extraction.get(\"entities\") or []\n",
    "        subjects = []\n",
    "        for item in ents:\n",
    "            if isinstance(item, (list, tuple)) and len(item) >= 2:\n",
    "                subjects.append(str(item[0]))\n",
    "        threat_type = rec.get(\"threat_type\")\n",
    "        if threat_type:\n",
    "            subjects.append(str(threat_type))\n",
    "        subjects = [s for s in {s.strip(): None for s in subjects}.keys() if s]\n",
    "\n",
    "        # detect relationships\n",
    "        rels: List[List[str]] = []\n",
    "        verbs = [\"use\", \"uses\", \"abuse\", \"abuses\", \"leverage\", \"leverages\", \"employ\", \"employs\"]\n",
    "        if any(v in content_text.lower() for v in verbs):\n",
    "            for subj in subjects:\n",
    "                for t in (techniques or [])[:1]:\n",
    "                    rels.append([subj, \"uses\", t[\"id\"]])\n",
    "\n",
    "        rels = [list(x) for x in dict.fromkeys(tuple(r) for r in rels)]\n",
    "\n",
    "        # add results\n",
    "        out = dict(rec)\n",
    "        out[\"ttp_classification\"] = {\n",
    "            \"instruction\": None,\n",
    "            \"input\": None,\n",
    "            \"output\": {\"techniques\": techniques},\n",
    "        }\n",
    "        out[\"extended_relationships\"] = {\"relationships\": rels}\n",
    "        augmented.append(out)\n",
    "\n",
    "    # Save batch\n",
    "    dst_file = os.path.join(DST_DIR, f\"extended_relationships_batch_{batch_id}.json\")\n",
    "    with open(dst_file, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(augmented, f, ensure_ascii=False, indent=2)\n",
    "    print(f\"üíæ Written batch {batch_id}: {dst_file}\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Loading entity-extraction file: ../data/raw/merged_threat_intelligence.json\n",
      "‚úÖ Loaded 427 records\n"
     ]
    }
   ],
   "execution_count": 39
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-23T09:11:16.413797Z",
     "start_time": "2025-08-23T09:11:04.564990Z"
    }
   },
   "source": [
    "BATCH_SIZE = 50\n",
    "total = len(entity_records)\n",
    "\n",
    "# Chia danh s√°ch th√†nh nhi·ªÅu batch, m·ªói batch 50 record\n",
    "batches = [entity_records[i:i+BATCH_SIZE] for i in range(0, total, BATCH_SIZE)]\n",
    "\n",
    "print(f\"üìä T·ªïng s·ªë batch: {len(batches)}, m·ªói batch {BATCH_SIZE} records\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä T·ªïng s·ªë batch: 9, m·ªói batch 50 records\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 1:   0%|          | 0/50 [00:11<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[41], line 8\u001B[0m\n\u001B[1;32m      5\u001B[0m batches \u001B[38;5;241m=\u001B[39m [entity_records[i:i\u001B[38;5;241m+\u001B[39mBATCH_SIZE] \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m0\u001B[39m, total, BATCH_SIZE)]\n\u001B[1;32m      7\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124müìä T·ªïng s·ªë batch: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mlen\u001B[39m(batches)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, m·ªói batch \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mBATCH_SIZE\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m records\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m----> 8\u001B[0m \u001B[43mprocess_batch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbatches\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_id\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[39], line 24\u001B[0m, in \u001B[0;36mprocess_batch\u001B[0;34m(records, batch_id)\u001B[0m\n\u001B[1;32m     21\u001B[0m content_text \u001B[38;5;241m=\u001B[39m _coerce_text(rec\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcontent\u001B[39m\u001B[38;5;124m\"\u001B[39m))\n\u001B[1;32m     23\u001B[0m \u001B[38;5;66;03m# classify techniques\u001B[39;00m\n\u001B[0;32m---> 24\u001B[0m techniques \u001B[38;5;241m=\u001B[39m \u001B[43mclassify_multiple_techniques\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcontent_text\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtop_k\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mTOP_K\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mTOP_K\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mglobals\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;241;43m6\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m     26\u001B[0m \u001B[38;5;66;03m# entities ‚Üí subjects\u001B[39;00m\n\u001B[1;32m     27\u001B[0m extraction \u001B[38;5;241m=\u001B[39m rec\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mextraction\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;129;01mor\u001B[39;00m {}\n",
      "Cell \u001B[0;32mIn[38], line 50\u001B[0m, in \u001B[0;36mclassify_multiple_techniques\u001B[0;34m(threat_text, top_k)\u001B[0m\n\u001B[1;32m     47\u001B[0m inputs \u001B[38;5;241m=\u001B[39m {k: v\u001B[38;5;241m.\u001B[39mto(model\u001B[38;5;241m.\u001B[39mdevice) \u001B[38;5;28;01mfor\u001B[39;00m k, v \u001B[38;5;129;01min\u001B[39;00m inputs\u001B[38;5;241m.\u001B[39mitems()}\n\u001B[1;32m     49\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mno_grad():\n\u001B[0;32m---> 50\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgenerate\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     51\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     52\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmax_new_tokens\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m512\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     53\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdo_sample\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# T·∫Øt sampling\u001B[39;49;00m\n\u001B[1;32m     54\u001B[0m \u001B[43m        \u001B[49m\u001B[43mnum_beams\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m      \u001B[49m\u001B[38;5;66;43;03m# S·ª≠ d·ª•ng greedy decoding\u001B[39;49;00m\n\u001B[1;32m     55\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpad_token_id\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtokenizer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43meos_token_id\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     56\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     58\u001B[0m resp \u001B[38;5;241m=\u001B[39m tokenizer\u001B[38;5;241m.\u001B[39mdecode(outputs[\u001B[38;5;241m0\u001B[39m], skip_special_tokens\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m     59\u001B[0m content \u001B[38;5;241m=\u001B[39m resp\u001B[38;5;241m.\u001B[39msplit(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m<|im_start|>assistant\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m]\n",
      "File \u001B[0;32m~/Documents/UIT/2nd/NLP/LLM-TKIG/.venv/lib/python3.12/site-packages/torch/utils/_contextlib.py:120\u001B[0m, in \u001B[0;36mcontext_decorator.<locals>.decorate_context\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    117\u001B[0m \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mwraps(func)\n\u001B[1;32m    118\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mdecorate_context\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m    119\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m ctx_factory():\n\u001B[0;32m--> 120\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/UIT/2nd/NLP/LLM-TKIG/.venv/lib/python3.12/site-packages/transformers/generation/utils.py:2548\u001B[0m, in \u001B[0;36mGenerationMixin.generate\u001B[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, use_model_defaults, custom_generate, **kwargs)\u001B[0m\n\u001B[1;32m   2536\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_contrastive_search(\n\u001B[1;32m   2537\u001B[0m         input_ids,\n\u001B[1;32m   2538\u001B[0m         logits_processor\u001B[38;5;241m=\u001B[39mprepared_logits_processor,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   2543\u001B[0m         \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mmodel_kwargs,\n\u001B[1;32m   2544\u001B[0m     )\n\u001B[1;32m   2546\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m generation_mode \u001B[38;5;129;01min\u001B[39;00m (GenerationMode\u001B[38;5;241m.\u001B[39mSAMPLE, GenerationMode\u001B[38;5;241m.\u001B[39mGREEDY_SEARCH):\n\u001B[1;32m   2547\u001B[0m     \u001B[38;5;66;03m# 11. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001B[39;00m\n\u001B[0;32m-> 2548\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_sample\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   2549\u001B[0m \u001B[43m        \u001B[49m\u001B[43minput_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2550\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlogits_processor\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mprepared_logits_processor\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2551\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstopping_criteria\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mprepared_stopping_criteria\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2552\u001B[0m \u001B[43m        \u001B[49m\u001B[43mgeneration_config\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgeneration_config\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2553\u001B[0m \u001B[43m        \u001B[49m\u001B[43msynced_gpus\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msynced_gpus\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2554\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstreamer\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstreamer\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2555\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mmodel_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2556\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   2558\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m generation_mode \u001B[38;5;129;01min\u001B[39;00m (GenerationMode\u001B[38;5;241m.\u001B[39mBEAM_SAMPLE, GenerationMode\u001B[38;5;241m.\u001B[39mBEAM_SEARCH):\n\u001B[1;32m   2559\u001B[0m     \u001B[38;5;66;03m# 11. run beam sample\u001B[39;00m\n\u001B[1;32m   2560\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_beam_search(\n\u001B[1;32m   2561\u001B[0m         input_ids,\n\u001B[1;32m   2562\u001B[0m         logits_processor\u001B[38;5;241m=\u001B[39mprepared_logits_processor,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   2566\u001B[0m         \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mmodel_kwargs,\n\u001B[1;32m   2567\u001B[0m     )\n",
      "File \u001B[0;32m~/Documents/UIT/2nd/NLP/LLM-TKIG/.venv/lib/python3.12/site-packages/transformers/generation/utils.py:3507\u001B[0m, in \u001B[0;36mGenerationMixin._sample\u001B[0;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, **model_kwargs)\u001B[0m\n\u001B[1;32m   3504\u001B[0m model_inputs\u001B[38;5;241m.\u001B[39mupdate({\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124moutput_hidden_states\u001B[39m\u001B[38;5;124m\"\u001B[39m: output_hidden_states} \u001B[38;5;28;01mif\u001B[39;00m output_hidden_states \u001B[38;5;28;01melse\u001B[39;00m {})\n\u001B[1;32m   3506\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m is_prefill:\n\u001B[0;32m-> 3507\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mmodel_inputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreturn_dict\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[1;32m   3508\u001B[0m     is_prefill \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[1;32m   3509\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "File \u001B[0;32m~/Documents/UIT/2nd/NLP/LLM-TKIG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1773\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1771\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1772\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1773\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/UIT/2nd/NLP/LLM-TKIG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1784\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1779\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1780\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1781\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1782\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1783\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1784\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1786\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1787\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[0;32m~/Documents/UIT/2nd/NLP/LLM-TKIG/.venv/lib/python3.12/site-packages/transformers/utils/generic.py:959\u001B[0m, in \u001B[0;36mcan_return_tuple.<locals>.wrapper\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    957\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m return_dict_passed \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    958\u001B[0m     return_dict \u001B[38;5;241m=\u001B[39m return_dict_passed\n\u001B[0;32m--> 959\u001B[0m output \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    960\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m return_dict \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(output, \u001B[38;5;28mtuple\u001B[39m):\n\u001B[1;32m    961\u001B[0m     output \u001B[38;5;241m=\u001B[39m output\u001B[38;5;241m.\u001B[39mto_tuple()\n",
      "File \u001B[0;32m~/Documents/UIT/2nd/NLP/LLM-TKIG/.venv/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py:455\u001B[0m, in \u001B[0;36mQwen2ForCausalLM.forward\u001B[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, cache_position, logits_to_keep, **kwargs)\u001B[0m\n\u001B[1;32m    423\u001B[0m \u001B[38;5;129m@can_return_tuple\u001B[39m\n\u001B[1;32m    424\u001B[0m \u001B[38;5;129m@auto_docstring\u001B[39m\n\u001B[1;32m    425\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mforward\u001B[39m(\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    436\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs: Unpack[TransformersKwargs],\n\u001B[1;32m    437\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m CausalLMOutputWithPast:\n\u001B[1;32m    438\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    439\u001B[0m \u001B[38;5;124;03m    Example:\u001B[39;00m\n\u001B[1;32m    440\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    453\u001B[0m \u001B[38;5;124;03m    \"Hey, are you conscious? Can you talk to me?\\nI'm not conscious, but I can talk to you.\"\u001B[39;00m\n\u001B[1;32m    454\u001B[0m \u001B[38;5;124;03m    ```\"\"\"\u001B[39;00m\n\u001B[0;32m--> 455\u001B[0m     outputs: BaseModelOutputWithPast \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    456\u001B[0m \u001B[43m        \u001B[49m\u001B[43minput_ids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minput_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    457\u001B[0m \u001B[43m        \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    458\u001B[0m \u001B[43m        \u001B[49m\u001B[43mposition_ids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mposition_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    459\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpast_key_values\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpast_key_values\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    460\u001B[0m \u001B[43m        \u001B[49m\u001B[43minputs_embeds\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs_embeds\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    461\u001B[0m \u001B[43m        \u001B[49m\u001B[43muse_cache\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muse_cache\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    462\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcache_position\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcache_position\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    463\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    464\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    466\u001B[0m     hidden_states \u001B[38;5;241m=\u001B[39m outputs\u001B[38;5;241m.\u001B[39mlast_hidden_state\n\u001B[1;32m    467\u001B[0m     \u001B[38;5;66;03m# Only compute necessary logits, and do not upcast them to float if we are not computing the loss\u001B[39;00m\n",
      "File \u001B[0;32m~/Documents/UIT/2nd/NLP/LLM-TKIG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1773\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1771\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1772\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1773\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/UIT/2nd/NLP/LLM-TKIG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1784\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1779\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1780\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1781\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1782\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1783\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1784\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1786\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1787\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[0;32m~/Documents/UIT/2nd/NLP/LLM-TKIG/.venv/lib/python3.12/site-packages/transformers/utils/generic.py:1083\u001B[0m, in \u001B[0;36mcheck_model_inputs.<locals>.wrapper\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1080\u001B[0m                 module\u001B[38;5;241m.\u001B[39mforward \u001B[38;5;241m=\u001B[39m make_capture_wrapper(module, original_forward, key, specs\u001B[38;5;241m.\u001B[39mindex)\n\u001B[1;32m   1081\u001B[0m                 monkey_patched_layers\u001B[38;5;241m.\u001B[39mappend((module, original_forward))\n\u001B[0;32m-> 1083\u001B[0m outputs \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1084\u001B[0m \u001B[38;5;66;03m# Restore original forward methods\u001B[39;00m\n\u001B[1;32m   1085\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m module, original_forward \u001B[38;5;129;01min\u001B[39;00m monkey_patched_layers:\n",
      "File \u001B[0;32m~/Documents/UIT/2nd/NLP/LLM-TKIG/.venv/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py:381\u001B[0m, in \u001B[0;36mQwen2Model.forward\u001B[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, cache_position, **kwargs)\u001B[0m\n\u001B[1;32m    378\u001B[0m hidden_states \u001B[38;5;241m=\u001B[39m inputs_embeds\n\u001B[1;32m    380\u001B[0m \u001B[38;5;66;03m# create position embeddings to be shared across the decoder layers\u001B[39;00m\n\u001B[0;32m--> 381\u001B[0m position_embeddings \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrotary_emb\u001B[49m(hidden_states, position_ids)\n\u001B[1;32m    383\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m decoder_layer \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlayers[: \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39mnum_hidden_layers]:\n\u001B[1;32m    384\u001B[0m     hidden_states \u001B[38;5;241m=\u001B[39m decoder_layer(\n\u001B[1;32m    385\u001B[0m         hidden_states,\n\u001B[1;32m    386\u001B[0m         attention_mask\u001B[38;5;241m=\u001B[39mcausal_mask_mapping[decoder_layer\u001B[38;5;241m.\u001B[39mattention_type],\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    392\u001B[0m         \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[1;32m    393\u001B[0m     )\n",
      "File \u001B[0;32m~/Documents/UIT/2nd/NLP/LLM-TKIG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1949\u001B[0m, in \u001B[0;36mModule.__getattr__\u001B[0;34m(self, name)\u001B[0m\n\u001B[1;32m   1944\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;241m=\u001B[39m OrderedDict()\n\u001B[1;32m   1946\u001B[0m \u001B[38;5;66;03m# It is crucial that the return type is not annotated as `Any`, otherwise type checking\u001B[39;00m\n\u001B[1;32m   1947\u001B[0m \u001B[38;5;66;03m# on `torch.nn.Module` and all its subclasses is largely disabled as a result. See:\u001B[39;00m\n\u001B[1;32m   1948\u001B[0m \u001B[38;5;66;03m# https://github.com/pytorch/pytorch/pull/115074\u001B[39;00m\n\u001B[0;32m-> 1949\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21m__getattr__\u001B[39m(\u001B[38;5;28mself\u001B[39m, name: \u001B[38;5;28mstr\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Union[Tensor, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mModule\u001B[39m\u001B[38;5;124m\"\u001B[39m]:\n\u001B[1;32m   1950\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_parameters\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__dict__\u001B[39m:\n\u001B[1;32m   1951\u001B[0m         _parameters \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__dict__\u001B[39m[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_parameters\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 41
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "process_batch(batches[0], batch_id=1)"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#Batch 2 (records 50‚Äì99):\n",
    "process_batch(batches[1], batch_id=2)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#Batch 3 (records 100‚Äì149):\n",
    "process_batch(batches[1], batch_id=3)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#Batch 4 (records 150 ‚Äì 199):\n",
    "process_batch(batches[1], batch_id=3)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#Batch 5 (records 200 ‚Äì 249):\n",
    "process_batch(batches[1], batch_id=3)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#Batch 6 (records 250 ‚Äì 299):\n",
    "process_batch(batches[1], batch_id=3)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#Batch 7 (records 300 ‚Äì 349):\n",
    "process_batch(batches[1], batch_id=3)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#Batch 8 (records 350 ‚Äì 399):\n",
    "process_batch(batches[1], batch_id=3)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#Batch 9 (records 400 ‚Äì 426):\n",
    "process_batch(batches[1], batch_id=3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
