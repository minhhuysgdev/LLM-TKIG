{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# TTP Classification Training with Qwen Model\n",
    "\n",
    "## Overview\n",
    "This notebook implements TTP (Tactics, Techniques, and Procedures) classification training using Qwen model with MITRE ATT&CK framework.\n",
    "\n",
    "### Task Description\n",
    "- **Input**: Threat intelligence text descriptions\n",
    "- **Output**: MITRE ATT&CK technique classification (T1xxx format)\n",
    "- **Model**: Qwen/Qwen2.5-1.5B-Instruct (fine-tuned)\n",
    "\n",
    "### Dataset Statistics\n",
    "- **Total samples**: 921 training examples\n",
    "- **Enterprise Matrix**: 691 techniques (222 main + 469 sub-techniques)\n",
    "- **Mobile Matrix**: 135 techniques (89 main + 46 sub-techniques)\n",
    "- **ICS Matrix**: 95 techniques (95 main + 0 sub-techniques)\n",
    "\n",
    "### Key Steps\n",
    "1. Load and prepare MITRE ATT&CK training data\n",
    "2. Setup Qwen model for fine-tuning\n",
    "3. Create training and validation splits\n",
    "4. Fine-tune model for TTP classification\n",
    "5. Evaluate model performance\n",
    "6. Test on real threat intelligence data\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## 1. Environment Setup and Dependencies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-09T03:26:45.278043Z",
     "start_time": "2025-08-09T03:26:45.266144Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìö Dependencies loaded successfully!\n",
      "üî• PyTorch version: 2.8.0\n",
      "ü§ñ CUDA available: False\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Any, Tuple\n",
    "import logging\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Transformers and training\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForCausalLM,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    DataCollatorForLanguageModeling\n",
    ")\n",
    "from datasets import Dataset, DatasetDict\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "print(\"üìö Dependencies loaded successfully!\")\n",
    "print(f\"üî• PyTorch version: {torch.__version__}\")\n",
    "print(f\"ü§ñ CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"üéÆ GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"üíæ GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## 2. Load MITRE ATT&CK Training Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-09T03:26:45.305098Z",
     "start_time": "2025-08-09T03:26:45.290509Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Loading MITRE ATT&CK dataset...\n",
      "‚úÖ Loaded 921 training samples\n",
      "\n",
      "üìä Dataset Analysis:\n",
      "  ‚Ä¢ Enterprise: 691 samples\n",
      "  ‚Ä¢ Mobile: 135 samples\n",
      "  ‚Ä¢ ICS: 95 samples\n",
      "  ‚Ä¢ Techniques: 406 samples\n",
      "  ‚Ä¢ Sub-techniques: 515 samples\n",
      "  ‚Ä¢ Unique technique IDs: 921\n",
      "\n",
      "üìù Sample Training Example:\n",
      "Instruction: Adversaries may inject malicious code into process via Extra Window Memory (EWM) in order to evade p...\n",
      "Technique ID: T1055.011\n",
      "Technique Name: Extra Window Memory Injection\n",
      "Matrix: enterprise\n"
     ]
    }
   ],
   "source": [
    "# Load merged MITRE ATT&CK dataset\n",
    "dataset_path = \"../data/TTP-classification/merged_mitre_attack_dataset.json\"\n",
    "\n",
    "print(\"üìÇ Loading MITRE ATT&CK dataset...\")\n",
    "with open(dataset_path, 'r', encoding='utf-8') as f:\n",
    "    mitre_data = json.load(f)\n",
    "\n",
    "# Extract training samples\n",
    "training_samples = mitre_data['dataset']\n",
    "print(f\"‚úÖ Loaded {len(training_samples):,} training samples\")\n",
    "\n",
    "# Analyze dataset structure\n",
    "print(\"\\nüìä Dataset Analysis:\")\n",
    "matrices = {'enterprise': 0, 'mobile': 0, 'ics': 0}\n",
    "techniques_count = 0\n",
    "sub_techniques_count = 0\n",
    "technique_ids = set()\n",
    "\n",
    "for sample in training_samples:\n",
    "    technique = sample['output']['techniques'][0]\n",
    "    matrix = technique['matrix']\n",
    "    technique_id = technique['id']\n",
    "\n",
    "    matrices[matrix] += 1\n",
    "    technique_ids.add(technique_id)\n",
    "\n",
    "    if '.' in technique_id:\n",
    "        sub_techniques_count += 1\n",
    "    else:\n",
    "        techniques_count += 1\n",
    "\n",
    "print(f\"  ‚Ä¢ Enterprise: {matrices['enterprise']:,} samples\")\n",
    "print(f\"  ‚Ä¢ Mobile: {matrices['mobile']:,} samples\")\n",
    "print(f\"  ‚Ä¢ ICS: {matrices['ics']:,} samples\")\n",
    "print(f\"  ‚Ä¢ Techniques: {techniques_count:,} samples\")\n",
    "print(f\"  ‚Ä¢ Sub-techniques: {sub_techniques_count:,} samples\")\n",
    "print(f\"  ‚Ä¢ Unique technique IDs: {len(technique_ids):,}\")\n",
    "\n",
    "# Show sample data\n",
    "print(\"\\nüìù Sample Training Example:\")\n",
    "sample = training_samples[0]\n",
    "print(f\"Instruction: {sample['instruction'][:100]}...\")\n",
    "print(f\"Technique ID: {sample['output']['techniques'][0]['id']}\")\n",
    "print(f\"Technique Name: {sample['output']['techniques'][0]['name']}\")\n",
    "print(f\"Matrix: {sample['output']['techniques'][0]['matrix']}\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## 3. Prepare Training Data Format\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-09T03:26:45.342951Z",
     "start_time": "2025-08-09T03:26:45.327346Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Formatting training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 921/921 [00:00<00:00, 143231.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Formatted 921 training samples\n",
      "\n",
      "üìù Formatted Training Example:\n",
      "<|im_start|>system\n",
      "You are a cybersecurity expert specializing in MITRE ATT&CK framework. Your task is to analyze threat intelligence descriptions and identify the corresponding MITRE ATT&CK techniques.\n",
      "\n",
      "Given a description of adversary behavior, identify the most relevant MITRE ATT&CK technique and provide:\n",
      "1. Technique ID (e.g., T1055.011)\n",
      "2. Technique Name\n",
      "3. Matrix (enterprise/mobile/ics)\n",
      "\n",
      "Respond in JSON format.<|im_end|>\n",
      "<|im_start|>user\n",
      "Analyze this threat behavior and identify the MITRE ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def format_training_sample(sample: Dict[str, Any]) -> Dict[str, str]:\n",
    "    \"\"\"\n",
    "    Format training sample for instruction tuning\n",
    "\n",
    "    Input format:\n",
    "    {\n",
    "        \"instruction\": \"Adversary behavior description...\",\n",
    "        \"output\": {\n",
    "            \"techniques\": [{\n",
    "                \"id\": \"T1055.011\",\n",
    "                \"name\": \"Extra Window Memory Injection\",\n",
    "                \"description\": \"...\",\n",
    "                \"matrix\": \"enterprise\"\n",
    "            }]\n",
    "        }\n",
    "    }\n",
    "\n",
    "    Output format for instruction tuning:\n",
    "    {\n",
    "        \"text\": \"<|im_start|>system\\nYou are a cybersecurity expert...\\n<|im_end|>\\n<|im_start|>user\\n...\\n<|im_end|>\\n<|im_start|>assistant\\n...\\n<|im_end|>\"\n",
    "    }\n",
    "    \"\"\"\n",
    "    instruction = sample['instruction']\n",
    "    technique = sample['output']['techniques'][0]\n",
    "\n",
    "    # Create system prompt\n",
    "    system_prompt = \"\"\"You are a cybersecurity expert specializing in MITRE ATT&CK framework. Your task is to analyze threat intelligence descriptions and identify the corresponding MITRE ATT&CK techniques.\n",
    "\n",
    "Given a description of adversary behavior, identify the most relevant MITRE ATT&CK technique and provide:\n",
    "1. Technique ID (e.g., T1055.011)\n",
    "2. Technique Name\n",
    "3. Matrix (enterprise/mobile/ics)\n",
    "\n",
    "Respond in JSON format.\"\"\"\n",
    "\n",
    "    # Create user input\n",
    "    user_input = f\"Analyze this threat behavior and identify the MITRE ATT&CK technique:\\n\\n{instruction}\"\n",
    "\n",
    "    # Create assistant response\n",
    "    assistant_response = json.dumps({\n",
    "        \"technique_id\": technique['id'],\n",
    "        \"technique_name\": technique['name'],\n",
    "        \"matrix\": technique['matrix'],\n",
    "        \"description\": technique['description']\n",
    "    }, ensure_ascii=False)\n",
    "\n",
    "    # Format for Qwen chat template\n",
    "    formatted_text = f\"\"\"<|im_start|>system\n",
    "{system_prompt}<|im_end|>\n",
    "<|im_start|>user\n",
    "{user_input}<|im_end|>\n",
    "<|im_start|>assistant\n",
    "{assistant_response}<|im_end|>\"\"\"\n",
    "\n",
    "    return {\"text\": formatted_text}\n",
    "\n",
    "# Format all training samples\n",
    "print(\"üîÑ Formatting training data...\")\n",
    "formatted_samples = []\n",
    "for sample in tqdm(training_samples):\n",
    "    formatted_sample = format_training_sample(sample)\n",
    "    formatted_samples.append(formatted_sample)\n",
    "\n",
    "print(f\"‚úÖ Formatted {len(formatted_samples):,} training samples\")\n",
    "\n",
    "# Show formatted example\n",
    "print(\"\\nüìù Formatted Training Example:\")\n",
    "print(formatted_samples[0]['text'][:500] + \"...\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## 4. Setup Qwen Model and Tokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-09T03:27:12.837796Z",
     "start_time": "2025-08-09T03:26:45.365172Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ Setting up model: Qwen/Qwen2.5-1.5B-Instruct\n",
      "üîß Using device: cpu\n",
      "üìù Loading tokenizer...\n",
      "‚úÖ Tokenizer loaded\n",
      "üìä Vocab size: 151,665\n",
      "üîë Special tokens: {'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}\n",
      "ü§ñ Loading model...\n",
      "‚úÖ Model loaded\n",
      "üìä Model parameters: 1,543,714,304\n",
      "üéØ Trainable parameters: 1,543,714,304\n"
     ]
    }
   ],
   "source": [
    "# Model configuration\n",
    "MODEL_NAME = \"Qwen/Qwen2.5-1.5B-Instruct\"\n",
    "MAX_LENGTH = 2048\n",
    "BATCH_SIZE = 4\n",
    "LEARNING_RATE = 2e-5\n",
    "NUM_EPOCHS = 3\n",
    "WARMUP_STEPS = 100\n",
    "\n",
    "print(f\"ü§ñ Setting up model: {MODEL_NAME}\")\n",
    "\n",
    "# Setup device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"üîß Using device: {device}\")\n",
    "\n",
    "# Load tokenizer\n",
    "print(\"üìù Loading tokenizer...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    trust_remote_code=True,\n",
    "    padding_side=\"right\"\n",
    ")\n",
    "\n",
    "# Add padding token if not exists\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    print(\"üîß Set pad_token = eos_token\")\n",
    "\n",
    "print(f\"‚úÖ Tokenizer loaded\")\n",
    "print(f\"üìä Vocab size: {len(tokenizer):,}\")\n",
    "print(f\"üîë Special tokens: {tokenizer.special_tokens_map}\")\n",
    "\n",
    "# Load model\n",
    "print(\"ü§ñ Loading model...\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    trust_remote_code=True,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\",\n",
    "    low_cpu_mem_usage=True\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Model loaded\")\n",
    "print(f\"üìä Model parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "print(f\"üéØ Trainable parameters: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## 5. Create Dataset and Data Loaders\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-09T03:27:13.753497Z",
     "start_time": "2025-08-09T03:27:13.035604Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Creating train/validation split...\n",
      "üìö Training samples: 828\n",
      "üîç Validation samples: 93\n",
      "üîÑ Creating datasets...\n",
      "üî§ Tokenizing datasets...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33916b7d631b4dee843069b26cfb6ea1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing train data:   0%|          | 0/828 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1440e9a486784b0f902964f42ae9bdf0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing validation data:   0%|          | 0/93 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Datasets prepared\n",
      "üìä Train dataset: 828 samples\n",
      "üìä Validation dataset: 93 samples\n",
      "\n",
      "üìù Sample tokenization:\n",
      "Input IDs length: 2048\n",
      "Attention mask length: 2048\n",
      "Labels length: 2048\n"
     ]
    }
   ],
   "source": [
    "def tokenize_function(examples):\n",
    "    \"\"\"\n",
    "    Tokenize training examples\n",
    "    \"\"\"\n",
    "    # Tokenize the text\n",
    "    tokenized = tokenizer(\n",
    "        examples[\"text\"],\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",  # S·ª¨A L·ªñI: Pad to max length\n",
    "        max_length=MAX_LENGTH,\n",
    "        return_tensors=None\n",
    "    )\n",
    "\n",
    "    # For causal language modeling, labels are the same as input_ids\n",
    "    tokenized[\"labels\"] = tokenized[\"input_ids\"].copy()\n",
    "\n",
    "    return tokenized\n",
    "\n",
    "# Create train/validation split\n",
    "print(\"üìä Creating train/validation split...\")\n",
    "train_samples, val_samples = train_test_split(\n",
    "    formatted_samples,\n",
    "    test_size=0.1,\n",
    "    random_state=42,\n",
    "    stratify=[sample['text'].split('\"matrix\": \"')[1].split('\"')[0] for sample in formatted_samples]\n",
    ")\n",
    "\n",
    "print(f\"üìö Training samples: {len(train_samples):,}\")\n",
    "print(f\"üîç Validation samples: {len(val_samples):,}\")\n",
    "\n",
    "# Create HuggingFace datasets\n",
    "print(\"üîÑ Creating datasets...\")\n",
    "train_dataset = Dataset.from_list(train_samples)\n",
    "val_dataset = Dataset.from_list(val_samples)\n",
    "\n",
    "# Tokenize datasets\n",
    "print(\"üî§ Tokenizing datasets...\")\n",
    "train_dataset = train_dataset.map(\n",
    "    tokenize_function,\n",
    "    batched=True,\n",
    "    remove_columns=[\"text\"],\n",
    "    desc=\"Tokenizing train data\"\n",
    ")\n",
    "\n",
    "val_dataset = val_dataset.map(\n",
    "    tokenize_function,\n",
    "    batched=True,\n",
    "    remove_columns=[\"text\"],\n",
    "    desc=\"Tokenizing validation data\"\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Datasets prepared\")\n",
    "print(f\"üìä Train dataset: {len(train_dataset):,} samples\")\n",
    "print(f\"üìä Validation dataset: {len(val_dataset):,} samples\")\n",
    "\n",
    "# Check tokenization\n",
    "sample_tokens = train_dataset[0]\n",
    "print(f\"\\nüìù Sample tokenization:\")\n",
    "print(f\"Input IDs length: {len(sample_tokens['input_ids'])}\")\n",
    "print(f\"Attention mask length: {len(sample_tokens['attention_mask'])}\")\n",
    "print(f\"Labels length: {len(sample_tokens['labels'])}\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## 6. Setup Training Configuration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-09T03:27:13.802275Z",
     "start_time": "2025-08-09T03:27:13.787638Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÅ Output directory: ../models/qwen-ttp-classification-2025-08-09_10-27-13\n",
      "‚úÖ Training arguments configured\n",
      "üéØ Batch size: 4\n",
      "üìà Learning rate: 2e-05\n",
      "üîÑ Epochs: 3\n",
      "üî• FP16: True\n",
      "üíæ Gradient checkpointing: True\n",
      "‚úÖ Data collator configured\n"
     ]
    }
   ],
   "source": [
    "# Create output directory\n",
    "timestamp = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "output_dir = f\"../models/qwen-ttp-classification-{timestamp}\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "print(f\"üìÅ Output directory: {output_dir}\")\n",
    "\n",
    "# Training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    overwrite_output_dir=True,\n",
    "\n",
    "    # Training parameters\n",
    "    num_train_epochs=NUM_EPOCHS,\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    per_device_eval_batch_size=BATCH_SIZE,\n",
    "    gradient_accumulation_steps=1,\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    weight_decay=0.01,\n",
    "    warmup_steps=WARMUP_STEPS,\n",
    "\n",
    "    # Optimization\n",
    "    fp16=True,\n",
    "    dataloader_pin_memory=False,\n",
    "    gradient_checkpointing=True,\n",
    "\n",
    "    # Logging and saving\n",
    "    logging_dir=f\"{output_dir}/logs\",\n",
    "    logging_steps=10,\n",
    "    save_steps=100,\n",
    "    save_total_limit=3,\n",
    "    eval_steps=100,\n",
    "    eval_strategy=\"steps\",  # FIXED: was evaluation_strategy\n",
    "\n",
    "    # Other settings\n",
    "    remove_unused_columns=False,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    "    greater_is_better=False,\n",
    "\n",
    "    # Report\n",
    "    report_to=None,  # Disable wandb/tensorboard\n",
    "    run_name=f\"qwen-ttp-classification-{timestamp}\"\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Training arguments configured\")\n",
    "print(f\"üéØ Batch size: {BATCH_SIZE}\")\n",
    "print(f\"üìà Learning rate: {LEARNING_RATE}\")\n",
    "print(f\"üîÑ Epochs: {NUM_EPOCHS}\")\n",
    "print(f\"üî• FP16: {training_args.fp16}\")\n",
    "print(f\"üíæ Gradient checkpointing: {training_args.gradient_checkpointing}\")\n",
    "\n",
    "# Data collator\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer,\n",
    "    mlm=False,  # No masking for causal LM\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Data collator configured\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## 7. Initialize Trainer and Start Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-09T03:27:14.064268Z",
     "start_time": "2025-08-09T03:27:13.813276Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß Initializing MPS-compatible training...\n",
      "üßπ MPS cache cleared\n",
      "üìÅ Output: ../models/qwen-ttp-mps-2025-08-09_10-27-13\n",
      "‚úÖ Configuration created!\n",
      "üî• FP16: False (ph·∫£i False)\n",
      "üçé BF16: False (ph·∫£i False)\n",
      "\n",
      "üèÉ‚Äç‚ôÇÔ∏è Creating trainer...\n",
      "‚úÖ Trainer initialized successfully!"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/lt/y_3sh6vn2mb68907rlw4xvww0000gn/T/ipykernel_8563/3816146588.py:81: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üçé Ready for MPS training!\n",
      "üìä Batch size: 2\n",
      "üîÑ Effective batch: 4 (v·ªõi gradient accumulation)\n",
      "üìà Learning rate: 2e-05\n",
      "\n",
      "üöÄ Ready to train! Run: trainer.train()\n"
     ]
    }
   ],
   "source": [
    "# ‚úÖ CODE ƒê√É S·ª¨A HO√ÄN CH·ªàNH CHO MPS (APPLE SILICON)\n",
    "print(\"üîß Initializing MPS-compatible training...\")\n",
    "\n",
    "import torch\n",
    "from transformers import TrainingArguments, Trainer, DataCollatorForLanguageModeling\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "# Clear memory\n",
    "if torch.backends.mps.is_available():\n",
    "    torch.mps.empty_cache()\n",
    "    print(\"üßπ MPS cache cleared\")\n",
    "\n",
    "# Configuration\n",
    "MODEL_NAME = \"Qwen/Qwen2.5-1.5B-Instruct\"\n",
    "BATCH_SIZE = 2  # Smaller for MPS\n",
    "LEARNING_RATE = 2e-5\n",
    "NUM_EPOCHS = 3\n",
    "WARMUP_STEPS = 100\n",
    "\n",
    "# Create output directory\n",
    "timestamp = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "output_dir = f\"../models/qwen-ttp-mps-{timestamp}\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "print(f\"üìÅ Output: {output_dir}\")\n",
    "\n",
    "# ‚úÖ MPS-COMPATIBLE TrainingArguments (S·ª¨A L·ªñI)\n",
    "training_args_mps = TrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    overwrite_output_dir=True,\n",
    "\n",
    "    # Training params\n",
    "    num_train_epochs=NUM_EPOCHS,\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    per_device_eval_batch_size=BATCH_SIZE,\n",
    "    gradient_accumulation_steps=2,  # TƒÉng ƒë·ªÉ b√π ƒë·∫Øp batch nh·ªè\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    weight_decay=0.01,\n",
    "    warmup_steps=WARMUP_STEPS,\n",
    "\n",
    "    # ‚ö†Ô∏è QUAN TR·ªåNG: MPS settings\n",
    "    fp16=False,              # PH·∫¢I False cho MPS\n",
    "    bf16=False,              # PH·∫¢I False cho MPS\n",
    "    dataloader_pin_memory=False,\n",
    "    gradient_checkpointing=True,\n",
    "\n",
    "    # Logging\n",
    "    logging_steps=10,\n",
    "    save_steps=100,\n",
    "    eval_steps=100,\n",
    "    eval_strategy=\"steps\",   # S·ª¨A: kh√¥ng ph·∫£i evaluation_strategy\n",
    "    save_total_limit=3,\n",
    "\n",
    "    # Evaluation\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    "    greater_is_better=False,\n",
    "\n",
    "    # Disable external services\n",
    "    report_to=None,\n",
    "    dataloader_num_workers=0,  # Single thread cho MPS\n",
    ")\n",
    "\n",
    "# ‚úÖ Data collator (S·ª¨A L·ªñI)\n",
    "data_collator_mps = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer,\n",
    "    mlm=False\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Configuration created!\")\n",
    "print(f\"üî• FP16: {training_args_mps.fp16} (ph·∫£i False)\")\n",
    "print(f\"üçé BF16: {training_args_mps.bf16} (ph·∫£i False)\")\n",
    "\n",
    "# ‚úÖ Initialize Trainer (S·ª¨A L·ªñI - KH√îNG c√≥ accelerator argument)\n",
    "print(\"\\nüèÉ‚Äç‚ôÇÔ∏è Creating trainer...\")\n",
    "\n",
    "os.environ[\"ACCELERATE_MIXED_PRECISION\"] = \"no\"\n",
    "os.environ[\"ACCELERATE_DISABLE_RICH\"] = \"1\"\n",
    "\n",
    "# Kh·ªüi t·∫°o trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args_mps,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator_mps,\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Trainer initialized successfully!\")\n",
    "print(\"üçé Ready for MPS training!\")\n",
    "print(f\"üìä Batch size: {BATCH_SIZE}\")\n",
    "print(f\"üîÑ Effective batch: {BATCH_SIZE * 2} (v·ªõi gradient accumulation)\")\n",
    "print(f\"üìà Learning rate: {LEARNING_RATE}\")\n",
    "\n",
    "# ‚úÖ B√¢y gi·ªù c√≥ th·ªÉ b·∫Øt ƒë·∫ßu training\n",
    "print(\"\\nüöÄ Ready to train! Run: trainer.train()\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## 8. Model Evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-09T03:58:09.511032Z",
     "start_time": "2025-08-09T03:27:14.082629Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Evaluating model...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13' max='47' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13/47 14:06 < 39:57, 0.01 it/s]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "print(\"üìä Evaluating model...\")\n",
    "eval_result = trainer.evaluate()\n",
    "\n",
    "print(\"\\nüìà Evaluation Results:\")\n",
    "for key, value in eval_result.items():\n",
    "    print(f\"  {key}: {value:.4f}\")\n",
    "\n",
    "# Save evaluation results\n",
    "eval_file = os.path.join(output_dir, \"evaluation_results.json\")\n",
    "with open(eval_file, 'w') as f:\n",
    "    json.dump(eval_result, f, indent=2)\n",
    "\n",
    "print(f\"‚úÖ Evaluation results saved to: {eval_file}\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## 9. Test Model Inference\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-09T03:58:35.820645Z",
     "start_time": "2025-08-09T03:58:12.378309Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß™ Testing model inference...\n",
      "\n",
      "üìù Test Case 1:\n",
      "Input: Adversaries may inject malicious code into processes in order to evade process-based defenses or elevate privileges.\n",
      "Output: system\n",
      "You are a cybersecurity expert specializing in MITRE ATT&CK framework. Your task is to analyze threat intelligence descriptions and identify the corresponding MITRE ATT&CK techniques.\n",
      "\n",
      "Given a description of adversary behavior, identify the most relevant MITRE ATT&CK technique and provide:\n",
      "1. Technique ID (e.g., T1055.011)\n",
      "2. Technique Name\n",
      "3. Matrix (enterprise/mobile/ics)\n",
      "\n",
      "Respond in JSON format.\n",
      "user\n",
      "Analyze this threat behavior and identify the MITRE ATT&CK technique:\n",
      "\n",
      "Adversaries may inject malicious code into processes in order to evade process-based defenses or elevate privileges.\n",
      "assistant\n",
      "```json\n",
      "{\n",
      "  \"TechniqueID\": \"T1078\",\n",
      "  \"TechniqueName\": \"Elevate Privileges via Process Injection\",\n",
      "  \"Matrix\": \"enterprise\"\n",
      "}\n",
      "```\n",
      "\n",
      "Explanation:\n",
      "- **TechniqueID**: `T1078` - This technique involves elevating privileges by injecting malicious code into legitimate processes.\n",
      "- **TechniqueName**: `Elevate Privileges via Process Injection` - This describes how adversaries can manipulate system processes to gain elevated privileges without directly compromising the integrity of the operating system.\n",
      "- **Matrix**: `enterprise` - This indicates that this technique is applicable across enterprise environments where traditional security measures might be less effective due to the nature of process injection.\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "üìù Test Case 2:\n",
      "Input: Attackers send phishing emails with malicious attachments to gain initial access to the target system.\n",
      "Output: system\n",
      "You are a cybersecurity expert specializing in MITRE ATT&CK framework. Your task is to analyze threat intelligence descriptions and identify the corresponding MITRE ATT&CK techniques.\n",
      "\n",
      "Given a description of adversary behavior, identify the most relevant MITRE ATT&CK technique and provide:\n",
      "1. Technique ID (e.g., T1055.011)\n",
      "2. Technique Name\n",
      "3. Matrix (enterprise/mobile/ics)\n",
      "\n",
      "Respond in JSON format.\n",
      "user\n",
      "Analyze this threat behavior and identify the MITRE ATT&CK technique:\n",
      "\n",
      "Attackers send phishing emails with malicious attachments to gain initial access to the target system.\n",
      "assistant\n",
      "```json\n",
      "{\n",
      "  \"TechniqueID\": \"T1047\",\n",
      "  \"TechniqueName\": \"Create Phishing Campaigns\",\n",
      "  \"Matrix\": \"enterprise\"\n",
      "}\n",
      "```\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "üìù Test Case 3:\n",
      "Input: The malware establishes persistence by creating scheduled tasks that execute at system startup.\n",
      "Output: system\n",
      "You are a cybersecurity expert specializing in MITRE ATT&CK framework. Your task is to analyze threat intelligence descriptions and identify the corresponding MITRE ATT&CK techniques.\n",
      "\n",
      "Given a description of adversary behavior, identify the most relevant MITRE ATT&CK technique and provide:\n",
      "1. Technique ID (e.g., T1055.011)\n",
      "2. Technique Name\n",
      "3. Matrix (enterprise/mobile/ics)\n",
      "\n",
      "Respond in JSON format.\n",
      "user\n",
      "Analyze this threat behavior and identify the MITRE ATT&CK technique:\n",
      "\n",
      "The malware establishes persistence by creating scheduled tasks that execute at system startup.\n",
      "assistant\n",
      "```json\n",
      "{\n",
      "  \"TechniqueID\": \"T1078\",\n",
      "  \"TechniqueName\": \"Create Scheduled Tasks\",\n",
      "  \"Matrix\": \"enterprise\"\n",
      "}\n",
      "```\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "üìù Test Case 4:\n",
      "Input: Adversaries may abuse elevation control mechanisms to gain higher-level permissions on a system.\n",
      "Output: system\n",
      "You are a cybersecurity expert specializing in MITRE ATT&CK framework. Your task is to analyze threat intelligence descriptions and identify the corresponding MITRE ATT&CK techniques.\n",
      "\n",
      "Given a description of adversary behavior, identify the most relevant MITRE ATT&CK technique and provide:\n",
      "1. Technique ID (e.g., T1055.011)\n",
      "2. Technique Name\n",
      "3. Matrix (enterprise/mobile/ics)\n",
      "\n",
      "Respond in JSON format.\n",
      "user\n",
      "Analyze this threat behavior and identify the MITRE ATT&CK technique:\n",
      "\n",
      "Adversaries may abuse elevation control mechanisms to gain higher-level permissions on a system.\n",
      "assistant\n",
      "```json\n",
      "{\n",
      "  \"TechniqueID\": \"T1078\",\n",
      "  \"TechniqueName\": \"Elevation of Privilege\",\n",
      "  \"Matrix\": \"enterprise\"\n",
      "}\n",
      "```\n",
      "\n",
      "Explanation:\n",
      "- **TechniqueID**: `T1078` corresponds to the MITRE ATT&CK technique for Elevation of Privilege.\n",
      "- **TechniqueName**: This technique involves gaining elevated privileges by exploiting vulnerabilities or misconfigurations that allow an attacker to escalate their access level within a system.\n",
      "- **Matrix**: The technique is categorized under enterprise, which means it applies to both Windows and Linux environments.\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def test_ttp_classification(model, tokenizer, threat_description: str) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Test TTP classification on a threat description\n",
    "    \"\"\"\n",
    "    system_prompt = \"\"\"You are a cybersecurity expert specializing in MITRE ATT&CK framework. Your task is to analyze threat intelligence descriptions and identify the corresponding MITRE ATT&CK techniques.\n",
    "\n",
    "Given a description of adversary behavior, identify the most relevant MITRE ATT&CK technique and provide:\n",
    "1. Technique ID (e.g., T1055.011)\n",
    "2. Technique Name\n",
    "3. Matrix (enterprise/mobile/ics)\n",
    "\n",
    "Respond in JSON format.\"\"\"\n",
    "\n",
    "    user_input = f\"Analyze this threat behavior and identify the MITRE ATT&CK technique:\\n\\n{threat_description}\"\n",
    "\n",
    "    # Format input\n",
    "    prompt = f\"\"\"<|im_start|>system\n",
    "{system_prompt}<|im_end|>\n",
    "<|im_start|>user\n",
    "{user_input}<|im_end|>\n",
    "<|im_start|>assistant\n",
    "\"\"\"\n",
    "\n",
    "    # Tokenize\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=1024)\n",
    "    inputs = {k: v.to(model.device) for k, v in inputs.items()}\n",
    "\n",
    "    # Generate response\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=256,\n",
    "            temperature=0.1,\n",
    "            do_sample=True,\n",
    "            pad_token_id=tokenizer.eos_token_id\n",
    "        )\n",
    "\n",
    "    # Decode response\n",
    "    full_response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    assistant_response = full_response.split(\"<|im_start|>assistant\\n\")[-1]\n",
    "\n",
    "    return {\n",
    "        \"input\": threat_description,\n",
    "        \"response\": assistant_response,\n",
    "        \"full_prompt\": prompt\n",
    "    }\n",
    "\n",
    "# Test examples\n",
    "test_cases = [\n",
    "    \"Adversaries may inject malicious code into processes in order to evade process-based defenses or elevate privileges.\",\n",
    "    \"Attackers send phishing emails with malicious attachments to gain initial access to the target system.\",\n",
    "    \"The malware establishes persistence by creating scheduled tasks that execute at system startup.\",\n",
    "    \"Adversaries may abuse elevation control mechanisms to gain higher-level permissions on a system.\"\n",
    "]\n",
    "\n",
    "print(\"üß™ Testing model inference...\")\n",
    "for i, test_case in enumerate(test_cases, 1):\n",
    "    print(f\"\\nüìù Test Case {i}:\")\n",
    "    print(f\"Input: {test_case}\")\n",
    "\n",
    "    result = test_ttp_classification(model, tokenizer, test_case)\n",
    "    print(f\"Output: {result['response']}\")\n",
    "    print(\"-\" * 80)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## 10. Save Training Summary\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 11. Batch TTP Classification from File and Relationship Analysis\n",
    "\n",
    "This section loads a threat intelligence file, runs batch TTP classification with the (fine-tuned) Qwen model, extracts hash values, and analyzes relationships between:\n",
    "- Threat types (labels/categories in your data)\n",
    "- Techniques (MITRE ATT&CK technique IDs)\n",
    "- Hash values (MD5/SHA1/SHA256)\n",
    "\n",
    "Outputs:\n",
    "- Predictions dataset (`CSV` + `JSONL`)\n",
    "- Relationship edge list (`JSON`)\n",
    "- Knowledge graph export (`.gexf` for Gephi/NetworkX)\n",
    "\n",
    "Notes:\n",
    "- Techniques are labeled strictly by technique `id` (e.g., `T1055.011`).\n",
    "- The loader is schema-flexible; configure field mappings if needed.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-09T04:18:07.333145Z",
     "start_time": "2025-08-09T03:58:35.840159Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Loading records from: ../data/raw/threat_intelligence_multi_source_20250726_231524.json\n",
      "‚úÖ Loaded 257 records\n",
      "üß† Running TTP classification...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|‚ñà‚ñâ        | 51/257 [19:30<1:18:49, 22.96s/it]  \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[29], line 195\u001B[0m\n\u001B[1;32m    192\u001B[0m threat_type \u001B[38;5;241m=\u001B[39m _first_present(rec, FIELD_MAP[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mthreat_type\u001B[39m\u001B[38;5;124m\"\u001B[39m], default\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[1;32m    193\u001B[0m title \u001B[38;5;241m=\u001B[39m _first_present(rec, FIELD_MAP[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtitle\u001B[39m\u001B[38;5;124m\"\u001B[39m], default\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[0;32m--> 195\u001B[0m tech_id, tech_name, matrix, raw_resp \u001B[38;5;241m=\u001B[39m \u001B[43mclassify_one\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtext_val\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    196\u001B[0m hashes \u001B[38;5;241m=\u001B[39m _extract_hashes(rec)\n\u001B[1;32m    198\u001B[0m results\u001B[38;5;241m.\u001B[39mappend({\n\u001B[1;32m    199\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrecord_id\u001B[39m\u001B[38;5;124m\"\u001B[39m: rec_id,\n\u001B[1;32m    200\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtitle\u001B[39m\u001B[38;5;124m\"\u001B[39m: title,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    207\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mraw_response\u001B[39m\u001B[38;5;124m\"\u001B[39m: raw_resp,\n\u001B[1;32m    208\u001B[0m })\n",
      "Cell \u001B[0;32mIn[29], line 120\u001B[0m, in \u001B[0;36mclassify_one\u001B[0;34m(text_value)\u001B[0m\n\u001B[1;32m    117\u001B[0m inputs \u001B[38;5;241m=\u001B[39m {k: v\u001B[38;5;241m.\u001B[39mto(model\u001B[38;5;241m.\u001B[39mdevice) \u001B[38;5;28;01mfor\u001B[39;00m k, v \u001B[38;5;129;01min\u001B[39;00m inputs\u001B[38;5;241m.\u001B[39mitems()}\n\u001B[1;32m    119\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mno_grad():\n\u001B[0;32m--> 120\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgenerate\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    121\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    122\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmax_new_tokens\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m256\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    123\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtemperature\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0.1\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    124\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdo_sample\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    125\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpad_token_id\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtokenizer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43meos_token_id\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    126\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    128\u001B[0m full_response \u001B[38;5;241m=\u001B[39m tokenizer\u001B[38;5;241m.\u001B[39mdecode(outputs[\u001B[38;5;241m0\u001B[39m], skip_special_tokens\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m    129\u001B[0m assistant_response \u001B[38;5;241m=\u001B[39m full_response\u001B[38;5;241m.\u001B[39msplit(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m<|im_start|>assistant\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m]\n",
      "File \u001B[0;32m~/Documents/UIT/2nd/NLP/LLM-TKIG/.venv/lib/python3.12/site-packages/torch/utils/_contextlib.py:120\u001B[0m, in \u001B[0;36mcontext_decorator.<locals>.decorate_context\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    117\u001B[0m \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mwraps(func)\n\u001B[1;32m    118\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mdecorate_context\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m    119\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m ctx_factory():\n\u001B[0;32m--> 120\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/UIT/2nd/NLP/LLM-TKIG/.venv/lib/python3.12/site-packages/transformers/generation/utils.py:2625\u001B[0m, in \u001B[0;36mGenerationMixin.generate\u001B[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, use_model_defaults, custom_generate, **kwargs)\u001B[0m\n\u001B[1;32m   2617\u001B[0m     input_ids, model_kwargs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_expand_inputs_for_generation(\n\u001B[1;32m   2618\u001B[0m         input_ids\u001B[38;5;241m=\u001B[39minput_ids,\n\u001B[1;32m   2619\u001B[0m         expand_size\u001B[38;5;241m=\u001B[39mgeneration_config\u001B[38;5;241m.\u001B[39mnum_return_sequences,\n\u001B[1;32m   2620\u001B[0m         is_encoder_decoder\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39mis_encoder_decoder,\n\u001B[1;32m   2621\u001B[0m         \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mmodel_kwargs,\n\u001B[1;32m   2622\u001B[0m     )\n\u001B[1;32m   2624\u001B[0m     \u001B[38;5;66;03m# 12. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001B[39;00m\n\u001B[0;32m-> 2625\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_sample\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   2626\u001B[0m \u001B[43m        \u001B[49m\u001B[43minput_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2627\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlogits_processor\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mprepared_logits_processor\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2628\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstopping_criteria\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mprepared_stopping_criteria\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2629\u001B[0m \u001B[43m        \u001B[49m\u001B[43mgeneration_config\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgeneration_config\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2630\u001B[0m \u001B[43m        \u001B[49m\u001B[43msynced_gpus\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msynced_gpus\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2631\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstreamer\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstreamer\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2632\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mmodel_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2633\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   2635\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m generation_mode \u001B[38;5;129;01min\u001B[39;00m (GenerationMode\u001B[38;5;241m.\u001B[39mBEAM_SAMPLE, GenerationMode\u001B[38;5;241m.\u001B[39mBEAM_SEARCH):\n\u001B[1;32m   2636\u001B[0m     \u001B[38;5;66;03m# 11. interleave input_ids with `num_beams` additional sequences per batch\u001B[39;00m\n\u001B[1;32m   2637\u001B[0m     input_ids, model_kwargs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_expand_inputs_for_generation(\n\u001B[1;32m   2638\u001B[0m         input_ids\u001B[38;5;241m=\u001B[39minput_ids,\n\u001B[1;32m   2639\u001B[0m         expand_size\u001B[38;5;241m=\u001B[39mgeneration_config\u001B[38;5;241m.\u001B[39mnum_beams,\n\u001B[1;32m   2640\u001B[0m         is_encoder_decoder\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39mis_encoder_decoder,\n\u001B[1;32m   2641\u001B[0m         \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mmodel_kwargs,\n\u001B[1;32m   2642\u001B[0m     )\n",
      "File \u001B[0;32m~/Documents/UIT/2nd/NLP/LLM-TKIG/.venv/lib/python3.12/site-packages/transformers/generation/utils.py:3651\u001B[0m, in \u001B[0;36mGenerationMixin._sample\u001B[0;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, **model_kwargs)\u001B[0m\n\u001B[1;32m   3649\u001B[0m     probs \u001B[38;5;241m=\u001B[39m nn\u001B[38;5;241m.\u001B[39mfunctional\u001B[38;5;241m.\u001B[39msoftmax(next_token_scores, dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m   3650\u001B[0m     \u001B[38;5;66;03m# TODO (joao): this OP throws \"skipping cudagraphs due to ['incompatible ops']\", find solution\u001B[39;00m\n\u001B[0;32m-> 3651\u001B[0m     next_tokens \u001B[38;5;241m=\u001B[39m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmultinomial\u001B[49m\u001B[43m(\u001B[49m\u001B[43mprobs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_samples\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39msqueeze(\u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m   3652\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   3653\u001B[0m     next_tokens \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39margmax(next_token_scores, dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import uuid\n",
    "from datetime import datetime\n",
    "from typing import Dict, Any, List, Tuple, Optional\n",
    "\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ========== Config ==========\n",
    "# Input file with threat intel. You can switch to any structured JSON/JSONL/CSV.\n",
    "INPUT_FILE = \"../data/raw/threat_intelligence_multi_source_20250726_231524.json\"  # adjust if needed\n",
    "# Optional: limit number of records for quick tests\n",
    "MAX_RECORDS: Optional[int] = 5\n",
    "\n",
    "# Field mappings (adjust to your data schema)\n",
    "FIELD_MAP = {\n",
    "    \"id\": [\"id\", \"_id\", \"uuid\"],\n",
    "    \"threat_type\": [\"threat_type\", \"type\", \"category\", \"topic\"],\n",
    "    \"title\": [\"title\", \"headline\"],\n",
    "    \"text\": [\"text\", \"content\", \"description\", \"body\"],\n",
    "    \"hashes\": [\"hashes\", \"artifacts.hashes\", \"ioc.hashes\", \"ioc\"],\n",
    "}\n",
    "\n",
    "# Output directory\n",
    "REL_TIMESTAMP = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "REL_OUT_DIR = f\"../models/ttp_batch_analysis_{REL_TIMESTAMP}\"\n",
    "os.makedirs(REL_OUT_DIR, exist_ok=True)\n",
    "\n",
    "HASH_REGEX = re.compile(r\"\\b([A-Fa-f0-9]{32}|[A-Fa-f0-9]{40}|[A-Fa-f0-9]{64})\\b\")  # MD5|SHA1|SHA256\n",
    "\n",
    "\n",
    "def _coerce_text(raw: Any) -> str:\n",
    "    \"\"\"Coerce list/dict/other into a single plain text string.\"\"\"\n",
    "    if raw is None:\n",
    "        return \"\"\n",
    "    if isinstance(raw, str):\n",
    "        return raw\n",
    "    if isinstance(raw, list):\n",
    "        return \" \".join([str(x) for x in raw if isinstance(x, (str, int, float))])\n",
    "    if isinstance(raw, dict):\n",
    "        return \" \".join([str(v) for v in raw.values() if isinstance(v, (str, int, float))])\n",
    "    return str(raw)\n",
    "\n",
    "def _first_present(d: Dict[str, Any], keys: List[str], default: Any = None):\n",
    "    for k in keys:\n",
    "        # support dotted paths like 'artifacts.hashes'\n",
    "        node = d\n",
    "        valid = True\n",
    "        for part in k.split('.'):\n",
    "            if isinstance(node, dict) and part in node:\n",
    "                node = node[part]\n",
    "            else:\n",
    "                valid = False\n",
    "                break\n",
    "        if valid:\n",
    "            return node\n",
    "    return default\n",
    "\n",
    "\n",
    "def _extract_hashes(record: Dict[str, Any]) -> List[str]:\n",
    "    # Try mapped fields first\n",
    "    hashes_field = _first_present(record, FIELD_MAP[\"hashes\"], default=None)\n",
    "    found: List[str] = []\n",
    "    if isinstance(hashes_field, list):\n",
    "        for x in hashes_field:\n",
    "            if isinstance(x, str) and HASH_REGEX.fullmatch(x):\n",
    "                found.append(x.lower())\n",
    "            elif isinstance(x, dict):\n",
    "                for v in x.values():\n",
    "                    if isinstance(v, str) and HASH_REGEX.fullmatch(v):\n",
    "                        found.append(v.lower())\n",
    "    elif isinstance(hashes_field, dict):\n",
    "        for v in hashes_field.values():\n",
    "            if isinstance(v, str) and HASH_REGEX.fullmatch(v):\n",
    "                found.append(v.lower())\n",
    "            elif isinstance(v, list):\n",
    "                for x in v:\n",
    "                    if isinstance(x, str) and HASH_REGEX.fullmatch(x):\n",
    "                        found.append(x.lower())\n",
    "    # Fallback: scan text (coerce list/dict to string)\n",
    "    raw_text = _first_present(record, FIELD_MAP[\"text\"], default=\"\")\n",
    "    text = _coerce_text(raw_text)\n",
    "    found += [h.lower() for h in HASH_REGEX.findall(text)]\n",
    "    # Normalize unique\n",
    "    uniq = sorted(set(found))\n",
    "    return uniq\n",
    "\n",
    "\n",
    "def _make_prompt(threat_text: str) -> str:\n",
    "    system_prompt = (\n",
    "        \"You are a cybersecurity expert specializing in MITRE ATT&CK framework. \"\n",
    "        \"Your task is to analyze threat intelligence descriptions and identify the corresponding MITRE ATT&CK techniques.\\n\\n\"\n",
    "        \"Given a description of adversary behavior, identify the most relevant MITRE ATT&CK technique and provide:\\n\"\n",
    "        \"1. Technique ID (e.g., T1055.011)\\n\"\n",
    "        \"2. Technique Name\\n\"\n",
    "        \"3. Matrix (enterprise/mobile/ics)\\n\\n\"\n",
    "        \"Respond in JSON format.\"\n",
    "    )\n",
    "    user_input = f\"Analyze this threat behavior and identify the MITRE ATT&CK technique:\\n\\n{threat_text}\"\n",
    "    return (\n",
    "        f\"<|im_start|>system\\n{system_prompt}<|im_end|>\\n\"\n",
    "        f\"<|im_start|>user\\n{user_input}<|im_end|>\\n\"\n",
    "        f\"<|im_start|>assistant\\n\"\n",
    "    )\n",
    "\n",
    "\n",
    "def classify_one(text_value: str) -> Tuple[Optional[str], Optional[str], Optional[str], str]:\n",
    "    \"\"\"Run model inference; return (technique_id, technique_name, matrix, raw_response).\"\"\"\n",
    "    if not text_value or not isinstance(text_value, str):\n",
    "        return None, None, None, \"\"\n",
    "\n",
    "    prompt = _make_prompt(text_value)\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=1024)\n",
    "    inputs = {k: v.to(model.device) for k, v in inputs.items()}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=128,\n",
    "            temperature=0.0,\n",
    "            do_sample=False,\n",
    "            pad_token_id=tokenizer.eos_token_id,\n",
    "        )\n",
    "\n",
    "    full_response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    assistant_response = full_response.split(\"<|im_start|>assistant\\n\")[-1]\n",
    "\n",
    "    # Try to parse JSON\n",
    "    tech_id = tech_name = matrix = None\n",
    "    try:\n",
    "        # Extract JSON block if wrapped\n",
    "        json_match = re.search(r\"\\{[\\s\\S]*\\}\", assistant_response)\n",
    "        if json_match:\n",
    "            data = json.loads(json_match.group(0))\n",
    "        else:\n",
    "            data = json.loads(assistant_response)\n",
    "        tech_id = (data.get(\"technique_id\") or data.get(\"id\") or \"\").strip() or None\n",
    "        tech_name = (data.get(\"technique_name\") or data.get(\"name\") or \"\").strip() or None\n",
    "        matrix = (data.get(\"matrix\") or \"\").strip() or None\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    # Ensure technique id label format\n",
    "    if tech_id and not re.match(r\"^T\\d{4}(?:\\.\\d{3})?$\", tech_id):\n",
    "        tech_id = None\n",
    "\n",
    "    return tech_id, tech_name, matrix, assistant_response\n",
    "\n",
    "\n",
    "def load_records(input_path: str) -> List[Dict[str, Any]]:\n",
    "    if input_path.endswith(\".jsonl\"):\n",
    "        rows = []\n",
    "        with open(input_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            for line in f:\n",
    "                if line.strip():\n",
    "                    rows.append(json.loads(line))\n",
    "        return rows\n",
    "    elif input_path.endswith(\".json\"):\n",
    "        with open(input_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            data = json.load(f)\n",
    "        # try top-level list or known keys\n",
    "        if isinstance(data, list):\n",
    "            return data\n",
    "        for key in [\"data\", \"items\", \"records\", \"dataset\", \"documents\"]:\n",
    "            if key in data and isinstance(data[key], list):\n",
    "                return data[key]\n",
    "        # fallback: single object\n",
    "        return [data]\n",
    "    elif input_path.endswith(\".csv\"):\n",
    "        df = pd.read_csv(input_path)\n",
    "        return df.to_dict(orient=\"records\")\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported file type: {input_path}\")\n",
    "\n",
    "\n",
    "print(f\"üìÇ Loading records from: {INPUT_FILE}\")\n",
    "records = load_records(INPUT_FILE)\n",
    "if MAX_RECORDS is not None:\n",
    "    records = records[:MAX_RECORDS]\n",
    "print(f\"‚úÖ Loaded {len(records)} records\")\n",
    "\n",
    "# Inference\n",
    "results: List[Dict[str, Any]] = []\n",
    "print(\"üß† Running TTP classification...\")\n",
    "for rec in tqdm(records):\n",
    "    rec_id = _first_present(rec, FIELD_MAP[\"id\"], default=str(uuid.uuid4()))\n",
    "    raw_val = _first_present(rec, FIELD_MAP[\"text\"], default=\"\")\n",
    "    text_val = _coerce_text(raw_val)\n",
    "    threat_type = _first_present(rec, FIELD_MAP[\"threat_type\"], default=None)\n",
    "    title = _first_present(rec, FIELD_MAP[\"title\"], default=None)\n",
    "\n",
    "    tech_id, tech_name, matrix, raw_resp = classify_one(text_val)\n",
    "    hashes = _extract_hashes(rec)\n",
    "\n",
    "    results.append({\n",
    "        \"record_id\": rec_id,\n",
    "        \"title\": title,\n",
    "        \"threat_type\": threat_type,\n",
    "        \"text\": text_val,\n",
    "        \"technique_id\": tech_id,      # label: technique ID\n",
    "        \"technique_name\": tech_name,\n",
    "        \"matrix\": matrix,\n",
    "        \"hashes\": hashes,\n",
    "        \"raw_response\": raw_resp,\n",
    "    })\n",
    "\n",
    "# Save predictions\n",
    "pred_df = pd.DataFrame(results)\n",
    "pred_csv = os.path.join(REL_OUT_DIR, \"ttp_predictions.csv\")\n",
    "pred_jsonl = os.path.join(REL_OUT_DIR, \"ttp_predictions.jsonl\")\n",
    "pred_df.to_csv(pred_csv, index=False)\n",
    "with open(pred_jsonl, \"w\", encoding=\"utf-8\") as f:\n",
    "    for row in results:\n",
    "        f.write(json.dumps(row, ensure_ascii=False) + \"\\n\")\n",
    "print(f\"üìÑ Saved predictions to: {pred_csv} and {pred_jsonl}\")\n",
    "\n",
    "# Build relationships graph: ThreatType -> TechniqueID, Hash -> TechniqueID\n",
    "G = nx.DiGraph()\n",
    "\n",
    "for row in results:\n",
    "    rec_id = row[\"record_id\"]\n",
    "    threat_type = row.get(\"threat_type\")\n",
    "    technique_id = row.get(\"technique_id\")\n",
    "    tech_name = row.get(\"technique_name\")\n",
    "    matrix = row.get(\"matrix\")\n",
    "    hashes = row.get(\"hashes\") or []\n",
    "\n",
    "    # Nodes\n",
    "    if threat_type:\n",
    "        G.add_node((\"threat_type\", threat_type), label=\"threat_type\", name=threat_type)\n",
    "    if technique_id:\n",
    "        G.add_node((\"technique\", technique_id), label=\"technique\", name=technique_id, tech_name=tech_name, matrix=matrix)\n",
    "    for h in hashes:\n",
    "        G.add_node((\"hash\", h), label=\"hash\", name=h)\n",
    "\n",
    "    # Edges\n",
    "    if threat_type and technique_id:\n",
    "        G.add_edge((\"threat_type\", threat_type), (\"technique\", technique_id), relation=\"HAS_TECHNIQUE\")\n",
    "    for h in hashes:\n",
    "        if technique_id:\n",
    "            G.add_edge((\"hash\", h), (\"technique\", technique_id), relation=\"INDICATES_TECHNIQUE\")\n",
    "        # Optionally link record->hash for provenance\n",
    "        G.add_edge((\"hash\", h), (\"threat_type\", threat_type) if threat_type else (\"record\", rec_id), relation=\"ASSOCIATED_WITH\")\n",
    "\n",
    "# Export graph\n",
    "gexf_path = os.path.join(REL_OUT_DIR, \"ttp_relations.gexf\")\n",
    "nx.write_gexf(G, gexf_path)\n",
    "print(f\"üï∏Ô∏è Graph exported to: {gexf_path}\")\n",
    "\n",
    "# Export edge list JSON\n",
    "edges = [\n",
    "    {\n",
    "        \"source_type\": s[0],\n",
    "        \"source\": s[1],\n",
    "        \"target_type\": t[0],\n",
    "        \"target\": t[1],\n",
    "        \"relation\": data.get(\"relation\"),\n",
    "    }\n",
    "    for s, t, data in G.edges(data=True)\n",
    "]\n",
    "edges_path = os.path.join(REL_OUT_DIR, \"ttp_edges.json\")\n",
    "with open(edges_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(edges, f, indent=2, ensure_ascii=False)\n",
    "print(f\"üîó Edge list saved to: {edges_path}\")\n",
    "\n",
    "print(\"‚úÖ Done.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "### 11.1 Relationship summaries (counts)\n",
    "\n",
    "This cell summarizes co-occurrences:\n",
    "- Threat type ‚Üî Technique ID counts\n",
    "- Hash ‚Üî Technique ID counts\n",
    "\n",
    "It saves CSV summaries alongside the predictions and graph.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-09T04:18:07.393175Z",
     "start_time": "2025-08-09T03:15:59.195065Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÑ Saved: ../models/ttp_batch_analysis_2025-08-09_10-15-44/summary_threattype_technique.csv\n",
      "üìÑ Saved: ../models/ttp_batch_analysis_2025-08-09_10-15-44/summary_hash_technique.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>threat_type</th>\n",
       "      <th>technique_id</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [threat_type, technique_id, count]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hash</th>\n",
       "      <th>technique_id</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [hash, technique_id, count]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Summaries\n",
    "from collections import Counter\n",
    "\n",
    "# Threat type ‚Üî Technique ID\n",
    "pair_counts_tt = Counter()\n",
    "for row in results:\n",
    "    threat_type = row.get(\"threat_type\")\n",
    "    technique_id = row.get(\"technique_id\")\n",
    "    if threat_type and technique_id:\n",
    "        pair_counts_tt[(threat_type, technique_id)] += 1\n",
    "\n",
    "summary_tt = pd.DataFrame(\n",
    "    [(tt, tid, c) for (tt, tid), c in pair_counts_tt.items()],\n",
    "    columns=[\"threat_type\", \"technique_id\", \"count\"],\n",
    ").sort_values(\"count\", ascending=False)\n",
    "\n",
    "# Hash ‚Üî Technique ID\n",
    "pair_counts_ht = Counter()\n",
    "for row in results:\n",
    "    technique_id = row.get(\"technique_id\")\n",
    "    for h in row.get(\"hashes\") or []:\n",
    "        if technique_id:\n",
    "            pair_counts_ht[(h, technique_id)] += 1\n",
    "\n",
    "summary_ht = pd.DataFrame(\n",
    "    [(h, tid, c) for (h, tid), c in pair_counts_ht.items()],\n",
    "    columns=[\"hash\", \"technique_id\", \"count\"],\n",
    ").sort_values(\"count\", ascending=False)\n",
    "\n",
    "# Save\n",
    "summary_tt_csv = os.path.join(REL_OUT_DIR, \"summary_threattype_technique.csv\")\n",
    "summary_ht_csv = os.path.join(REL_OUT_DIR, \"summary_hash_technique.csv\")\n",
    "summary_tt.to_csv(summary_tt_csv, index=False)\n",
    "summary_ht.to_csv(summary_ht_csv, index=False)\n",
    "\n",
    "print(f\"üìÑ Saved: {summary_tt_csv}\")\n",
    "print(f\"üìÑ Saved: {summary_ht_csv}\")\n",
    "\n",
    "# Display top rows\n",
    "display(summary_tt.head(20))\n",
    "display(summary_ht.head(20))\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "### 11.2 Build extended relationships JSON (per-record)\n",
    "\n",
    "This step:\n",
    "- Extracts multiple techniques from `content` using the model (top-k list)\n",
    "- Creates `extended_relationships` as requested\n",
    "- Produces a JSON file under `data/TTP-classification/`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb-core(10761) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "wandb-core(10762) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "wandb-core(10765) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "wandb-core(10766) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    }
   ],
   "source": [
    "# Quick test overrides\n",
    "TOP_K = 3  # limit techniques per record\n",
    "print(f\"TOP_K overridden to: {TOP_K}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-09T07:34:11.742933Z",
     "start_time": "2025-08-09T07:29:17.164662Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß© Building extended relationships per record...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [04:53<00:00, 58.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Extended relationships saved to: ../data/TTP-classification/extended_relationships_output.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from typing import Iterable\n",
    "\n",
    "# Settings for multi-technique extraction\n",
    "TOP_K = 6  # max techniques to extract per record\n",
    "SAVE_JSON_PATH = \"../data/TTP-classification/extended_relationships_output.json\"\n",
    "\n",
    "# Local fallback in case _coerce_text wasn't executed in earlier cells\n",
    "try:\n",
    "    _coerce_text\n",
    "except NameError:\n",
    "    def _coerce_text(raw):\n",
    "        if raw is None:\n",
    "            return \"\"\n",
    "        if isinstance(raw, str):\n",
    "            return raw\n",
    "        if isinstance(raw, list):\n",
    "            return \" \".join(str(x) for x in raw if isinstance(x, (str, int, float)))\n",
    "        if isinstance(raw, dict):\n",
    "            return \" \".join(str(v) for v in raw.values() if isinstance(v, (str, int, float)))\n",
    "        return str(raw)\n",
    "\n",
    "def classify_multiple_techniques(threat_text: str, top_k: int = TOP_K) -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Query the model to extract up to top_k techniques from text.\n",
    "    Returns list of {id, name, description, matrix} using technique ids as labels.\n",
    "    \"\"\"\n",
    "    if not threat_text or not isinstance(threat_text, str):\n",
    "        return []\n",
    "\n",
    "    system_prompt = (\n",
    "        \"You are a cybersecurity expert specializing in MITRE ATT&CK framework. \"\n",
    "        \"Read the text and return a JSON object with a 'techniques' array listing up to N relevant techniques. \"\n",
    "        \"Each technique must include: id, name, description, matrix. Use MITRE technique ids strictly (e.g., T1218, T1218.011).\"\n",
    "    )\n",
    "    user_input = (\n",
    "        \"Extract up to N MITRE ATT&CK techniques from the following content. \"\n",
    "        f\"N={top_k}. Return JSON with key 'techniques'.\\n\\nContent:\\n{threat_text}\"\n",
    "    )\n",
    "\n",
    "    prompt = (\n",
    "        f\"<|im_start|>system\\n{system_prompt}<|im_end|>\\n\"\n",
    "        f\"<|im_start|>user\\n{user_input}<|im_end|>\\n\"\n",
    "        f\"<|im_start|>assistant\\n\"\n",
    "    )\n",
    "\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=2048)\n",
    "    inputs = {k: v.to(model.device) for k, v in inputs.items()}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=512,\n",
    "            temperature=0.2,\n",
    "            do_sample=True,\n",
    "            pad_token_id=tokenizer.eos_token_id,\n",
    "        )\n",
    "\n",
    "    resp = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    content = resp.split(\"<|im_start|>assistant\\n\")[-1]\n",
    "\n",
    "    # Parse JSON\n",
    "    techniques: List[Dict[str, Any]] = []\n",
    "    try:\n",
    "        json_match = re.search(r\"\\{[\\s\\S]*\\}\", content)\n",
    "        data = json.loads(json_match.group(0) if json_match else content)\n",
    "        items = data.get(\"techniques\") or data\n",
    "        if isinstance(items, dict) and \"techniques\" in items:\n",
    "            items = items[\"techniques\"]\n",
    "        if isinstance(items, list):\n",
    "            for t in items[:top_k]:\n",
    "                tid = (t.get(\"id\") or t.get(\"technique_id\") or \"\").strip()\n",
    "                if not re.match(r\"^T\\d{4}(?:\\.\\d{3})?$\", tid):\n",
    "                    continue\n",
    "                techniques.append({\n",
    "                    \"id\": tid,\n",
    "                    \"name\": t.get(\"name\"),\n",
    "                    \"description\": t.get(\"description\"),\n",
    "                    \"matrix\": t.get(\"matrix\"),\n",
    "                })\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    # Deduplicate by id\n",
    "    seen = set()\n",
    "    uniq: List[Dict[str, Any]] = []\n",
    "    for t in techniques:\n",
    "        if t[\"id\"] in seen:\n",
    "            continue\n",
    "        seen.add(t[\"id\"])\n",
    "        uniq.append(t)\n",
    "    return uniq\n",
    "\n",
    "\n",
    "def build_extended_relationships(record: Dict[str, Any], techniques: List[Dict[str, Any]]) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Construct extended_relationships.relationships using the requested format:\n",
    "    [ [subject, predicate, object], ... ]\n",
    "    - Map high-level threat types/entities to technique ids\n",
    "    - Also include 'associated_with' links from the main threat label to all techniques\n",
    "    \"\"\"\n",
    "    title = _first_present(record, FIELD_MAP[\"title\"], default=None)\n",
    "    link = record.get(\"link\") or record.get(\"url\")\n",
    "    raw_content = _first_present(record, FIELD_MAP[\"text\"], default=\"\")\n",
    "    content_text = _coerce_text(raw_content)\n",
    "\n",
    "    # Use existing entity extraction section if present\n",
    "    extraction = record.get(\"extraction\") or {}\n",
    "    ents = extraction.get(\"entities\") or []\n",
    "\n",
    "    # Collect subjects from entities and threat_type field\n",
    "    subjects: List[str] = []\n",
    "    if ents:\n",
    "        for item in ents:\n",
    "            if isinstance(item, (list, tuple)) and len(item) >= 2:\n",
    "                subjects.append(str(item[0]))\n",
    "    tt = _first_present(record, FIELD_MAP[\"threat_type\"], default=None)\n",
    "    if tt:\n",
    "        subjects.append(str(tt))\n",
    "\n",
    "    subjects = [s for s in {s.strip(): None for s in subjects}.keys() if s]\n",
    "\n",
    "    # Relationships\n",
    "    rels: List[List[str]] = []\n",
    "    # Example mapping rules: ransomware uses T1486 etc. We simply create generic relations here.\n",
    "    for subj in subjects:\n",
    "        for t in techniques:\n",
    "            rels.append([subj, \"associated_with\", t[\"id\"]])\n",
    "    # Add specific 'uses' if subject text suggests usage verbs in content\n",
    "    verbs = [\"use\", \"uses\", \"abuse\", \"abuses\", \"leverage\", \"leverages\", \"employ\", \"employs\"]\n",
    "    text_lower = content_text.lower() if isinstance(content_text, str) else _coerce_text(content_text).lower()\n",
    "    if any(v in text_lower for v in verbs):\n",
    "        for subj in subjects:\n",
    "            for t in techniques:\n",
    "                rels.append([subj, \"uses\", t[\"id\"]])\n",
    "\n",
    "    return {\n",
    "        \"title\": title,\n",
    "        \"link\": link,\n",
    "        \"content\": content_text,\n",
    "        \"extraction\": extraction or None,\n",
    "        \"ttp_classification\": {\n",
    "            \"instruction\": None,\n",
    "            \"input\": None,\n",
    "            \"output\": {\"techniques\": techniques},\n",
    "        },\n",
    "        \"extended_relationships\": {\"relationships\": rels},\n",
    "    }\n",
    "\n",
    "\n",
    "print(\"üß© Building extended relationships per record...\")\n",
    "extended_docs: List[Dict[str, Any]] = []\n",
    "for rec in tqdm(records):\n",
    "    raw_content = _first_present(rec, FIELD_MAP[\"text\"], default=\"\")\n",
    "    content_text = _coerce_text(raw_content)\n",
    "    techniques = classify_multiple_techniques(content_text, top_k=TOP_K)\n",
    "    extended = build_extended_relationships(rec, techniques)\n",
    "    extended_docs.append(extended)\n",
    "\n",
    "# Save to data/TTP-classification\n",
    "os.makedirs(\"../data/TTP-classification\", exist_ok=True)\n",
    "with open(SAVE_JSON_PATH, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(extended_docs, f, ensure_ascii=False, indent=2)\n",
    "print(f\"üíæ Extended relationships saved to: {SAVE_JSON_PATH}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-09T13:44:32.575431Z",
     "start_time": "2025-08-09T13:13:25.254492Z"
    }
   },
   "source": [
    "import os, json, re\n",
    "from typing import Dict, Any, List\n",
    "\n",
    "SRC_ENTITY_JSON = \"../data/entity-extraction/entity_extraction_results_Qwen/Qwen2.5-1.5B-Instruct_test_2025-08-04_09-45-09_250_300.json\"\n",
    "DST_JSON = \"../data/TTP-classification/qwen-ttp-classifiation/extended_relationships_output_250_300.json\"\n",
    "os.makedirs(os.path.dirname(DST_JSON), exist_ok=True)\n",
    "\n",
    "print(f\"üìÇ Loading entity-extraction file: {SRC_ENTITY_JSON}\")\n",
    "with open(SRC_ENTITY_JSON, \"r\", encoding=\"utf-8\") as f:\n",
    "    entity_records = json.load(f)\n",
    "print(f\"‚úÖ Loaded {len(entity_records)} records\")\n",
    "\n",
    "augmented: List[Dict[str, Any]] = []\n",
    "\n",
    "for rec in tqdm(entity_records):\n",
    "    title = rec.get(\"title\")\n",
    "    link = rec.get(\"link\") or rec.get(\"url\")\n",
    "    content_text = _coerce_text(rec.get(\"content\"))\n",
    "\n",
    "    # techniques via the multi-tech classifier\n",
    "    techniques = classify_multiple_techniques(content_text, top_k=TOP_K if 'TOP_K' in globals() else 6)\n",
    "\n",
    "    # relationships: subjects from extraction.entities and threat_type if exists\n",
    "    extraction = rec.get(\"extraction\") or {}\n",
    "    ents = extraction.get(\"entities\") or []\n",
    "    subjects = []\n",
    "    for item in ents:\n",
    "        if isinstance(item, (list, tuple)) and len(item) >= 2:\n",
    "            subjects.append(str(item[0]))\n",
    "    threat_type = rec.get(\"threat_type\")\n",
    "    if threat_type:\n",
    "        subjects.append(str(threat_type))\n",
    "    subjects = [s for s in {s.strip(): None for s in subjects}.keys() if s]\n",
    "\n",
    "    # uses only\n",
    "    rels: List[List[str]] = []\n",
    "    verbs = [\"use\", \"uses\", \"abuse\", \"abuses\", \"leverage\", \"leverages\", \"employ\", \"employs\"]\n",
    "    if any(v in content_text.lower() for v in verbs):\n",
    "        for subj in subjects:\n",
    "            for t in (techniques or [])[:1]:\n",
    "                rels.append([subj, \"uses\", t[\"id\"]])\n",
    "\n",
    "    # dedup\n",
    "    rels = [list(x) for x in dict.fromkeys(tuple(r) for r in rels)]\n",
    "\n",
    "    # append without changing original fields\n",
    "    out = dict(rec)\n",
    "    out[\"ttp_classification\"] = {\n",
    "        \"instruction\": None,\n",
    "        \"input\": None,\n",
    "        \"output\": {\"techniques\": techniques},\n",
    "    }\n",
    "    out[\"extended_relationships\"] = {\"relationships\": rels}\n",
    "\n",
    "    augmented.append(out)\n",
    "\n",
    "with open(DST_JSON, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(augmented, f, ensure_ascii=False, indent=2)\n",
    "print(f\"üíæ Written: {DST_JSON}\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Loading entity-extraction file: ../data/entity-extraction/entity_extraction_results_Qwen/Qwen2.5-1.5B-Instruct_test_2025-08-04_09-45-09_250_300.json\n",
      "‚úÖ Loaded 50 records\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [31:07<00:00, 37.34s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Written: ../data/TTP-classification/qwen-ttp-classifiation/extended_relationships_output.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 40
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "### 11.2b Override relationships builder (uses only)\n",
    "\n",
    "This overrides `build_extended_relationships` to remove `associated_with` links and only add `uses` when verb cues are present (top-1 technique per subject).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_extended_relationships(record: Dict[str, Any], techniques: List[Dict[str, Any]]) -> Dict[str, Any]:\n",
    "    title = _first_present(record, FIELD_MAP[\"title\"], default=None)\n",
    "    link = record.get(\"link\") or record.get(\"url\")\n",
    "    raw_content = _first_present(record, FIELD_MAP[\"text\"], default=\"\")\n",
    "    content_text = _coerce_text(raw_content)\n",
    "\n",
    "    extraction = record.get(\"extraction\") or {}\n",
    "    ents = extraction.get(\"entities\") or []\n",
    "\n",
    "    subjects: List[str] = []\n",
    "    if ents:\n",
    "        for item in ents:\n",
    "            if isinstance(item, (list, tuple)) and len(item) >= 2:\n",
    "                subjects.append(str(item[0]))\n",
    "    tt = _first_present(record, FIELD_MAP[\"threat_type\"], default=None)\n",
    "    if tt:\n",
    "        subjects.append(str(tt))\n",
    "    subjects = [s for s in {s.strip(): None for s in subjects}.keys() if s]\n",
    "\n",
    "    # Relationships: uses only\n",
    "    rels: List[List[str]] = []\n",
    "    verbs = [\"use\", \"uses\", \"abuse\", \"abuses\", \"leverage\", \"leverages\", \"employ\", \"employs\"]\n",
    "    text_lower = content_text.lower()\n",
    "    if any(v in text_lower for v in verbs):\n",
    "        for subj in subjects:\n",
    "            for t in (techniques or [])[:1]:\n",
    "                rels.append([subj, \"uses\", t[\"id\"]])\n",
    "    rels = [list(x) for x in dict.fromkeys(tuple(r) for r in rels)]\n",
    "\n",
    "    return {\n",
    "        \"title\": title,\n",
    "        \"link\": link,\n",
    "        \"content\": content_text,\n",
    "        \"extraction\": extraction or None,\n",
    "        \"ttp_classification\": {\n",
    "            \"instruction\": None,\n",
    "            \"input\": None,\n",
    "            \"output\": {\"techniques\": techniques},\n",
    "        },\n",
    "        \"extended_relationships\": {\"relationships\": rels},\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
