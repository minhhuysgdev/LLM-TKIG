{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# TTP Classification Training with Qwen Model\n",
    "\n",
    "## Overview\n",
    "This notebook implements TTP (Tactics, Techniques, and Procedures) classification training using Qwen model with MITRE ATT&CK framework.\n",
    "\n",
    "### Task Description\n",
    "- **Input**: Threat intelligence text descriptions\n",
    "- **Output**: MITRE ATT&CK technique classification (T1xxx format)\n",
    "- **Model**: Qwen/Qwen2.5-1.5B-Instruct (fine-tuned)\n",
    "\n",
    "### Dataset Statistics\n",
    "- **Total samples**: 921 training examples\n",
    "- **Enterprise Matrix**: 691 techniques (222 main + 469 sub-techniques)\n",
    "- **Mobile Matrix**: 135 techniques (89 main + 46 sub-techniques)\n",
    "- **ICS Matrix**: 95 techniques (95 main + 0 sub-techniques)\n",
    "\n",
    "### Key Steps\n",
    "1. Load and prepare MITRE ATT&CK training data\n",
    "2. Setup Qwen model for fine-tuning\n",
    "3. Create training and validation splits\n",
    "4. Fine-tune model for TTP classification\n",
    "5. Evaluate model performance\n",
    "6. Test on real threat intelligence data\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 1. Environment Setup and Dependencies\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-08T07:19:26.656306Z",
     "start_time": "2025-08-08T07:19:22.772656Z"
    }
   },
   "source": [
    "import json\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Any, Tuple\n",
    "import logging\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Transformers and training\n",
    "from transformers import (\n",
    "    AutoTokenizer, \n",
    "    AutoModelForCausalLM,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    DataCollatorForLanguageModeling\n",
    ")\n",
    "from datasets import Dataset, DatasetDict\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "print(\"ğŸ“š Dependencies loaded successfully!\")\n",
    "print(f\"ğŸ”¥ PyTorch version: {torch.__version__}\")\n",
    "\n",
    "# Check device availability\n",
    "print(f\"ğŸ¤– CUDA available: {torch.cuda.is_available()}\")\n",
    "print(f\"ğŸ MPS available: {torch.backends.mps.is_available()}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"ğŸ® GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"ğŸ’¾ GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    print(f\"ğŸ Using Apple Silicon MPS\")\n",
    "    print(f\"ğŸ’» Device: Apple Silicon Mac\")\n",
    "else:\n",
    "    print(f\"âš ï¸  Using CPU only\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“š Dependencies loaded successfully!\n",
      "ğŸ”¥ PyTorch version: 2.8.0\n",
      "ğŸ¤– CUDA available: False\n",
      "ğŸ MPS available: True\n",
      "ğŸ Using Apple Silicon MPS\n",
      "ğŸ’» Device: Apple Silicon Mac\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 2. Load MITRE ATT&CK Training Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-08T07:19:22.039341Z",
     "start_time": "2025-08-08T07:15:00.921344Z"
    }
   },
   "source": [
    "# Load merged MITRE ATT&CK dataset\n",
    "dataset_path = \"../data/TTP-classification/merged_mitre_attack_dataset.json\"\n",
    "\n",
    "print(\"ğŸ“‚ Loading MITRE ATT&CK dataset...\")\n",
    "with open(dataset_path, 'r', encoding='utf-8') as f:\n",
    "    mitre_data = json.load(f)\n",
    "\n",
    "# Extract training samples\n",
    "training_samples = mitre_data['dataset']\n",
    "print(f\"âœ… Loaded {len(training_samples):,} training samples\")\n",
    "\n",
    "# Analyze dataset structure\n",
    "print(\"\\nğŸ“Š Dataset Analysis:\")\n",
    "matrices = {'enterprise': 0, 'mobile': 0, 'ics': 0}\n",
    "techniques_count = 0\n",
    "sub_techniques_count = 0\n",
    "technique_ids = set()\n",
    "\n",
    "for sample in training_samples:\n",
    "    technique = sample['output']['techniques'][0]\n",
    "    matrix = technique['matrix']\n",
    "    technique_id = technique['id']\n",
    "    \n",
    "    matrices[matrix] += 1\n",
    "    technique_ids.add(technique_id)\n",
    "    \n",
    "    if '.' in technique_id:\n",
    "        sub_techniques_count += 1\n",
    "    else:\n",
    "        techniques_count += 1\n",
    "\n",
    "print(f\"  â€¢ Enterprise: {matrices['enterprise']:,} samples\")\n",
    "print(f\"  â€¢ Mobile: {matrices['mobile']:,} samples\")\n",
    "print(f\"  â€¢ ICS: {matrices['ics']:,} samples\")\n",
    "print(f\"  â€¢ Techniques: {techniques_count:,} samples\")\n",
    "print(f\"  â€¢ Sub-techniques: {sub_techniques_count:,} samples\")\n",
    "print(f\"  â€¢ Unique technique IDs: {len(technique_ids):,}\")\n",
    "\n",
    "# Show sample data\n",
    "print(\"\\nğŸ“ Sample Training Example:\")\n",
    "sample = training_samples[0]\n",
    "print(f\"Instruction: {sample['instruction'][:100]}...\")\n",
    "print(f\"Technique ID: {sample['output']['techniques'][0]['id']}\")\n",
    "print(f\"Technique Name: {sample['output']['techniques'][0]['name']}\")\n",
    "print(f\"Matrix: {sample['output']['techniques'][0]['matrix']}\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“‚ Loading MITRE ATT&CK dataset...\n",
      "âœ… Loaded 921 training samples\n",
      "\n",
      "ğŸ“Š Dataset Analysis:\n",
      "  â€¢ Enterprise: 691 samples\n",
      "  â€¢ Mobile: 135 samples\n",
      "  â€¢ ICS: 95 samples\n",
      "  â€¢ Techniques: 406 samples\n",
      "  â€¢ Sub-techniques: 515 samples\n",
      "  â€¢ Unique technique IDs: 921\n",
      "\n",
      "ğŸ“ Sample Training Example:\n",
      "Instruction: Adversaries may inject malicious code into process via Extra Window Memory (EWM) in order to evade p...\n",
      "Technique ID: T1055.011\n",
      "Technique Name: Extra Window Memory Injection\n",
      "Matrix: enterprise\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 3. Setup Training Configuration (Fixed)\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-08T07:19:22.046989Z",
     "start_time": "2025-08-08T07:15:00.953015Z"
    }
   },
   "source": [
    "# Model configuration\n",
    "MODEL_NAME = \"Qwen/Qwen2.5-1.5B-Instruct\"\n",
    "MAX_LENGTH = 2048\n",
    "BATCH_SIZE = 4\n",
    "LEARNING_RATE = 2e-5\n",
    "NUM_EPOCHS = 3\n",
    "WARMUP_STEPS = 100\n",
    "\n",
    "print(f\"ğŸ¤– Setting up model: {MODEL_NAME}\")\n",
    "\n",
    "# Create output directory\n",
    "timestamp = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "output_dir = f\"../models/qwen-ttp-classification-{timestamp}\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "print(f\"ğŸ“ Output directory: {output_dir}\")\n",
    "\n",
    "# Training arguments (FIXED - eval_strategy instead of evaluation_strategy)\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    overwrite_output_dir=True,\n",
    "    \n",
    "    # Training parameters\n",
    "    num_train_epochs=NUM_EPOCHS,\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    per_device_eval_batch_size=BATCH_SIZE,\n",
    "    gradient_accumulation_steps=1,\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    weight_decay=0.01,\n",
    "    warmup_steps=WARMUP_STEPS,\n",
    "    \n",
    "    # Optimization (MPS compatible - FIXED)\n",
    "    fp16=torch.cuda.is_available(),  # Only use fp16 on CUDA\n",
    "    bf16=False,  # Disable bf16 - MPS doesn't support it in TrainingArguments\n",
    "    dataloader_pin_memory=False,\n",
    "    gradient_checkpointing=True,\n",
    "    \n",
    "    # Logging and saving\n",
    "    logging_dir=f\"{output_dir}/logs\",\n",
    "    logging_steps=10,\n",
    "    save_steps=100,\n",
    "    save_total_limit=3,\n",
    "    eval_steps=100,\n",
    "    eval_strategy=\"steps\",  # FIXED: was evaluation_strategy\n",
    "    \n",
    "    # Other settings\n",
    "    remove_unused_columns=False,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    "    greater_is_better=False,\n",
    "    \n",
    "    # Report\n",
    "    report_to=None,  # Disable wandb/tensorboard\n",
    "    run_name=f\"qwen-ttp-classification-{timestamp}\"\n",
    ")\n",
    "\n",
    "print(\"âœ… Training arguments configured (FIXED + MPS)\")\n",
    "print(f\"ğŸ¯ Batch size: {BATCH_SIZE}\")\n",
    "print(f\"ğŸ“ˆ Learning rate: {LEARNING_RATE}\")\n",
    "print(f\"ğŸ”„ Epochs: {NUM_EPOCHS}\")\n",
    "print(f\"ğŸ”¥ FP16 (CUDA only): {training_args.fp16}\")\n",
    "print(f\"ğŸ BF16 (Disabled): {training_args.bf16}\")\n",
    "print(f\"ğŸ’¾ Gradient checkpointing: {training_args.gradient_checkpointing}\")\n",
    "print(f\"ğŸ”§ FIXED: eval_strategy + MPS compatibility\")\n",
    "\n",
    "# Show which precision will be used\n",
    "if torch.cuda.is_available():\n",
    "    print(\"âš¡ Using FP16 precision for CUDA training\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    print(\"ğŸ Using FP32 precision for MPS training (safest option)\")\n",
    "else:\n",
    "    print(\"âš ï¸  Using FP32 precision for CPU training\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¤– Setting up model: Qwen/Qwen2.5-1.5B-Instruct\n",
      "ğŸ“ Output directory: ../models/qwen-ttp-classification-2025-08-08_14-15-00\n",
      "âœ… Training arguments configured (FIXED + MPS)\n",
      "ğŸ¯ Batch size: 4\n",
      "ğŸ“ˆ Learning rate: 2e-05\n",
      "ğŸ”„ Epochs: 3\n",
      "ğŸ”¥ FP16 (CUDA only): False\n",
      "ğŸ BF16 (Disabled): False\n",
      "ğŸ’¾ Gradient checkpointing: True\n",
      "ğŸ”§ FIXED: eval_strategy + MPS compatibility\n",
      "ğŸ Using FP32 precision for MPS training (safest option)\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 4. Prepare Training Data Format\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-08T07:19:22.047901Z",
     "start_time": "2025-08-08T07:15:00.992814Z"
    }
   },
   "source": [
    "def format_training_sample(sample: Dict[str, Any]) -> Dict[str, str]:\n",
    "    \"\"\"\n",
    "    Format training sample for instruction tuning\n",
    "    \"\"\"\n",
    "    instruction = sample['instruction']\n",
    "    technique = sample['output']['techniques'][0]\n",
    "    \n",
    "    # Create system prompt\n",
    "    system_prompt = \"\"\"You are a cybersecurity expert specializing in MITRE ATT&CK framework. Your task is to analyze threat intelligence descriptions and identify the corresponding MITRE ATT&CK techniques.\n",
    "\n",
    "Given a description of adversary behavior, identify the most relevant MITRE ATT&CK technique and provide:\n",
    "1. Technique ID (e.g., T1055.011)\n",
    "2. Technique Name\n",
    "3. Matrix (enterprise/mobile/ics)\n",
    "\n",
    "Respond in JSON format.\"\"\"\n",
    "    \n",
    "    # Create user input\n",
    "    user_input = f\"Analyze this threat behavior and identify the MITRE ATT&CK technique:\\n\\n{instruction}\"\n",
    "    \n",
    "    # Create assistant response\n",
    "    assistant_response = json.dumps({\n",
    "        \"technique_id\": technique['id'],\n",
    "        \"technique_name\": technique['name'],\n",
    "        \"matrix\": technique['matrix'],\n",
    "        \"description\": technique['description']\n",
    "    }, ensure_ascii=False)\n",
    "    \n",
    "    # Format for Qwen chat template\n",
    "    formatted_text = f\"\"\"<|im_start|>system\n",
    "{system_prompt}<|im_end|>\n",
    "<|im_start|>user\n",
    "{user_input}<|im_end|>\n",
    "<|im_start|>assistant\n",
    "{assistant_response}<|im_end|>\"\"\"\n",
    "    \n",
    "    return {\"text\": formatted_text}\n",
    "\n",
    "# Format all training samples\n",
    "print(\"ğŸ”„ Formatting training data...\")\n",
    "formatted_samples = []\n",
    "for sample in tqdm(training_samples):\n",
    "    formatted_sample = format_training_sample(sample)\n",
    "    formatted_samples.append(formatted_sample)\n",
    "\n",
    "print(f\"âœ… Formatted {len(formatted_samples):,} training samples\")\n",
    "\n",
    "# Show formatted example\n",
    "print(\"\\nğŸ“ Formatted Training Example:\")\n",
    "print(formatted_samples[0]['text'][:500] + \"...\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”„ Formatting training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 921/921 [00:00<00:00, 72455.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Formatted 921 training samples\n",
      "\n",
      "ğŸ“ Formatted Training Example:\n",
      "<|im_start|>system\n",
      "You are a cybersecurity expert specializing in MITRE ATT&CK framework. Your task is to analyze threat intelligence descriptions and identify the corresponding MITRE ATT&CK techniques.\n",
      "\n",
      "Given a description of adversary behavior, identify the most relevant MITRE ATT&CK technique and provide:\n",
      "1. Technique ID (e.g., T1055.011)\n",
      "2. Technique Name\n",
      "3. Matrix (enterprise/mobile/ics)\n",
      "\n",
      "Respond in JSON format.<|im_end|>\n",
      "<|im_start|>user\n",
      "Analyze this threat behavior and identify the MITRE ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 5. Setup Qwen Model and Tokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-08T07:19:22.048637Z",
     "start_time": "2025-08-08T07:15:01.064027Z"
    }
   },
   "source": [
    "# Setup device with MPS support\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(f\"ğŸ”§ Using device: CUDA\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "    print(f\"ğŸ”§ Using device: MPS (Apple Silicon)\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(f\"ğŸ”§ Using device: CPU\")\n",
    "\n",
    "print(f\"ğŸ“± Selected device: {device}\")\n",
    "\n",
    "# Load tokenizer\n",
    "print(\"ğŸ“ Loading tokenizer...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    trust_remote_code=True,\n",
    "    padding_side=\"right\"\n",
    ")\n",
    "\n",
    "# Add padding token if not exists\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    print(\"ğŸ”§ Set pad_token = eos_token\")\n",
    "\n",
    "print(f\"âœ… Tokenizer loaded\")\n",
    "print(f\"ğŸ“Š Vocab size: {len(tokenizer):,}\")\n",
    "\n",
    "# Load model with MPS support\n",
    "print(\"ğŸ¤– Loading model...\")\n",
    "\n",
    "# Set appropriate dtype based on device (FIXED for MPS)\n",
    "if torch.cuda.is_available():\n",
    "    torch_dtype = torch.float16  # FP16 for CUDA\n",
    "    device_map = \"auto\"\n",
    "elif torch.backends.mps.is_available():\n",
    "    torch_dtype = torch.float32  # FP32 for MPS (safest option)\n",
    "    device_map = None  # MPS doesn't support device_map=\"auto\"\n",
    "else:\n",
    "    torch_dtype = torch.float32  # FP32 for CPU\n",
    "    device_map = None\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    trust_remote_code=True,\n",
    "    torch_dtype=torch_dtype,\n",
    "    device_map=device_map,\n",
    "    low_cpu_mem_usage=True\n",
    ")\n",
    "\n",
    "# Move to MPS if needed (device_map=\"auto\" doesn't work with MPS)\n",
    "if torch.backends.mps.is_available() and not torch.cuda.is_available():\n",
    "    model = model.to(\"mps\")\n",
    "    print(\"ğŸ Model moved to MPS device\")\n",
    "\n",
    "print(f\"âœ… Model loaded\")\n",
    "print(f\"ğŸ“Š Model parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "print(f\"ğŸ¯ Trainable parameters: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”§ Using device: MPS (Apple Silicon)\n",
      "ğŸ“± Selected device: mps\n",
      "ğŸ“ Loading tokenizer...\n",
      "âœ… Tokenizer loaded\n",
      "ğŸ“Š Vocab size: 151,665\n",
      "ğŸ¤– Loading model...\n",
      "ğŸ Model moved to MPS device\n",
      "âœ… Model loaded\n",
      "ğŸ“Š Model parameters: 1,543,714,304\n",
      "ğŸ¯ Trainable parameters: 1,543,714,304\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 6. Create Dataset and Start Training\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-08T07:19:22.052776Z",
     "start_time": "2025-08-08T07:15:12.694741Z"
    }
   },
   "source": [
    "# Create train/validation split and start training\n",
    "print(\"ğŸ“Š Creating train/validation split...\")\n",
    "train_samples, val_samples = train_test_split(\n",
    "    formatted_samples, \n",
    "    test_size=0.1, \n",
    "    random_state=42,\n",
    "    stratify=[sample['text'].split('\"matrix\": \"')[1].split('\"')[0] for sample in formatted_samples]\n",
    ")\n",
    "\n",
    "print(f\"ğŸ“š Training samples: {len(train_samples):,}\")\n",
    "print(f\"ğŸ” Validation samples: {len(val_samples):,}\")\n",
    "\n",
    "# Ready to train message\n",
    "print(\"âœ… Setup completed!\")\n",
    "print(\"ğŸš€ You can now run training by executing the trainer.train() command\")\n",
    "print(\"âš ï¸  Note: eval_strategy parameter has been fixed in TrainingArguments\")\n",
    "print(\"ğŸ MPS (Apple Silicon) support added for Mac users\")\n",
    "\n",
    "# Device info summary\n",
    "if torch.cuda.is_available():\n",
    "    print(\"ğŸ® Training will use CUDA GPU acceleration\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    print(\"ğŸ Training will use MPS (Apple Silicon) acceleration\")\n",
    "else:\n",
    "    print(\"âš ï¸  Training will use CPU (slower)\")\n",
    "\n",
    "# Memory management tip for MPS (UPDATED)\n",
    "if torch.backends.mps.is_available() and not torch.cuda.is_available():\n",
    "    print(\"\\nğŸ’¡ MPS Tips (UPDATED):\")\n",
    "    print(\"   â€¢ Using FP32 precision (BF16 not supported in TrainingArguments)\")\n",
    "    print(\"   â€¢ Reduce batch size if you encounter memory issues\")\n",
    "    print(\"   â€¢ Use torch.mps.empty_cache() to clear memory\")\n",
    "    print(\"   â€¢ Training will be slower than FP16 but more stable\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š Creating train/validation split...\n",
      "ğŸ“š Training samples: 828\n",
      "ğŸ” Validation samples: 93\n",
      "âœ… Setup completed!\n",
      "ğŸš€ You can now run training by executing the trainer.train() command\n",
      "âš ï¸  Note: eval_strategy parameter has been fixed in TrainingArguments\n",
      "ğŸ MPS (Apple Silicon) support added for Mac users\n",
      "ğŸ Training will use MPS (Apple Silicon) acceleration\n",
      "\n",
      "ğŸ’¡ MPS Tips (UPDATED):\n",
      "   â€¢ Using FP32 precision (BF16 not supported in TrainingArguments)\n",
      "   â€¢ Reduce batch size if you encounter memory issues\n",
      "   â€¢ Use torch.mps.empty_cache() to clear memory\n",
      "   â€¢ Training will be slower than FP16 but more stable\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 7. Training with MPS Support\n",
    "\n",
    "### ğŸ **MPS (Apple Silicon) Optimizations (FIXED):**\n",
    "\n",
    "- **FP32 precision** for MPS compatibility (BF16 not supported in TrainingArguments)\n",
    "- **Manual device placement** (device_map=\"auto\" not supported on MPS)\n",
    "- **Memory management** with `torch.mps.empty_cache()`\n",
    "- **Optimized batch size** for Apple Silicon memory constraints\n",
    "\n",
    "### ğŸ”§ **Training Configuration (FIXED):**\n",
    "- **CUDA**: FP16 precision + device_map=\"auto\"\n",
    "- **MPS**: FP32 precision + manual device placement  \n",
    "- **CPU**: FP32 precision fallback\n",
    "\n",
    "### âš ï¸ **MPS Limitations:**\n",
    "- BF16 not supported in HuggingFace TrainingArguments for MPS\n",
    "- Using FP32 for stability and compatibility\n",
    "- Slightly slower than FP16 but more reliable\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-08T07:19:22.053308Z",
     "start_time": "2025-08-08T07:15:12.719803Z"
    }
   },
   "source": [
    "# Optional: Start training (uncomment to run)\n",
    "# Uncomment the lines below to start training\n",
    "\n",
    "\"\"\"\n",
    "# Clear memory cache before training\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "elif torch.backends.mps.is_available():\n",
    "    torch.mps.empty_cache()\n",
    "\n",
    "# Create tokenizer function\n",
    "def tokenize_function(examples):\n",
    "    tokenized = tokenizer(\n",
    "        examples[\"text\"],\n",
    "        truncation=True,\n",
    "        padding=False,\n",
    "        max_length=MAX_LENGTH,\n",
    "        return_tensors=None\n",
    "    )\n",
    "    tokenized[\"labels\"] = tokenized[\"input_ids\"].copy()\n",
    "    return tokenized\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = Dataset.from_list(train_samples)\n",
    "val_dataset = Dataset.from_list(val_samples)\n",
    "\n",
    "# Tokenize\n",
    "train_dataset = train_dataset.map(tokenize_function, batched=True, remove_columns=[\"text\"])\n",
    "val_dataset = val_dataset.map(tokenize_function, batched=True, remove_columns=[\"text\"])\n",
    "\n",
    "# Data collator\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)\n",
    "\n",
    "# Initialize trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n",
    "# Start training\n",
    "print(\"ğŸš€ Starting training...\")\n",
    "training_result = trainer.train()\n",
    "\n",
    "print(\"ğŸ‰ Training completed!\")\n",
    "print(f\"ğŸ“Š Final loss: {training_result.training_loss:.4f}\")\n",
    "\"\"\"\n",
    "\n",
    "print(\"ğŸ“ Training code is ready!\")\n",
    "print(\"ğŸ”“ Uncomment the code above to start training\")\n",
    "print(\"âš¡ Optimized for MPS (Apple Silicon) and CUDA\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“ Training code is ready!\n",
      "ğŸ”“ Uncomment the code above to start training\n",
      "âš¡ Optimized for MPS (Apple Silicon) and CUDA\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-08T07:19:22.053466Z",
     "start_time": "2025-08-08T07:15:12.733064Z"
    }
   },
   "source": [
    "# CORRECTED Training Arguments - Run this if you get TypeError\n",
    "print(\"ğŸ”§ Creating CORRECTED training arguments...\")\n",
    "\n",
    "# Model configuration\n",
    "MODEL_NAME = \"Qwen/Qwen2.5-1.5B-Instruct\"\n",
    "MAX_LENGTH = 2048\n",
    "BATCH_SIZE = 4\n",
    "LEARNING_RATE = 2e-5\n",
    "NUM_EPOCHS = 3\n",
    "WARMUP_STEPS = 100\n",
    "\n",
    "# Create output directory\n",
    "timestamp = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "output_dir = f\"../models/qwen-ttp-classification-{timestamp}\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "print(f\"ğŸ“ Output directory: {output_dir}\")\n",
    "\n",
    "# CORRECTED Training arguments (eval_strategy NOT evaluation_strategy)\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    overwrite_output_dir=True,\n",
    "    \n",
    "    # Training parameters\n",
    "    num_train_epochs=NUM_EPOCHS,\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    per_device_eval_batch_size=BATCH_SIZE,\n",
    "    gradient_accumulation_steps=1,\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    weight_decay=0.01,\n",
    "    warmup_steps=WARMUP_STEPS,\n",
    "    \n",
    "    # Optimization (MPS compatible)\n",
    "    fp16=torch.cuda.is_available(),  # Only FP16 on CUDA\n",
    "    bf16=False,  # Disabled for MPS compatibility\n",
    "    dataloader_pin_memory=False,\n",
    "    gradient_checkpointing=True,\n",
    "    \n",
    "    # Logging and saving\n",
    "    logging_dir=f\"{output_dir}/logs\",\n",
    "    logging_steps=10,\n",
    "    save_steps=100,\n",
    "    save_total_limit=3,\n",
    "    eval_steps=100,\n",
    "    eval_strategy=\"steps\",  # CORRECT: eval_strategy (NOT evaluation_strategy)\n",
    "    \n",
    "    # Other settings\n",
    "    remove_unused_columns=False,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    "    greater_is_better=False,\n",
    "    \n",
    "    # Report\n",
    "    report_to=None,\n",
    "    run_name=f\"qwen-ttp-classification-{timestamp}\"\n",
    ")\n",
    "\n",
    "print(\"âœ… CORRECTED Training arguments configured!\")\n",
    "print(f\"ğŸ¯ Batch size: {BATCH_SIZE}\")\n",
    "print(f\"ğŸ“ˆ Learning rate: {LEARNING_RATE}\")\n",
    "print(f\"ğŸ”„ Epochs: {NUM_EPOCHS}\")\n",
    "print(f\"ğŸ”¥ FP16 (CUDA only): {training_args.fp16}\")\n",
    "print(f\"ğŸ BF16 (Disabled): {training_args.bf16}\")\n",
    "print(f\"ğŸ’¾ Gradient checkpointing: {training_args.gradient_checkpointing}\")\n",
    "print(f\"âœ… FIXED: eval_strategy (NOT evaluation_strategy)\")\n",
    "\n",
    "# Show device-specific precision\n",
    "if torch.cuda.is_available():\n",
    "    print(\"âš¡ Using FP16 precision for CUDA training\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    print(\"ğŸ Using FP32 precision for MPS training\")\n",
    "else:\n",
    "    print(\"âš ï¸  Using FP32 precision for CPU training\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”§ Creating CORRECTED training arguments...\n",
      "ğŸ“ Output directory: ../models/qwen-ttp-classification-2025-08-08_14-15-12\n",
      "âœ… CORRECTED Training arguments configured!\n",
      "ğŸ¯ Batch size: 4\n",
      "ğŸ“ˆ Learning rate: 2e-05\n",
      "ğŸ”„ Epochs: 3\n",
      "ğŸ”¥ FP16 (CUDA only): False\n",
      "ğŸ BF16 (Disabled): False\n",
      "ğŸ’¾ Gradient checkpointing: True\n",
      "âœ… FIXED: eval_strategy (NOT evaluation_strategy)\n",
      "ğŸ Using FP32 precision for MPS training\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# TTP Classification Training with Qwen Model\n",
    "\n",
    "## Overview\n",
    "This notebook implements TTP (Tactics, Techniques, and Procedures) classification training using Qwen model with MITRE ATT&CK framework.\n",
    "\n",
    "### Task Description\n",
    "- **Input**: Threat intelligence text descriptions\n",
    "- **Output**: MITRE ATT&CK technique classification (T1xxx format)\n",
    "- **Model**: Qwen/Qwen2.5-1.5B-Instruct (fine-tuned)\n",
    "\n",
    "### Dataset Statistics\n",
    "- **Total samples**: 921 training examples\n",
    "- **Enterprise Matrix**: 691 techniques (222 main + 469 sub-techniques)\n",
    "- **Mobile Matrix**: 135 techniques (89 main + 46 sub-techniques)\n",
    "- **ICS Matrix**: 95 techniques (95 main + 0 sub-techniques)\n",
    "\n",
    "### Key Steps\n",
    "1. Load and prepare MITRE ATT&CK training data\n",
    "2. Setup Qwen model for fine-tuning\n",
    "3. Create training and validation splits\n",
    "4. Fine-tune model for TTP classification\n",
    "5. Evaluate model performance\n",
    "6. Test on real threat intelligence data\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 1. Environment Setup and Dependencies\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-08T07:19:22.053575Z",
     "start_time": "2025-08-08T07:15:12.743215Z"
    }
   },
   "source": [
    "import json\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Any, Tuple\n",
    "import logging\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Transformers and training\n",
    "from transformers import (\n",
    "    AutoTokenizer, \n",
    "    AutoModelForCausalLM,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    DataCollatorForLanguageModeling\n",
    ")\n",
    "from datasets import Dataset, DatasetDict\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "print(\"ğŸ“š Dependencies loaded successfully!\")\n",
    "print(f\"ğŸ”¥ PyTorch version: {torch.__version__}\")\n",
    "print(f\"ğŸ¤– CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"ğŸ® GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"ğŸ’¾ GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“š Dependencies loaded successfully!\n",
      "ğŸ”¥ PyTorch version: 2.8.0\n",
      "ğŸ¤– CUDA available: False\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 2. Load MITRE ATT&CK Training Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-08T07:19:22.053684Z",
     "start_time": "2025-08-08T07:15:12.755115Z"
    }
   },
   "source": [
    "# Load merged MITRE ATT&CK dataset\n",
    "dataset_path = \"../data/TTP-classification/merged_mitre_attack_dataset.json\"\n",
    "\n",
    "print(\"ğŸ“‚ Loading MITRE ATT&CK dataset...\")\n",
    "with open(dataset_path, 'r', encoding='utf-8') as f:\n",
    "    mitre_data = json.load(f)\n",
    "\n",
    "# Extract training samples\n",
    "training_samples = mitre_data['dataset']\n",
    "print(f\"âœ… Loaded {len(training_samples):,} training samples\")\n",
    "\n",
    "# Analyze dataset structure\n",
    "print(\"\\nğŸ“Š Dataset Analysis:\")\n",
    "matrices = {'enterprise': 0, 'mobile': 0, 'ics': 0}\n",
    "techniques_count = 0\n",
    "sub_techniques_count = 0\n",
    "technique_ids = set()\n",
    "\n",
    "for sample in training_samples:\n",
    "    technique = sample['output']['techniques'][0]\n",
    "    matrix = technique['matrix']\n",
    "    technique_id = technique['id']\n",
    "    \n",
    "    matrices[matrix] += 1\n",
    "    technique_ids.add(technique_id)\n",
    "    \n",
    "    if '.' in technique_id:\n",
    "        sub_techniques_count += 1\n",
    "    else:\n",
    "        techniques_count += 1\n",
    "\n",
    "print(f\"  â€¢ Enterprise: {matrices['enterprise']:,} samples\")\n",
    "print(f\"  â€¢ Mobile: {matrices['mobile']:,} samples\")\n",
    "print(f\"  â€¢ ICS: {matrices['ics']:,} samples\")\n",
    "print(f\"  â€¢ Techniques: {techniques_count:,} samples\")\n",
    "print(f\"  â€¢ Sub-techniques: {sub_techniques_count:,} samples\")\n",
    "print(f\"  â€¢ Unique technique IDs: {len(technique_ids):,}\")\n",
    "\n",
    "# Show sample data\n",
    "print(\"\\nğŸ“ Sample Training Example:\")\n",
    "sample = training_samples[0]\n",
    "print(f\"Instruction: {sample['instruction'][:100]}...\")\n",
    "print(f\"Technique ID: {sample['output']['techniques'][0]['id']}\")\n",
    "print(f\"Technique Name: {sample['output']['techniques'][0]['name']}\")\n",
    "print(f\"Matrix: {sample['output']['techniques'][0]['matrix']}\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“‚ Loading MITRE ATT&CK dataset...\n",
      "âœ… Loaded 921 training samples\n",
      "\n",
      "ğŸ“Š Dataset Analysis:\n",
      "  â€¢ Enterprise: 691 samples\n",
      "  â€¢ Mobile: 135 samples\n",
      "  â€¢ ICS: 95 samples\n",
      "  â€¢ Techniques: 406 samples\n",
      "  â€¢ Sub-techniques: 515 samples\n",
      "  â€¢ Unique technique IDs: 921\n",
      "\n",
      "ğŸ“ Sample Training Example:\n",
      "Instruction: Adversaries may inject malicious code into process via Extra Window Memory (EWM) in order to evade p...\n",
      "Technique ID: T1055.011\n",
      "Technique Name: Extra Window Memory Injection\n",
      "Matrix: enterprise\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 3. Prepare Training Data Format\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-08T07:19:22.053770Z",
     "start_time": "2025-08-08T07:15:12.780138Z"
    }
   },
   "source": [
    "def format_training_sample(sample: Dict[str, Any]) -> Dict[str, str]:\n",
    "    \"\"\"\n",
    "    Format training sample for instruction tuning\n",
    "    \n",
    "    Input format:\n",
    "    {\n",
    "        \"instruction\": \"Adversary behavior description...\",\n",
    "        \"output\": {\n",
    "            \"techniques\": [{\n",
    "                \"id\": \"T1055.011\",\n",
    "                \"name\": \"Extra Window Memory Injection\",\n",
    "                \"description\": \"...\",\n",
    "                \"matrix\": \"enterprise\"\n",
    "            }]\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    Output format for instruction tuning:\n",
    "    {\n",
    "        \"text\": \"<|im_start|>system\\nYou are a cybersecurity expert...\\n<|im_end|>\\n<|im_start|>user\\n...\\n<|im_end|>\\n<|im_start|>assistant\\n...\\n<|im_end|>\"\n",
    "    }\n",
    "    \"\"\"\n",
    "    instruction = sample['instruction']\n",
    "    technique = sample['output']['techniques'][0]\n",
    "    \n",
    "    # Create system prompt\n",
    "    system_prompt = \"\"\"You are a cybersecurity expert specializing in MITRE ATT&CK framework. Your task is to analyze threat intelligence descriptions and identify the corresponding MITRE ATT&CK techniques.\n",
    "\n",
    "Given a description of adversary behavior, identify the most relevant MITRE ATT&CK technique and provide:\n",
    "1. Technique ID (e.g., T1055.011)\n",
    "2. Technique Name\n",
    "3. Matrix (enterprise/mobile/ics)\n",
    "\n",
    "Respond in JSON format.\"\"\"\n",
    "    \n",
    "    # Create user input\n",
    "    user_input = f\"Analyze this threat behavior and identify the MITRE ATT&CK technique:\\n\\n{instruction}\"\n",
    "    \n",
    "    # Create assistant response\n",
    "    assistant_response = json.dumps({\n",
    "        \"technique_id\": technique['id'],\n",
    "        \"technique_name\": technique['name'],\n",
    "        \"matrix\": technique['matrix'],\n",
    "        \"description\": technique['description']\n",
    "    }, ensure_ascii=False)\n",
    "    \n",
    "    # Format for Qwen chat template\n",
    "    formatted_text = f\"\"\"<|im_start|>system\n",
    "{system_prompt}<|im_end|>\n",
    "<|im_start|>user\n",
    "{user_input}<|im_end|>\n",
    "<|im_start|>assistant\n",
    "{assistant_response}<|im_end|>\"\"\"\n",
    "    \n",
    "    return {\"text\": formatted_text}\n",
    "\n",
    "# Format all training samples\n",
    "print(\"ğŸ”„ Formatting training data...\")\n",
    "formatted_samples = []\n",
    "for sample in tqdm(training_samples):\n",
    "    formatted_sample = format_training_sample(sample)\n",
    "    formatted_samples.append(formatted_sample)\n",
    "\n",
    "print(f\"âœ… Formatted {len(formatted_samples):,} training samples\")\n",
    "\n",
    "# Show formatted example\n",
    "print(\"\\nğŸ“ Formatted Training Example:\")\n",
    "print(formatted_samples[0]['text'][:500] + \"...\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”„ Formatting training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 921/921 [00:00<00:00, 219598.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Formatted 921 training samples\n",
      "\n",
      "ğŸ“ Formatted Training Example:\n",
      "<|im_start|>system\n",
      "You are a cybersecurity expert specializing in MITRE ATT&CK framework. Your task is to analyze threat intelligence descriptions and identify the corresponding MITRE ATT&CK techniques.\n",
      "\n",
      "Given a description of adversary behavior, identify the most relevant MITRE ATT&CK technique and provide:\n",
      "1. Technique ID (e.g., T1055.011)\n",
      "2. Technique Name\n",
      "3. Matrix (enterprise/mobile/ics)\n",
      "\n",
      "Respond in JSON format.<|im_end|>\n",
      "<|im_start|>user\n",
      "Analyze this threat behavior and identify the MITRE ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 4. Setup Qwen Model and Tokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-08T07:19:22.053897Z",
     "start_time": "2025-08-08T07:15:12.794515Z"
    }
   },
   "source": [
    "# Model configuration\n",
    "MODEL_NAME = \"Qwen/Qwen2.5-1.5B-Instruct\"\n",
    "MAX_LENGTH = 2048\n",
    "BATCH_SIZE = 4\n",
    "LEARNING_RATE = 2e-5\n",
    "NUM_EPOCHS = 3\n",
    "WARMUP_STEPS = 100\n",
    "\n",
    "print(f\"ğŸ¤– Setting up model: {MODEL_NAME}\")\n",
    "\n",
    "# Setup device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"ğŸ”§ Using device: {device}\")\n",
    "\n",
    "# Load tokenizer\n",
    "print(\"ğŸ“ Loading tokenizer...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    trust_remote_code=True,\n",
    "    padding_side=\"right\"\n",
    ")\n",
    "\n",
    "# Add padding token if not exists\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    print(\"ğŸ”§ Set pad_token = eos_token\")\n",
    "\n",
    "print(f\"âœ… Tokenizer loaded\")\n",
    "print(f\"ğŸ“Š Vocab size: {len(tokenizer):,}\")\n",
    "print(f\"ğŸ”‘ Special tokens: {tokenizer.special_tokens_map}\")\n",
    "\n",
    "# Load model\n",
    "print(\"ğŸ¤– Loading model...\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    trust_remote_code=True,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\",\n",
    "    low_cpu_mem_usage=True\n",
    ")\n",
    "\n",
    "print(f\"âœ… Model loaded\")\n",
    "print(f\"ğŸ“Š Model parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "print(f\"ğŸ¯ Trainable parameters: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¤– Setting up model: Qwen/Qwen2.5-1.5B-Instruct\n",
      "ğŸ”§ Using device: cpu\n",
      "ğŸ“ Loading tokenizer...\n",
      "âœ… Tokenizer loaded\n",
      "ğŸ“Š Vocab size: 151,665\n",
      "ğŸ”‘ Special tokens: {'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}\n",
      "ğŸ¤– Loading model...\n",
      "âœ… Model loaded\n",
      "ğŸ“Š Model parameters: 1,543,714,304\n",
      "ğŸ¯ Trainable parameters: 1,543,714,304\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 5. Create Dataset and Data Loaders\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-08T07:19:22.054007Z",
     "start_time": "2025-08-08T07:15:20.002698Z"
    }
   },
   "source": [
    "def tokenize_function(examples):\n",
    "    \"\"\"\n",
    "    Tokenize training examples\n",
    "    \"\"\"\n",
    "    # Tokenize the text\n",
    "    tokenized = tokenizer(\n",
    "        examples[\"text\"],\n",
    "        truncation=True,\n",
    "        padding=False,\n",
    "        max_length=MAX_LENGTH,\n",
    "        return_tensors=None\n",
    "    )\n",
    "    \n",
    "    # For causal language modeling, labels are the same as input_ids\n",
    "    tokenized[\"labels\"] = tokenized[\"input_ids\"].copy()\n",
    "    \n",
    "    return tokenized\n",
    "\n",
    "# Create train/validation split\n",
    "print(\"ğŸ“Š Creating train/validation split...\")\n",
    "train_samples, val_samples = train_test_split(\n",
    "    formatted_samples, \n",
    "    test_size=0.1, \n",
    "    random_state=42,\n",
    "    stratify=[sample['text'].split('\"matrix\": \"')[1].split('\"')[0] for sample in formatted_samples]\n",
    ")\n",
    "\n",
    "print(f\"ğŸ“š Training samples: {len(train_samples):,}\")\n",
    "print(f\"ğŸ” Validation samples: {len(val_samples):,}\")\n",
    "\n",
    "# Create HuggingFace datasets\n",
    "print(\"ğŸ”„ Creating datasets...\")\n",
    "train_dataset = Dataset.from_list(train_samples)\n",
    "val_dataset = Dataset.from_list(val_samples)\n",
    "\n",
    "# Tokenize datasets\n",
    "print(\"ğŸ”¤ Tokenizing datasets...\")\n",
    "train_dataset = train_dataset.map(\n",
    "    tokenize_function,\n",
    "    batched=True,\n",
    "    remove_columns=[\"text\"],\n",
    "    desc=\"Tokenizing train data\"\n",
    ")\n",
    "\n",
    "val_dataset = val_dataset.map(\n",
    "    tokenize_function,\n",
    "    batched=True,\n",
    "    remove_columns=[\"text\"],\n",
    "    desc=\"Tokenizing validation data\"\n",
    ")\n",
    "\n",
    "print(\"âœ… Datasets prepared\")\n",
    "print(f\"ğŸ“Š Train dataset: {len(train_dataset):,} samples\")\n",
    "print(f\"ğŸ“Š Validation dataset: {len(val_dataset):,} samples\")\n",
    "\n",
    "# Check tokenization\n",
    "sample_tokens = train_dataset[0]\n",
    "print(f\"\\nğŸ“ Sample tokenization:\")\n",
    "print(f\"Input IDs length: {len(sample_tokens['input_ids'])}\")\n",
    "print(f\"Attention mask length: {len(sample_tokens['attention_mask'])}\")\n",
    "print(f\"Labels length: {len(sample_tokens['labels'])}\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š Creating train/validation split...\n",
      "ğŸ“š Training samples: 828\n",
      "ğŸ” Validation samples: 93\n",
      "ğŸ”„ Creating datasets...\n",
      "ğŸ”¤ Tokenizing datasets...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Tokenizing train data:   0%|          | 0/828 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b66895436fdd4c1ba31576c1dc07cf55"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Tokenizing validation data:   0%|          | 0/93 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6e719e15a69746c0934bab02d432d9ac"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Datasets prepared\n",
      "ğŸ“Š Train dataset: 828 samples\n",
      "ğŸ“Š Validation dataset: 93 samples\n",
      "\n",
      "ğŸ“ Sample tokenization:\n",
      "Input IDs length: 368\n",
      "Attention mask length: 368\n",
      "Labels length: 368\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 6. Setup Training Configuration\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-08T07:19:22.054188Z",
     "start_time": "2025-08-08T07:15:20.288954Z"
    }
   },
   "source": [
    "# Create output directory\n",
    "timestamp = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "output_dir = f\"../models/qwen-ttp-classification-{timestamp}\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "print(f\"ğŸ“ Output directory: {output_dir}\")\n",
    "\n",
    "# Training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    overwrite_output_dir=True,\n",
    "    \n",
    "    # Training parameters\n",
    "    num_train_epochs=NUM_EPOCHS,\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    per_device_eval_batch_size=BATCH_SIZE,\n",
    "    gradient_accumulation_steps=1,\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    weight_decay=0.01,\n",
    "    warmup_steps=WARMUP_STEPS,\n",
    "    \n",
    "    # Optimization\n",
    "    fp16=True,\n",
    "    dataloader_pin_memory=False,\n",
    "    gradient_checkpointing=True,\n",
    "    \n",
    "    # Logging and saving\n",
    "    logging_dir=f\"{output_dir}/logs\",\n",
    "    logging_steps=10,\n",
    "    save_steps=100,\n",
    "    save_total_limit=3,\n",
    "    eval_steps=100,\n",
    "    eval_strategy=\"steps\",  # FIXED: was evaluation_strategy\n",
    "\n",
    "    # Other settings\n",
    "    remove_unused_columns=False,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    "    greater_is_better=False,\n",
    "    \n",
    "    # Report\n",
    "    report_to=None,  # Disable wandb/tensorboard\n",
    "    run_name=f\"qwen-ttp-classification-{timestamp}\"\n",
    ")\n",
    "\n",
    "print(\"âœ… Training arguments configured\")\n",
    "print(f\"ğŸ¯ Batch size: {BATCH_SIZE}\")\n",
    "print(f\"ğŸ“ˆ Learning rate: {LEARNING_RATE}\")\n",
    "print(f\"ğŸ”„ Epochs: {NUM_EPOCHS}\")\n",
    "print(f\"ğŸ”¥ FP16: {training_args.fp16}\")\n",
    "print(f\"ğŸ’¾ Gradient checkpointing: {training_args.gradient_checkpointing}\")\n",
    "\n",
    "# Data collator\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer,\n",
    "    mlm=False,  # No masking for causal LM\n",
    ")\n",
    "\n",
    "print(\"âœ… Data collator configured\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“ Output directory: ../models/qwen-ttp-classification-2025-08-08_14-15-20\n",
      "âœ… Training arguments configured\n",
      "ğŸ¯ Batch size: 4\n",
      "ğŸ“ˆ Learning rate: 2e-05\n",
      "ğŸ”„ Epochs: 3\n",
      "ğŸ”¥ FP16: True\n",
      "ğŸ’¾ Gradient checkpointing: True\n",
      "âœ… Data collator configured\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 7. Initialize Trainer and Start Training\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-08T07:19:22.054294Z",
     "start_time": "2025-08-08T07:15:20.307348Z"
    }
   },
   "source": [
    "# Initialize trainer\n",
    "print(\"ğŸƒâ€â™‚ï¸ Initializing trainer...\")\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n",
    "print(\"âœ… Trainer initialized\")\n",
    "\n",
    "# Start training\n",
    "print(\"\\nğŸš€ Starting training...\")\n",
    "print(f\"ğŸ“Š Total training samples: {len(train_dataset):,}\")\n",
    "print(f\"ğŸ“Š Total validation samples: {len(val_dataset):,}\")\n",
    "print(f\"â±ï¸ Estimated training time: ~{(len(train_dataset) // BATCH_SIZE) * NUM_EPOCHS // 60} minutes\")\n",
    "\n",
    "# Clear cache before training\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "# Train the model\n",
    "training_result = trainer.train()\n",
    "\n",
    "print(\"\\nğŸ‰ Training completed!\")\n",
    "print(f\"ğŸ“Š Final training loss: {training_result.training_loss:.4f}\")\n",
    "print(f\"â±ï¸ Training time: {training_result.training_time:.2f} seconds\")\n",
    "\n",
    "# Save the final model\n",
    "print(\"ğŸ’¾ Saving final model...\")\n",
    "trainer.save_model()\n",
    "tokenizer.save_pretrained(output_dir)\n",
    "\n",
    "print(f\"âœ… Model saved to: {output_dir}\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸƒâ€â™‚ï¸ Initializing trainer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/lt/y_3sh6vn2mb68907rlw4xvww0000gn/T/ipykernel_11776/2074198674.py:3: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "fp16 mixed precision requires a GPU (not 'mps').",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[15], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# Initialize trainer\u001B[39;00m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mğŸƒâ€â™‚ï¸ Initializing trainer...\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m----> 3\u001B[0m trainer \u001B[38;5;241m=\u001B[39m \u001B[43mTrainer\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m      4\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      5\u001B[0m \u001B[43m    \u001B[49m\u001B[43margs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtraining_args\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      6\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtrain_dataset\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrain_dataset\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      7\u001B[0m \u001B[43m    \u001B[49m\u001B[43meval_dataset\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mval_dataset\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      8\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtokenizer\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtokenizer\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      9\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdata_collator\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdata_collator\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     10\u001B[0m \u001B[43m)\u001B[49m\n\u001B[1;32m     12\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mâœ… Trainer initialized\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     14\u001B[0m \u001B[38;5;66;03m# Start training\u001B[39;00m\n",
      "File \u001B[0;32m~/Documents/UIT/2nd/NLP/LLM-TKIG/.venv/lib/python3.12/site-packages/transformers/utils/deprecation.py:172\u001B[0m, in \u001B[0;36mdeprecate_kwarg.<locals>.wrapper.<locals>.wrapped_func\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    168\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m minimum_action \u001B[38;5;129;01min\u001B[39;00m (Action\u001B[38;5;241m.\u001B[39mNOTIFY, Action\u001B[38;5;241m.\u001B[39mNOTIFY_ALWAYS) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_torchdynamo_compiling():\n\u001B[1;32m    169\u001B[0m     \u001B[38;5;66;03m# DeprecationWarning is ignored by default, so we use FutureWarning instead\u001B[39;00m\n\u001B[1;32m    170\u001B[0m     warnings\u001B[38;5;241m.\u001B[39mwarn(message, \u001B[38;5;167;01mFutureWarning\u001B[39;00m, stacklevel\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m)\n\u001B[0;32m--> 172\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/UIT/2nd/NLP/LLM-TKIG/.venv/lib/python3.12/site-packages/transformers/trainer.py:465\u001B[0m, in \u001B[0;36mTrainer.__init__\u001B[0;34m(self, model, args, data_collator, train_dataset, eval_dataset, processing_class, model_init, compute_loss_func, compute_metrics, callbacks, optimizers, optimizer_cls_and_kwargs, preprocess_logits_for_metrics)\u001B[0m\n\u001B[1;32m    463\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mis_in_train \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[1;32m    464\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel \u001B[38;5;241m=\u001B[39m model\n\u001B[0;32m--> 465\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcreate_accelerator_and_postprocess\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    467\u001B[0m \u001B[38;5;66;03m# memory metrics - must set up as early as possible\u001B[39;00m\n\u001B[1;32m    468\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_memory_tracker \u001B[38;5;241m=\u001B[39m TrainerMemoryTracker(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs\u001B[38;5;241m.\u001B[39mskip_memory_metrics)\n",
      "File \u001B[0;32m~/Documents/UIT/2nd/NLP/LLM-TKIG/.venv/lib/python3.12/site-packages/transformers/trainer.py:5208\u001B[0m, in \u001B[0;36mTrainer.create_accelerator_and_postprocess\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   5205\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mRequires accelerate>1.3.0 to use Tensor Parallelism.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m   5207\u001B[0m \u001B[38;5;66;03m# create accelerator object\u001B[39;00m\n\u001B[0;32m-> 5208\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39maccelerator \u001B[38;5;241m=\u001B[39m \u001B[43mAccelerator\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   5209\u001B[0m \u001B[38;5;66;03m# some Trainer classes need to use `gather` instead of `gather_for_metrics`, thus we store a flag\u001B[39;00m\n\u001B[1;32m   5210\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgather_function \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39maccelerator\u001B[38;5;241m.\u001B[39mgather_for_metrics\n",
      "File \u001B[0;32m~/Documents/UIT/2nd/NLP/LLM-TKIG/.venv/lib/python3.12/site-packages/accelerate/accelerator.py:567\u001B[0m, in \u001B[0;36mAccelerator.__init__\u001B[0;34m(self, device_placement, split_batches, mixed_precision, gradient_accumulation_steps, cpu, dataloader_config, deepspeed_plugin, fsdp_plugin, torch_tp_plugin, megatron_lm_plugin, rng_types, log_with, project_dir, project_config, gradient_accumulation_plugin, step_scheduler_with_optimizer, kwargs_handlers, dynamo_backend, dynamo_plugin, deepspeed_plugins)\u001B[0m\n\u001B[1;32m    556\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnative_amp \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m    557\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdevice\u001B[38;5;241m.\u001B[39mtype \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m (\n\u001B[1;32m    558\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mxpu\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    559\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcuda\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    565\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msdaa\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    566\u001B[0m ) \u001B[38;5;129;01mor\u001B[39;00m is_torch_xla_available(check_is_tpu\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m):\n\u001B[0;32m--> 567\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfp16 mixed precision requires a GPU (not \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdevice\u001B[38;5;241m.\u001B[39mtype\u001B[38;5;132;01m!r}\u001B[39;00m\u001B[38;5;124m).\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    568\u001B[0m kwargs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mscaler_handler\u001B[38;5;241m.\u001B[39mto_kwargs() \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mscaler_handler \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m {}\n\u001B[1;32m    570\u001B[0m \u001B[38;5;66;03m# FSDP2 doesn't use ShardedGradScaler, don't want to modify `get_grad_scaler`, rather create a simple utility\u001B[39;00m\n",
      "\u001B[0;31mValueError\u001B[0m: fp16 mixed precision requires a GPU (not 'mps')."
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 8. Model Evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "print(\"ğŸ“Š Evaluating model...\")\n",
    "eval_result = trainer.evaluate()\n",
    "\n",
    "print(\"\\nğŸ“ˆ Evaluation Results:\")\n",
    "for key, value in eval_result.items():\n",
    "    print(f\"  {key}: {value:.4f}\")\n",
    "\n",
    "# Save evaluation results\n",
    "eval_file = os.path.join(output_dir, \"evaluation_results.json\")\n",
    "with open(eval_file, 'w') as f:\n",
    "    json.dump(eval_result, f, indent=2)\n",
    "\n",
    "print(f\"âœ… Evaluation results saved to: {eval_file}\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 9. Test Model Inference\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_ttp_classification(model, tokenizer, threat_description: str) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Test TTP classification on a threat description\n",
    "    \"\"\"\n",
    "    system_prompt = \"\"\"You are a cybersecurity expert specializing in MITRE ATT&CK framework. Your task is to analyze threat intelligence descriptions and identify the corresponding MITRE ATT&CK techniques.\n",
    "\n",
    "Given a description of adversary behavior, identify the most relevant MITRE ATT&CK technique and provide:\n",
    "1. Technique ID (e.g., T1055.011)\n",
    "2. Technique Name\n",
    "3. Matrix (enterprise/mobile/ics)\n",
    "\n",
    "Respond in JSON format.\"\"\"\n",
    "    \n",
    "    user_input = f\"Analyze this threat behavior and identify the MITRE ATT&CK technique:\\n\\n{threat_description}\"\n",
    "    \n",
    "    # Format input\n",
    "    prompt = f\"\"\"<|im_start|>system\n",
    "{system_prompt}<|im_end|>\n",
    "<|im_start|>user\n",
    "{user_input}<|im_end|>\n",
    "<|im_start|>assistant\n",
    "\"\"\"\n",
    "    \n",
    "    # Tokenize\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=1024)\n",
    "    inputs = {k: v.to(model.device) for k, v in inputs.items()}\n",
    "    \n",
    "    # Generate response\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=256,\n",
    "            temperature=0.1,\n",
    "            do_sample=True,\n",
    "            pad_token_id=tokenizer.eos_token_id\n",
    "        )\n",
    "    \n",
    "    # Decode response\n",
    "    full_response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    assistant_response = full_response.split(\"<|im_start|>assistant\\n\")[-1]\n",
    "    \n",
    "    return {\n",
    "        \"input\": threat_description,\n",
    "        \"response\": assistant_response,\n",
    "        \"full_prompt\": prompt\n",
    "    }\n",
    "\n",
    "# Test examples\n",
    "test_cases = [\n",
    "    \"Adversaries may inject malicious code into processes in order to evade process-based defenses or elevate privileges.\",\n",
    "    \"Attackers send phishing emails with malicious attachments to gain initial access to the target system.\",\n",
    "    \"The malware establishes persistence by creating scheduled tasks that execute at system startup.\",\n",
    "    \"Adversaries may abuse elevation control mechanisms to gain higher-level permissions on a system.\"\n",
    "]\n",
    "\n",
    "print(\"ğŸ§ª Testing model inference...\")\n",
    "for i, test_case in enumerate(test_cases, 1):\n",
    "    print(f\"\\nğŸ“ Test Case {i}:\")\n",
    "    print(f\"Input: {test_case}\")\n",
    "    \n",
    "    result = test_ttp_classification(model, tokenizer, test_case)\n",
    "    print(f\"Output: {result['response']}\")\n",
    "    print(\"-\" * 80)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 10. Save Training Summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training summary\n",
    "training_summary = {\n",
    "    \"model_name\": MODEL_NAME,\n",
    "    \"training_timestamp\": timestamp,\n",
    "    \"output_directory\": output_dir,\n",
    "    \"dataset_info\": {\n",
    "        \"total_samples\": len(training_samples),\n",
    "        \"train_samples\": len(train_dataset),\n",
    "        \"val_samples\": len(val_dataset),\n",
    "        \"unique_techniques\": len(technique_ids),\n",
    "        \"matrix_distribution\": matrices\n",
    "    },\n",
    "    \"training_config\": {\n",
    "        \"batch_size\": BATCH_SIZE,\n",
    "        \"learning_rate\": LEARNING_RATE,\n",
    "        \"num_epochs\": NUM_EPOCHS,\n",
    "        \"max_length\": MAX_LENGTH,\n",
    "        \"warmup_steps\": WARMUP_STEPS\n",
    "    },\n",
    "    \"training_results\": {\n",
    "        \"final_loss\": training_result.training_loss,\n",
    "        \"training_time_seconds\": training_result.training_time\n",
    "    },\n",
    "    \"evaluation_results\": eval_result\n",
    "}\n",
    "\n",
    "# Save summary\n",
    "summary_file = os.path.join(output_dir, \"training_summary.json\")\n",
    "with open(summary_file, 'w', encoding='utf-8') as f:\n",
    "    json.dump(training_summary, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"ğŸ“„ Training summary saved to: {summary_file}\")\n",
    "\n",
    "# Display summary\n",
    "print(\"\\nğŸ“Š Training Summary:\")\n",
    "print(f\"  Model: {MODEL_NAME}\")\n",
    "print(f\"  Training samples: {len(train_dataset):,}\")\n",
    "print(f\"  Validation samples: {len(val_dataset):,}\")\n",
    "print(f\"  Unique techniques: {len(technique_ids):,}\")\n",
    "print(f\"  Final training loss: {training_result.training_loss:.4f}\")\n",
    "print(f\"  Final validation loss: {eval_result['eval_loss']:.4f}\")\n",
    "print(f\"  Training time: {training_result.training_time:.1f} seconds\")\n",
    "print(f\"  Model saved to: {output_dir}\")\n",
    "\n",
    "print(\"\\nğŸ‰ TTP Classification training completed successfully!\")\n",
    "print(f\"ğŸ“ All artifacts saved to: {output_dir}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
