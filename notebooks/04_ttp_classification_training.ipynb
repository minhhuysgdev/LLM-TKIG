{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# TTP Classification Training with Qwen Model\n",
    "\n",
    "## Overview\n",
    "This notebook implements TTP (Tactics, Techniques, and Procedures) classification training using Qwen model with MITRE ATT&CK framework.\n",
    "\n",
    "### Task Description\n",
    "- **Input**: Threat intelligence text descriptions\n",
    "- **Output**: MITRE ATT&CK technique classification (T1xxx format)\n",
    "- **Model**: Qwen/Qwen2.5-1.5B-Instruct (fine-tuned)\n",
    "\n",
    "### Dataset Statistics\n",
    "- **Total samples**: 921 training examples\n",
    "- **Enterprise Matrix**: 691 techniques (222 main + 469 sub-techniques)\n",
    "- **Mobile Matrix**: 135 techniques (89 main + 46 sub-techniques)\n",
    "- **ICS Matrix**: 95 techniques (95 main + 0 sub-techniques)\n",
    "\n",
    "### Key Steps\n",
    "1. Load and prepare MITRE ATT&CK training data\n",
    "2. Setup Qwen model for fine-tuning\n",
    "3. Create training and validation splits\n",
    "4. Fine-tune model for TTP classification\n",
    "5. Evaluate model performance\n",
    "6. Test on real threat intelligence data\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## 1. Environment Setup and Dependencies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-08T07:38:25.638999Z",
     "start_time": "2025-08-08T07:38:21.996036Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìö Dependencies loaded successfully!\n",
      "üî• PyTorch version: 2.8.0\n",
      "ü§ñ CUDA available: False\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Any, Tuple\n",
    "import logging\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Transformers and training\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForCausalLM,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    DataCollatorForLanguageModeling\n",
    ")\n",
    "from datasets import Dataset, DatasetDict\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "print(\"üìö Dependencies loaded successfully!\")\n",
    "print(f\"üî• PyTorch version: {torch.__version__}\")\n",
    "print(f\"ü§ñ CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"üéÆ GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"üíæ GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## 2. Load MITRE ATT&CK Training Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-08T07:38:25.649882Z",
     "start_time": "2025-08-08T07:38:25.642689Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Loading MITRE ATT&CK dataset...\n",
      "‚úÖ Loaded 921 training samples\n",
      "\n",
      "üìä Dataset Analysis:\n",
      "  ‚Ä¢ Enterprise: 691 samples\n",
      "  ‚Ä¢ Mobile: 135 samples\n",
      "  ‚Ä¢ ICS: 95 samples\n",
      "  ‚Ä¢ Techniques: 406 samples\n",
      "  ‚Ä¢ Sub-techniques: 515 samples\n",
      "  ‚Ä¢ Unique technique IDs: 921\n",
      "\n",
      "üìù Sample Training Example:\n",
      "Instruction: Adversaries may inject malicious code into process via Extra Window Memory (EWM) in order to evade p...\n",
      "Technique ID: T1055.011\n",
      "Technique Name: Extra Window Memory Injection\n",
      "Matrix: enterprise\n"
     ]
    }
   ],
   "source": [
    "# Load merged MITRE ATT&CK dataset\n",
    "dataset_path = \"../data/TTP-classification/merged_mitre_attack_dataset.json\"\n",
    "\n",
    "print(\"üìÇ Loading MITRE ATT&CK dataset...\")\n",
    "with open(dataset_path, 'r', encoding='utf-8') as f:\n",
    "    mitre_data = json.load(f)\n",
    "\n",
    "# Extract training samples\n",
    "training_samples = mitre_data['dataset']\n",
    "print(f\"‚úÖ Loaded {len(training_samples):,} training samples\")\n",
    "\n",
    "# Analyze dataset structure\n",
    "print(\"\\nüìä Dataset Analysis:\")\n",
    "matrices = {'enterprise': 0, 'mobile': 0, 'ics': 0}\n",
    "techniques_count = 0\n",
    "sub_techniques_count = 0\n",
    "technique_ids = set()\n",
    "\n",
    "for sample in training_samples:\n",
    "    technique = sample['output']['techniques'][0]\n",
    "    matrix = technique['matrix']\n",
    "    technique_id = technique['id']\n",
    "\n",
    "    matrices[matrix] += 1\n",
    "    technique_ids.add(technique_id)\n",
    "\n",
    "    if '.' in technique_id:\n",
    "        sub_techniques_count += 1\n",
    "    else:\n",
    "        techniques_count += 1\n",
    "\n",
    "print(f\"  ‚Ä¢ Enterprise: {matrices['enterprise']:,} samples\")\n",
    "print(f\"  ‚Ä¢ Mobile: {matrices['mobile']:,} samples\")\n",
    "print(f\"  ‚Ä¢ ICS: {matrices['ics']:,} samples\")\n",
    "print(f\"  ‚Ä¢ Techniques: {techniques_count:,} samples\")\n",
    "print(f\"  ‚Ä¢ Sub-techniques: {sub_techniques_count:,} samples\")\n",
    "print(f\"  ‚Ä¢ Unique technique IDs: {len(technique_ids):,}\")\n",
    "\n",
    "# Show sample data\n",
    "print(\"\\nüìù Sample Training Example:\")\n",
    "sample = training_samples[0]\n",
    "print(f\"Instruction: {sample['instruction'][:100]}...\")\n",
    "print(f\"Technique ID: {sample['output']['techniques'][0]['id']}\")\n",
    "print(f\"Technique Name: {sample['output']['techniques'][0]['name']}\")\n",
    "print(f\"Matrix: {sample['output']['techniques'][0]['matrix']}\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## 3. Prepare Training Data Format\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-08T07:38:25.672380Z",
     "start_time": "2025-08-08T07:38:25.653187Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Formatting training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 921/921 [00:00<00:00, 194225.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Formatted 921 training samples\n",
      "\n",
      "üìù Formatted Training Example:\n",
      "<|im_start|>system\n",
      "You are a cybersecurity expert specializing in MITRE ATT&CK framework. Your task is to analyze threat intelligence descriptions and identify the corresponding MITRE ATT&CK techniques.\n",
      "\n",
      "Given a description of adversary behavior, identify the most relevant MITRE ATT&CK technique and provide:\n",
      "1. Technique ID (e.g., T1055.011)\n",
      "2. Technique Name\n",
      "3. Matrix (enterprise/mobile/ics)\n",
      "\n",
      "Respond in JSON format.<|im_end|>\n",
      "<|im_start|>user\n",
      "Analyze this threat behavior and identify the MITRE ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def format_training_sample(sample: Dict[str, Any]) -> Dict[str, str]:\n",
    "    \"\"\"\n",
    "    Format training sample for instruction tuning\n",
    "\n",
    "    Input format:\n",
    "    {\n",
    "        \"instruction\": \"Adversary behavior description...\",\n",
    "        \"output\": {\n",
    "            \"techniques\": [{\n",
    "                \"id\": \"T1055.011\",\n",
    "                \"name\": \"Extra Window Memory Injection\",\n",
    "                \"description\": \"...\",\n",
    "                \"matrix\": \"enterprise\"\n",
    "            }]\n",
    "        }\n",
    "    }\n",
    "\n",
    "    Output format for instruction tuning:\n",
    "    {\n",
    "        \"text\": \"<|im_start|>system\\nYou are a cybersecurity expert...\\n<|im_end|>\\n<|im_start|>user\\n...\\n<|im_end|>\\n<|im_start|>assistant\\n...\\n<|im_end|>\"\n",
    "    }\n",
    "    \"\"\"\n",
    "    instruction = sample['instruction']\n",
    "    technique = sample['output']['techniques'][0]\n",
    "\n",
    "    # Create system prompt\n",
    "    system_prompt = \"\"\"You are a cybersecurity expert specializing in MITRE ATT&CK framework. Your task is to analyze threat intelligence descriptions and identify the corresponding MITRE ATT&CK techniques.\n",
    "\n",
    "Given a description of adversary behavior, identify the most relevant MITRE ATT&CK technique and provide:\n",
    "1. Technique ID (e.g., T1055.011)\n",
    "2. Technique Name\n",
    "3. Matrix (enterprise/mobile/ics)\n",
    "\n",
    "Respond in JSON format.\"\"\"\n",
    "\n",
    "    # Create user input\n",
    "    user_input = f\"Analyze this threat behavior and identify the MITRE ATT&CK technique:\\n\\n{instruction}\"\n",
    "\n",
    "    # Create assistant response\n",
    "    assistant_response = json.dumps({\n",
    "        \"technique_id\": technique['id'],\n",
    "        \"technique_name\": technique['name'],\n",
    "        \"matrix\": technique['matrix'],\n",
    "        \"description\": technique['description']\n",
    "    }, ensure_ascii=False)\n",
    "\n",
    "    # Format for Qwen chat template\n",
    "    formatted_text = f\"\"\"<|im_start|>system\n",
    "{system_prompt}<|im_end|>\n",
    "<|im_start|>user\n",
    "{user_input}<|im_end|>\n",
    "<|im_start|>assistant\n",
    "{assistant_response}<|im_end|>\"\"\"\n",
    "\n",
    "    return {\"text\": formatted_text}\n",
    "\n",
    "# Format all training samples\n",
    "print(\"üîÑ Formatting training data...\")\n",
    "formatted_samples = []\n",
    "for sample in tqdm(training_samples):\n",
    "    formatted_sample = format_training_sample(sample)\n",
    "    formatted_samples.append(formatted_sample)\n",
    "\n",
    "print(f\"‚úÖ Formatted {len(formatted_samples):,} training samples\")\n",
    "\n",
    "# Show formatted example\n",
    "print(\"\\nüìù Formatted Training Example:\")\n",
    "print(formatted_samples[0]['text'][:500] + \"...\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## 4. Setup Qwen Model and Tokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-08T07:38:30.767211Z",
     "start_time": "2025-08-08T07:38:25.677938Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ Setting up model: Qwen/Qwen2.5-1.5B-Instruct\n",
      "üîß Using device: cpu\n",
      "üìù Loading tokenizer...\n",
      "‚úÖ Tokenizer loaded\n",
      "üìä Vocab size: 151,665\n",
      "üîë Special tokens: {'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}\n",
      "ü§ñ Loading model...\n",
      "‚úÖ Model loaded\n",
      "üìä Model parameters: 1,543,714,304\n",
      "üéØ Trainable parameters: 1,543,714,304\n"
     ]
    }
   ],
   "source": [
    "# Model configuration\n",
    "MODEL_NAME = \"Qwen/Qwen2.5-1.5B-Instruct\"\n",
    "MAX_LENGTH = 2048\n",
    "BATCH_SIZE = 4\n",
    "LEARNING_RATE = 2e-5\n",
    "NUM_EPOCHS = 3\n",
    "WARMUP_STEPS = 100\n",
    "\n",
    "print(f\"ü§ñ Setting up model: {MODEL_NAME}\")\n",
    "\n",
    "# Setup device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"üîß Using device: {device}\")\n",
    "\n",
    "# Load tokenizer\n",
    "print(\"üìù Loading tokenizer...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    trust_remote_code=True,\n",
    "    padding_side=\"right\"\n",
    ")\n",
    "\n",
    "# Add padding token if not exists\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    print(\"üîß Set pad_token = eos_token\")\n",
    "\n",
    "print(f\"‚úÖ Tokenizer loaded\")\n",
    "print(f\"üìä Vocab size: {len(tokenizer):,}\")\n",
    "print(f\"üîë Special tokens: {tokenizer.special_tokens_map}\")\n",
    "\n",
    "# Load model\n",
    "print(\"ü§ñ Loading model...\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    trust_remote_code=True,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\",\n",
    "    low_cpu_mem_usage=True\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Model loaded\")\n",
    "print(f\"üìä Model parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "print(f\"üéØ Trainable parameters: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## 5. Create Dataset and Data Loaders\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-08T07:38:31.328746Z",
     "start_time": "2025-08-08T07:38:30.860232Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Creating train/validation split...\n",
      "üìö Training samples: 828\n",
      "üîç Validation samples: 93\n",
      "üîÑ Creating datasets...\n",
      "üî§ Tokenizing datasets...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b41600b79094715bb3b813f8c289e2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing train data:   0%|          | 0/828 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed9663394f8242cfad30306307359666",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing validation data:   0%|          | 0/93 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Datasets prepared\n",
      "üìä Train dataset: 828 samples\n",
      "üìä Validation dataset: 93 samples\n",
      "\n",
      "üìù Sample tokenization:\n",
      "Input IDs length: 2048\n",
      "Attention mask length: 2048\n",
      "Labels length: 2048\n"
     ]
    }
   ],
   "source": [
    "def tokenize_function(examples):\n",
    "    \"\"\"\n",
    "    Tokenize training examples\n",
    "    \"\"\"\n",
    "    # Tokenize the text\n",
    "    tokenized = tokenizer(\n",
    "        examples[\"text\"],\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",  # S·ª¨A L·ªñI: Pad to max length\n",
    "        max_length=MAX_LENGTH,\n",
    "        return_tensors=None\n",
    "    )\n",
    "\n",
    "    # For causal language modeling, labels are the same as input_ids\n",
    "    tokenized[\"labels\"] = tokenized[\"input_ids\"].copy()\n",
    "\n",
    "    return tokenized\n",
    "\n",
    "# Create train/validation split\n",
    "print(\"üìä Creating train/validation split...\")\n",
    "train_samples, val_samples = train_test_split(\n",
    "    formatted_samples,\n",
    "    test_size=0.1,\n",
    "    random_state=42,\n",
    "    stratify=[sample['text'].split('\"matrix\": \"')[1].split('\"')[0] for sample in formatted_samples]\n",
    ")\n",
    "\n",
    "print(f\"üìö Training samples: {len(train_samples):,}\")\n",
    "print(f\"üîç Validation samples: {len(val_samples):,}\")\n",
    "\n",
    "# Create HuggingFace datasets\n",
    "print(\"üîÑ Creating datasets...\")\n",
    "train_dataset = Dataset.from_list(train_samples)\n",
    "val_dataset = Dataset.from_list(val_samples)\n",
    "\n",
    "# Tokenize datasets\n",
    "print(\"üî§ Tokenizing datasets...\")\n",
    "train_dataset = train_dataset.map(\n",
    "    tokenize_function,\n",
    "    batched=True,\n",
    "    remove_columns=[\"text\"],\n",
    "    desc=\"Tokenizing train data\"\n",
    ")\n",
    "\n",
    "val_dataset = val_dataset.map(\n",
    "    tokenize_function,\n",
    "    batched=True,\n",
    "    remove_columns=[\"text\"],\n",
    "    desc=\"Tokenizing validation data\"\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Datasets prepared\")\n",
    "print(f\"üìä Train dataset: {len(train_dataset):,} samples\")\n",
    "print(f\"üìä Validation dataset: {len(val_dataset):,} samples\")\n",
    "\n",
    "# Check tokenization\n",
    "sample_tokens = train_dataset[0]\n",
    "print(f\"\\nüìù Sample tokenization:\")\n",
    "print(f\"Input IDs length: {len(sample_tokens['input_ids'])}\")\n",
    "print(f\"Attention mask length: {len(sample_tokens['attention_mask'])}\")\n",
    "print(f\"Labels length: {len(sample_tokens['labels'])}\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## 6. Setup Training Configuration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-08T07:38:31.339523Z",
     "start_time": "2025-08-08T07:38:31.334304Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÅ Output directory: ../models/qwen-ttp-classification-2025-08-08_14-38-31\n",
      "‚úÖ Training arguments configured\n",
      "üéØ Batch size: 4\n",
      "üìà Learning rate: 2e-05\n",
      "üîÑ Epochs: 3\n",
      "üî• FP16: True\n",
      "üíæ Gradient checkpointing: True\n",
      "‚úÖ Data collator configured\n"
     ]
    }
   ],
   "source": [
    "# Create output directory\n",
    "timestamp = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "output_dir = f\"../models/qwen-ttp-classification-{timestamp}\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "print(f\"üìÅ Output directory: {output_dir}\")\n",
    "\n",
    "# Training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    overwrite_output_dir=True,\n",
    "\n",
    "    # Training parameters\n",
    "    num_train_epochs=NUM_EPOCHS,\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    per_device_eval_batch_size=BATCH_SIZE,\n",
    "    gradient_accumulation_steps=1,\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    weight_decay=0.01,\n",
    "    warmup_steps=WARMUP_STEPS,\n",
    "\n",
    "    # Optimization\n",
    "    fp16=True,\n",
    "    dataloader_pin_memory=False,\n",
    "    gradient_checkpointing=True,\n",
    "\n",
    "    # Logging and saving\n",
    "    logging_dir=f\"{output_dir}/logs\",\n",
    "    logging_steps=10,\n",
    "    save_steps=100,\n",
    "    save_total_limit=3,\n",
    "    eval_steps=100,\n",
    "    eval_strategy=\"steps\",  # FIXED: was evaluation_strategy\n",
    "\n",
    "    # Other settings\n",
    "    remove_unused_columns=False,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    "    greater_is_better=False,\n",
    "\n",
    "    # Report\n",
    "    report_to=None,  # Disable wandb/tensorboard\n",
    "    run_name=f\"qwen-ttp-classification-{timestamp}\"\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Training arguments configured\")\n",
    "print(f\"üéØ Batch size: {BATCH_SIZE}\")\n",
    "print(f\"üìà Learning rate: {LEARNING_RATE}\")\n",
    "print(f\"üîÑ Epochs: {NUM_EPOCHS}\")\n",
    "print(f\"üî• FP16: {training_args.fp16}\")\n",
    "print(f\"üíæ Gradient checkpointing: {training_args.gradient_checkpointing}\")\n",
    "\n",
    "# Data collator\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer,\n",
    "    mlm=False,  # No masking for causal LM\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Data collator configured\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## 7. Initialize Trainer and Start Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-08T07:38:31.894058Z",
     "start_time": "2025-08-08T07:38:31.345196Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß Initializing MPS-compatible training...\n",
      "üßπ MPS cache cleared\n",
      "üìÅ Output: ../models/qwen-ttp-mps-2025-08-08_14-38-31\n",
      "‚úÖ Configuration created!\n",
      "üî• FP16: False (ph·∫£i False)\n",
      "üçé BF16: False (ph·∫£i False)\n",
      "\n",
      "üèÉ‚Äç‚ôÇÔ∏è Creating trainer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/lt/y_3sh6vn2mb68907rlw4xvww0000gn/T/ipykernel_12842/3816146588.py:81: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Trainer initialized successfully!\n",
      "üçé Ready for MPS training!\n",
      "üìä Batch size: 2\n",
      "üîÑ Effective batch: 4 (v·ªõi gradient accumulation)\n",
      "üìà Learning rate: 2e-05\n",
      "\n",
      "üöÄ Ready to train! Run: trainer.train()\n"
     ]
    }
   ],
   "source": [
    "# ‚úÖ CODE ƒê√É S·ª¨A HO√ÄN CH·ªàNH CHO MPS (APPLE SILICON)\n",
    "print(\"üîß Initializing MPS-compatible training...\")\n",
    "\n",
    "import torch\n",
    "from transformers import TrainingArguments, Trainer, DataCollatorForLanguageModeling\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "# Clear memory\n",
    "if torch.backends.mps.is_available():\n",
    "    torch.mps.empty_cache()\n",
    "    print(\"üßπ MPS cache cleared\")\n",
    "\n",
    "# Configuration\n",
    "MODEL_NAME = \"Qwen/Qwen2.5-1.5B-Instruct\"\n",
    "BATCH_SIZE = 2  # Smaller for MPS\n",
    "LEARNING_RATE = 2e-5\n",
    "NUM_EPOCHS = 3\n",
    "WARMUP_STEPS = 100\n",
    "\n",
    "# Create output directory\n",
    "timestamp = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "output_dir = f\"../models/qwen-ttp-mps-{timestamp}\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "print(f\"üìÅ Output: {output_dir}\")\n",
    "\n",
    "# ‚úÖ MPS-COMPATIBLE TrainingArguments (S·ª¨A L·ªñI)\n",
    "training_args_mps = TrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    overwrite_output_dir=True,\n",
    "\n",
    "    # Training params\n",
    "    num_train_epochs=NUM_EPOCHS,\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    per_device_eval_batch_size=BATCH_SIZE,\n",
    "    gradient_accumulation_steps=2,  # TƒÉng ƒë·ªÉ b√π ƒë·∫Øp batch nh·ªè\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    weight_decay=0.01,\n",
    "    warmup_steps=WARMUP_STEPS,\n",
    "\n",
    "    # ‚ö†Ô∏è QUAN TR·ªåNG: MPS settings\n",
    "    fp16=False,              # PH·∫¢I False cho MPS\n",
    "    bf16=False,              # PH·∫¢I False cho MPS\n",
    "    dataloader_pin_memory=False,\n",
    "    gradient_checkpointing=True,\n",
    "\n",
    "    # Logging\n",
    "    logging_steps=10,\n",
    "    save_steps=100,\n",
    "    eval_steps=100,\n",
    "    eval_strategy=\"steps\",   # S·ª¨A: kh√¥ng ph·∫£i evaluation_strategy\n",
    "    save_total_limit=3,\n",
    "\n",
    "    # Evaluation\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    "    greater_is_better=False,\n",
    "\n",
    "    # Disable external services\n",
    "    report_to=None,\n",
    "    dataloader_num_workers=0,  # Single thread cho MPS\n",
    ")\n",
    "\n",
    "# ‚úÖ Data collator (S·ª¨A L·ªñI)\n",
    "data_collator_mps = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer,\n",
    "    mlm=False\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Configuration created!\")\n",
    "print(f\"üî• FP16: {training_args_mps.fp16} (ph·∫£i False)\")\n",
    "print(f\"üçé BF16: {training_args_mps.bf16} (ph·∫£i False)\")\n",
    "\n",
    "# ‚úÖ Initialize Trainer (S·ª¨A L·ªñI - KH√îNG c√≥ accelerator argument)\n",
    "print(\"\\nüèÉ‚Äç‚ôÇÔ∏è Creating trainer...\")\n",
    "\n",
    "os.environ[\"ACCELERATE_MIXED_PRECISION\"] = \"no\"\n",
    "os.environ[\"ACCELERATE_DISABLE_RICH\"] = \"1\"\n",
    "\n",
    "# Kh·ªüi t·∫°o trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args_mps,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator_mps,\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Trainer initialized successfully!\")\n",
    "print(\"üçé Ready for MPS training!\")\n",
    "print(f\"üìä Batch size: {BATCH_SIZE}\")\n",
    "print(f\"üîÑ Effective batch: {BATCH_SIZE * 2} (v·ªõi gradient accumulation)\")\n",
    "print(f\"üìà Learning rate: {LEARNING_RATE}\")\n",
    "\n",
    "# ‚úÖ B√¢y gi·ªù c√≥ th·ªÉ b·∫Øt ƒë·∫ßu training\n",
    "print(\"\\nüöÄ Ready to train! Run: trainer.train()\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## 8. Model Evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-08T08:02:47.872429Z",
     "start_time": "2025-08-08T07:38:31.898205Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Evaluating model...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='43' max='47' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [43/47 23:32 < 02:14, 0.03 it/s]\n",
       "    </div>\n",
       "    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[8], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# Evaluate the model\u001B[39;00m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124müìä Evaluating model...\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m----> 3\u001B[0m eval_result \u001B[38;5;241m=\u001B[39m \u001B[43mtrainer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mevaluate\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      5\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124müìà Evaluation Results:\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m      6\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m key, value \u001B[38;5;129;01min\u001B[39;00m eval_result\u001B[38;5;241m.\u001B[39mitems():\n",
      "File \u001B[0;32m~/Documents/UIT/2nd/NLP/LLM-TKIG/.venv/lib/python3.12/site-packages/transformers/trainer.py:4199\u001B[0m, in \u001B[0;36mTrainer.evaluate\u001B[0;34m(self, eval_dataset, ignore_keys, metric_key_prefix)\u001B[0m\n\u001B[1;32m   4196\u001B[0m start_time \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime()\n\u001B[1;32m   4198\u001B[0m eval_loop \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprediction_loop \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs\u001B[38;5;241m.\u001B[39muse_legacy_prediction_loop \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mevaluation_loop\n\u001B[0;32m-> 4199\u001B[0m output \u001B[38;5;241m=\u001B[39m \u001B[43meval_loop\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   4200\u001B[0m \u001B[43m    \u001B[49m\u001B[43meval_dataloader\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   4201\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdescription\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mEvaluation\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m   4202\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;66;43;03m# No point gathering the predictions if there are no metrics, otherwise we defer to\u001B[39;49;00m\n\u001B[1;32m   4203\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;66;43;03m# self.args.prediction_loss_only\u001B[39;49;00m\n\u001B[1;32m   4204\u001B[0m \u001B[43m    \u001B[49m\u001B[43mprediction_loss_only\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcompute_metrics\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mis\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m   4205\u001B[0m \u001B[43m    \u001B[49m\u001B[43mignore_keys\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mignore_keys\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   4206\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmetric_key_prefix\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmetric_key_prefix\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   4207\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   4209\u001B[0m total_batch_size \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs\u001B[38;5;241m.\u001B[39meval_batch_size \u001B[38;5;241m*\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs\u001B[38;5;241m.\u001B[39mworld_size\n\u001B[1;32m   4210\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mmetric_key_prefix\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m_jit_compilation_time\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m output\u001B[38;5;241m.\u001B[39mmetrics:\n",
      "File \u001B[0;32m~/Documents/UIT/2nd/NLP/LLM-TKIG/.venv/lib/python3.12/site-packages/transformers/trainer.py:4384\u001B[0m, in \u001B[0;36mTrainer.evaluation_loop\u001B[0;34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001B[0m\n\u001B[1;32m   4381\u001B[0m observed_num_examples \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[1;32m   4383\u001B[0m \u001B[38;5;66;03m# Main evaluation loop\u001B[39;00m\n\u001B[0;32m-> 4384\u001B[0m \u001B[43m\u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mstep\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43menumerate\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mdataloader\u001B[49m\u001B[43m)\u001B[49m\u001B[43m:\u001B[49m\n\u001B[1;32m   4385\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;66;43;03m# Update the observed num examples\u001B[39;49;00m\n\u001B[1;32m   4386\u001B[0m \u001B[43m    \u001B[49m\u001B[43mobserved_batch_size\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mfind_batch_size\u001B[49m\u001B[43m(\u001B[49m\u001B[43minputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   4387\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mobserved_batch_size\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mis\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mnot\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m:\u001B[49m\n",
      "File \u001B[0;32m~/Documents/UIT/2nd/NLP/LLM-TKIG/.venv/lib/python3.12/site-packages/accelerate/data_loader.py:577\u001B[0m, in \u001B[0;36mDataLoaderShard.__iter__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    574\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    575\u001B[0m     \u001B[38;5;66;03m# But we still move it to the device so it is done before `StopIteration` is reached\u001B[39;00m\n\u001B[1;32m    576\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdevice \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 577\u001B[0m         current_batch \u001B[38;5;241m=\u001B[39m \u001B[43msend_to_device\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcurrent_batch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdevice\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnon_blocking\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_non_blocking\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    578\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_update_state_dict()\n\u001B[1;32m    579\u001B[0m     next_batch \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mnext\u001B[39m(dataloader_iter)\n",
      "File \u001B[0;32m~/Documents/UIT/2nd/NLP/LLM-TKIG/.venv/lib/python3.12/site-packages/accelerate/utils/operations.py:153\u001B[0m, in \u001B[0;36msend_to_device\u001B[0;34m(tensor, device, non_blocking, skip_keys)\u001B[0m\n\u001B[1;32m    151\u001B[0m     device \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnpu:0\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    152\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 153\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtensor\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnon_blocking\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnon_blocking\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    154\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m:  \u001B[38;5;66;03m# .to() doesn't accept non_blocking as kwarg\u001B[39;00m\n\u001B[1;32m    155\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m tensor\u001B[38;5;241m.\u001B[39mto(device)\n",
      "File \u001B[0;32m~/Documents/UIT/2nd/NLP/LLM-TKIG/.venv/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:811\u001B[0m, in \u001B[0;36mBatchEncoding.to\u001B[0;34m(self, device, non_blocking)\u001B[0m\n\u001B[1;32m    806\u001B[0m \u001B[38;5;66;03m# This check catches things like APEX blindly calling \"to\" on all inputs to a module\u001B[39;00m\n\u001B[1;32m    807\u001B[0m \u001B[38;5;66;03m# Otherwise it passes the casts down and casts the LongTensor containing the token idxs\u001B[39;00m\n\u001B[1;32m    808\u001B[0m \u001B[38;5;66;03m# into a HalfTensor\u001B[39;00m\n\u001B[1;32m    809\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(device, \u001B[38;5;28mstr\u001B[39m) \u001B[38;5;129;01mor\u001B[39;00m is_torch_device(device) \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(device, \u001B[38;5;28mint\u001B[39m):\n\u001B[1;32m    810\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdata \u001B[38;5;241m=\u001B[39m {\n\u001B[0;32m--> 811\u001B[0m         k: \u001B[43mv\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdevice\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdevice\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnon_blocking\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnon_blocking\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(v, torch\u001B[38;5;241m.\u001B[39mTensor) \u001B[38;5;28;01melse\u001B[39;00m v\n\u001B[1;32m    812\u001B[0m         \u001B[38;5;28;01mfor\u001B[39;00m k, v \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdata\u001B[38;5;241m.\u001B[39mitems()\n\u001B[1;32m    813\u001B[0m     }\n\u001B[1;32m    814\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    815\u001B[0m     logger\u001B[38;5;241m.\u001B[39mwarning(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAttempting to cast a BatchEncoding to type \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mstr\u001B[39m(device)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m. This is not supported.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "print(\"üìä Evaluating model...\")\n",
    "eval_result = trainer.evaluate()\n",
    "\n",
    "print(\"\\nüìà Evaluation Results:\")\n",
    "for key, value in eval_result.items():\n",
    "    print(f\"  {key}: {value:.4f}\")\n",
    "\n",
    "# Save evaluation results\n",
    "eval_file = os.path.join(output_dir, \"evaluation_results.json\")\n",
    "with open(eval_file, 'w') as f:\n",
    "    json.dump(eval_result, f, indent=2)\n",
    "\n",
    "print(f\"‚úÖ Evaluation results saved to: {eval_file}\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## 9. Test Model Inference\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_ttp_classification(model, tokenizer, threat_description: str) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Test TTP classification on a threat description\n",
    "    \"\"\"\n",
    "    system_prompt = \"\"\"You are a cybersecurity expert specializing in MITRE ATT&CK framework. Your task is to analyze threat intelligence descriptions and identify the corresponding MITRE ATT&CK techniques.\n",
    "\n",
    "Given a description of adversary behavior, identify the most relevant MITRE ATT&CK technique and provide:\n",
    "1. Technique ID (e.g., T1055.011)\n",
    "2. Technique Name\n",
    "3. Matrix (enterprise/mobile/ics)\n",
    "\n",
    "Respond in JSON format.\"\"\"\n",
    "\n",
    "    user_input = f\"Analyze this threat behavior and identify the MITRE ATT&CK technique:\\n\\n{threat_description}\"\n",
    "\n",
    "    # Format input\n",
    "    prompt = f\"\"\"<|im_start|>system\n",
    "{system_prompt}<|im_end|>\n",
    "<|im_start|>user\n",
    "{user_input}<|im_end|>\n",
    "<|im_start|>assistant\n",
    "\"\"\"\n",
    "\n",
    "    # Tokenize\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=1024)\n",
    "    inputs = {k: v.to(model.device) for k, v in inputs.items()}\n",
    "\n",
    "    # Generate response\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=256,\n",
    "            temperature=0.1,\n",
    "            do_sample=True,\n",
    "            pad_token_id=tokenizer.eos_token_id\n",
    "        )\n",
    "\n",
    "    # Decode response\n",
    "    full_response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    assistant_response = full_response.split(\"<|im_start|>assistant\\n\")[-1]\n",
    "\n",
    "    return {\n",
    "        \"input\": threat_description,\n",
    "        \"response\": assistant_response,\n",
    "        \"full_prompt\": prompt\n",
    "    }\n",
    "\n",
    "# Test examples\n",
    "test_cases = [\n",
    "    \"Adversaries may inject malicious code into processes in order to evade process-based defenses or elevate privileges.\",\n",
    "    \"Attackers send phishing emails with malicious attachments to gain initial access to the target system.\",\n",
    "    \"The malware establishes persistence by creating scheduled tasks that execute at system startup.\",\n",
    "    \"Adversaries may abuse elevation control mechanisms to gain higher-level permissions on a system.\"\n",
    "]\n",
    "\n",
    "print(\"üß™ Testing model inference...\")\n",
    "for i, test_case in enumerate(test_cases, 1):\n",
    "    print(f\"\\nüìù Test Case {i}:\")\n",
    "    print(f\"Input: {test_case}\")\n",
    "\n",
    "    result = test_ttp_classification(model, tokenizer, test_case)\n",
    "    print(f\"Output: {result['response']}\")\n",
    "    print(\"-\" * 80)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## 10. Save Training Summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training summary\n",
    "# This cell is now safe to run even if training/evaluation was skipped.\n",
    "\n",
    "print(\"üìÑ Creating training summary...\")\n",
    "\n",
    "# Use locals() to check if variables were defined in the session\n",
    "training_result_obj = locals().get('training_result')\n",
    "eval_result_obj = locals().get('eval_result')\n",
    "\n",
    "# Define all variables safely\n",
    "safe_model_name = locals().get('MODEL_NAME', 'N/A')\n",
    "safe_timestamp = locals().get('timestamp', datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\"))\n",
    "safe_output_dir = locals().get('output_dir', 'N/A')\n",
    "safe_training_samples = locals().get('training_samples', [])\n",
    "safe_train_dataset = locals().get('train_dataset', [])\n",
    "safe_val_dataset = locals().get('val_dataset', [])\n",
    "safe_technique_ids = locals().get('technique_ids', set())\n",
    "safe_matrices = locals().get('matrices', {})\n",
    "safe_batch_size = locals().get('BATCH_SIZE', 'N/A')\n",
    "safe_lr = locals().get('LEARNING_RATE', 'N/A')\n",
    "safe_epochs = locals().get('NUM_EPOCHS', 'N/A')\n",
    "safe_max_length = locals().get('MAX_LENGTH', 'N/A')\n",
    "safe_warmup_steps = locals().get('WARMUP_STEPS', 'N/A')\n",
    "\n",
    "\n",
    "training_summary = {\n",
    "    \"model_name\": safe_model_name,\n",
    "    \"training_timestamp\": safe_timestamp,\n",
    "    \"output_directory\": safe_output_dir,\n",
    "    \"dataset_info\": {\n",
    "        \"total_samples\": len(safe_training_samples),\n",
    "        \"train_samples\": len(safe_train_dataset),\n",
    "        \"val_samples\": len(safe_val_dataset),\n",
    "        \"unique_techniques\": len(safe_technique_ids),\n",
    "        \"matrix_distribution\": safe_matrices\n",
    "    },\n",
    "    \"training_config\": {\n",
    "        \"batch_size\": safe_batch_size,\n",
    "        \"learning_rate\": safe_lr,\n",
    "        \"num_epochs\": safe_epochs,\n",
    "        \"max_length\": safe_max_length,\n",
    "        \"warmup_steps\": safe_warmup_steps\n",
    "    },\n",
    "    \"training_results\": {\n",
    "        \"final_loss\": getattr(training_result_obj, 'training_loss', None),\n",
    "        \"training_time_seconds\": getattr(training_result_obj, 'training_time', None)\n",
    "    },\n",
    "    \"evaluation_results\": eval_result_obj\n",
    "}\n",
    "\n",
    "# Save summary\n",
    "summary_file = os.path.join(safe_output_dir, \"training_summary.json\") if safe_output_dir != \"N/A\" else \"training_summary.json\"\n",
    "with open(summary_file, 'w', encoding='utf-8') as f:\n",
    "    json.dump(training_summary, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"üìÑ Training summary saved to: {summary_file}\")\n",
    "\n",
    "# Display summary\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"üìä TRAINING SUMMARY üìä\")\n",
    "print(\"=\"*50)\n",
    "print(f\"  Model: {training_summary['model_name']}\")\n",
    "final_loss = training_summary['training_results']['final_loss']\n",
    "eval_loss = training_summary['evaluation_results'].get('eval_loss') if training_summary['evaluation_results'] else None\n",
    "training_time = training_summary['training_results']['training_time_seconds']\n",
    "\n",
    "print(f\"  Final training loss: {final_loss:.4f}\" if final_loss is not None else \"  Final training loss: N/A\")\n",
    "print(f\"  Final validation loss: {eval_loss:.4f}\" if eval_loss is not None else \"  Final validation loss: N/A\")\n",
    "print(f\"  Training time: {training_time:.1f} seconds\" if training_time is not None else \"  Training time: N/A\")\n",
    "print(f\"  Model saved to: {training_summary['output_directory']}\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "if training_result_obj is None:\n",
    "    print(\"\\n‚ö†Ô∏è NOTE: 'training_result' not found. Run 'training_result = trainer.train()' to get training stats.\")\n",
    "if eval_result_obj is None:\n",
    "    print(\"‚ö†Ô∏è NOTE: 'eval_result' not found. Run 'eval_result = trainer.evaluate()' to get evaluation stats.\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
