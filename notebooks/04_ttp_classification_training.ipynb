{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# TTP Classification Training with Qwen Model\n",
    "\n",
    "## Overview\n",
    "This notebook implements TTP (Tactics, Techniques, and Procedures) classification training using Qwen model with MITRE ATT&CK framework.\n",
    "\n",
    "### Task Description\n",
    "- **Input**: Threat intelligence text descriptions\n",
    "- **Output**: MITRE ATT&CK technique classification (T1xxx format)\n",
    "- **Model**: Qwen/Qwen2.5-1.5B-Instruct (fine-tuned)\n",
    "\n",
    "### Dataset Statistics\n",
    "- **Total samples**: 921 training examples\n",
    "- **Enterprise Matrix**: 691 techniques (222 main + 469 sub-techniques)\n",
    "- **Mobile Matrix**: 135 techniques (89 main + 46 sub-techniques)\n",
    "- **ICS Matrix**: 95 techniques (95 main + 0 sub-techniques)\n",
    "\n",
    "### Key Steps\n",
    "1. Load and prepare MITRE ATT&CK training data\n",
    "2. Setup Qwen model for fine-tuning\n",
    "3. Create training and validation splits\n",
    "4. Fine-tune model for TTP classification\n",
    "5. Evaluate model performance\n",
    "6. Test on real threat intelligence data\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 1. Environment Setup and Dependencies\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-08T07:19:26.656306Z",
     "start_time": "2025-08-08T07:19:22.772656Z"
    }
   },
   "source": [
    "import json\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Any, Tuple\n",
    "import logging\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Transformers and training\n",
    "from transformers import (\n",
    "    AutoTokenizer, \n",
    "    AutoModelForCausalLM,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    DataCollatorForLanguageModeling\n",
    ")\n",
    "from datasets import Dataset, DatasetDict\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "print(\"üìö Dependencies loaded successfully!\")\n",
    "print(f\"üî• PyTorch version: {torch.__version__}\")\n",
    "\n",
    "# Check device availability\n",
    "print(f\"ü§ñ CUDA available: {torch.cuda.is_available()}\")\n",
    "print(f\"üçé MPS available: {torch.backends.mps.is_available()}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"üéÆ GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"üíæ GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    print(f\"üçé Using Apple Silicon MPS\")\n",
    "    print(f\"üíª Device: Apple Silicon Mac\")\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è  Using CPU only\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìö Dependencies loaded successfully!\n",
      "üî• PyTorch version: 2.8.0\n",
      "ü§ñ CUDA available: False\n",
      "üçé MPS available: True\n",
      "üçé Using Apple Silicon MPS\n",
      "üíª Device: Apple Silicon Mac\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 2. Load MITRE ATT&CK Training Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-08T07:19:22.039341Z",
     "start_time": "2025-08-08T07:15:00.921344Z"
    }
   },
   "source": [
    "# Load merged MITRE ATT&CK dataset\n",
    "dataset_path = \"../data/TTP-classification/merged_mitre_attack_dataset.json\"\n",
    "\n",
    "print(\"üìÇ Loading MITRE ATT&CK dataset...\")\n",
    "with open(dataset_path, 'r', encoding='utf-8') as f:\n",
    "    mitre_data = json.load(f)\n",
    "\n",
    "# Extract training samples\n",
    "training_samples = mitre_data['dataset']\n",
    "print(f\"‚úÖ Loaded {len(training_samples):,} training samples\")\n",
    "\n",
    "# Analyze dataset structure\n",
    "print(\"\\nüìä Dataset Analysis:\")\n",
    "matrices = {'enterprise': 0, 'mobile': 0, 'ics': 0}\n",
    "techniques_count = 0\n",
    "sub_techniques_count = 0\n",
    "technique_ids = set()\n",
    "\n",
    "for sample in training_samples:\n",
    "    technique = sample['output']['techniques'][0]\n",
    "    matrix = technique['matrix']\n",
    "    technique_id = technique['id']\n",
    "    \n",
    "    matrices[matrix] += 1\n",
    "    technique_ids.add(technique_id)\n",
    "    \n",
    "    if '.' in technique_id:\n",
    "        sub_techniques_count += 1\n",
    "    else:\n",
    "        techniques_count += 1\n",
    "\n",
    "print(f\"  ‚Ä¢ Enterprise: {matrices['enterprise']:,} samples\")\n",
    "print(f\"  ‚Ä¢ Mobile: {matrices['mobile']:,} samples\")\n",
    "print(f\"  ‚Ä¢ ICS: {matrices['ics']:,} samples\")\n",
    "print(f\"  ‚Ä¢ Techniques: {techniques_count:,} samples\")\n",
    "print(f\"  ‚Ä¢ Sub-techniques: {sub_techniques_count:,} samples\")\n",
    "print(f\"  ‚Ä¢ Unique technique IDs: {len(technique_ids):,}\")\n",
    "\n",
    "# Show sample data\n",
    "print(\"\\nüìù Sample Training Example:\")\n",
    "sample = training_samples[0]\n",
    "print(f\"Instruction: {sample['instruction'][:100]}...\")\n",
    "print(f\"Technique ID: {sample['output']['techniques'][0]['id']}\")\n",
    "print(f\"Technique Name: {sample['output']['techniques'][0]['name']}\")\n",
    "print(f\"Matrix: {sample['output']['techniques'][0]['matrix']}\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Loading MITRE ATT&CK dataset...\n",
      "‚úÖ Loaded 921 training samples\n",
      "\n",
      "üìä Dataset Analysis:\n",
      "  ‚Ä¢ Enterprise: 691 samples\n",
      "  ‚Ä¢ Mobile: 135 samples\n",
      "  ‚Ä¢ ICS: 95 samples\n",
      "  ‚Ä¢ Techniques: 406 samples\n",
      "  ‚Ä¢ Sub-techniques: 515 samples\n",
      "  ‚Ä¢ Unique technique IDs: 921\n",
      "\n",
      "üìù Sample Training Example:\n",
      "Instruction: Adversaries may inject malicious code into process via Extra Window Memory (EWM) in order to evade p...\n",
      "Technique ID: T1055.011\n",
      "Technique Name: Extra Window Memory Injection\n",
      "Matrix: enterprise\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 3. Setup Training Configuration (Fixed)\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-08T07:19:22.046989Z",
     "start_time": "2025-08-08T07:15:00.953015Z"
    }
   },
   "source": [
    "# Model configuration\n",
    "MODEL_NAME = \"Qwen/Qwen2.5-1.5B-Instruct\"\n",
    "MAX_LENGTH = 2048\n",
    "BATCH_SIZE = 4\n",
    "LEARNING_RATE = 2e-5\n",
    "NUM_EPOCHS = 3\n",
    "WARMUP_STEPS = 100\n",
    "\n",
    "print(f\"ü§ñ Setting up model: {MODEL_NAME}\")\n",
    "\n",
    "# Create output directory\n",
    "timestamp = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "output_dir = f\"../models/qwen-ttp-classification-{timestamp}\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "print(f\"üìÅ Output directory: {output_dir}\")\n",
    "\n",
    "# Training arguments (FIXED - eval_strategy instead of evaluation_strategy)\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    overwrite_output_dir=True,\n",
    "    \n",
    "    # Training parameters\n",
    "    num_train_epochs=NUM_EPOCHS,\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    per_device_eval_batch_size=BATCH_SIZE,\n",
    "    gradient_accumulation_steps=1,\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    weight_decay=0.01,\n",
    "    warmup_steps=WARMUP_STEPS,\n",
    "    \n",
    "    # Optimization (MPS compatible - FIXED)\n",
    "    fp16=torch.cuda.is_available(),  # Only use fp16 on CUDA\n",
    "    bf16=False,  # Disable bf16 - MPS doesn't support it in TrainingArguments\n",
    "    dataloader_pin_memory=False,\n",
    "    gradient_checkpointing=True,\n",
    "    \n",
    "    # Logging and saving\n",
    "    logging_dir=f\"{output_dir}/logs\",\n",
    "    logging_steps=10,\n",
    "    save_steps=100,\n",
    "    save_total_limit=3,\n",
    "    eval_steps=100,\n",
    "    eval_strategy=\"steps\",  # FIXED: was evaluation_strategy\n",
    "    \n",
    "    # Other settings\n",
    "    remove_unused_columns=False,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    "    greater_is_better=False,\n",
    "    \n",
    "    # Report\n",
    "    report_to=None,  # Disable wandb/tensorboard\n",
    "    run_name=f\"qwen-ttp-classification-{timestamp}\"\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Training arguments configured (FIXED + MPS)\")\n",
    "print(f\"üéØ Batch size: {BATCH_SIZE}\")\n",
    "print(f\"üìà Learning rate: {LEARNING_RATE}\")\n",
    "print(f\"üîÑ Epochs: {NUM_EPOCHS}\")\n",
    "print(f\"üî• FP16 (CUDA only): {training_args.fp16}\")\n",
    "print(f\"üçé BF16 (Disabled): {training_args.bf16}\")\n",
    "print(f\"üíæ Gradient checkpointing: {training_args.gradient_checkpointing}\")\n",
    "print(f\"üîß FIXED: eval_strategy + MPS compatibility\")\n",
    "\n",
    "# Show which precision will be used\n",
    "if torch.cuda.is_available():\n",
    "    print(\"‚ö° Using FP16 precision for CUDA training\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    print(\"üçé Using FP32 precision for MPS training (safest option)\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Using FP32 precision for CPU training\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ Setting up model: Qwen/Qwen2.5-1.5B-Instruct\n",
      "üìÅ Output directory: ../models/qwen-ttp-classification-2025-08-08_14-15-00\n",
      "‚úÖ Training arguments configured (FIXED + MPS)\n",
      "üéØ Batch size: 4\n",
      "üìà Learning rate: 2e-05\n",
      "üîÑ Epochs: 3\n",
      "üî• FP16 (CUDA only): False\n",
      "üçé BF16 (Disabled): False\n",
      "üíæ Gradient checkpointing: True\n",
      "üîß FIXED: eval_strategy + MPS compatibility\n",
      "üçé Using FP32 precision for MPS training (safest option)\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 4. Prepare Training Data Format\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-08T07:19:22.047901Z",
     "start_time": "2025-08-08T07:15:00.992814Z"
    }
   },
   "source": [
    "def format_training_sample(sample: Dict[str, Any]) -> Dict[str, str]:\n",
    "    \"\"\"\n",
    "    Format training sample for instruction tuning\n",
    "    \"\"\"\n",
    "    instruction = sample['instruction']\n",
    "    technique = sample['output']['techniques'][0]\n",
    "    \n",
    "    # Create system prompt\n",
    "    system_prompt = \"\"\"You are a cybersecurity expert specializing in MITRE ATT&CK framework. Your task is to analyze threat intelligence descriptions and identify the corresponding MITRE ATT&CK techniques.\n",
    "\n",
    "Given a description of adversary behavior, identify the most relevant MITRE ATT&CK technique and provide:\n",
    "1. Technique ID (e.g., T1055.011)\n",
    "2. Technique Name\n",
    "3. Matrix (enterprise/mobile/ics)\n",
    "\n",
    "Respond in JSON format.\"\"\"\n",
    "    \n",
    "    # Create user input\n",
    "    user_input = f\"Analyze this threat behavior and identify the MITRE ATT&CK technique:\\n\\n{instruction}\"\n",
    "    \n",
    "    # Create assistant response\n",
    "    assistant_response = json.dumps({\n",
    "        \"technique_id\": technique['id'],\n",
    "        \"technique_name\": technique['name'],\n",
    "        \"matrix\": technique['matrix'],\n",
    "        \"description\": technique['description']\n",
    "    }, ensure_ascii=False)\n",
    "    \n",
    "    # Format for Qwen chat template\n",
    "    formatted_text = f\"\"\"<|im_start|>system\n",
    "{system_prompt}<|im_end|>\n",
    "<|im_start|>user\n",
    "{user_input}<|im_end|>\n",
    "<|im_start|>assistant\n",
    "{assistant_response}<|im_end|>\"\"\"\n",
    "    \n",
    "    return {\"text\": formatted_text}\n",
    "\n",
    "# Format all training samples\n",
    "print(\"üîÑ Formatting training data...\")\n",
    "formatted_samples = []\n",
    "for sample in tqdm(training_samples):\n",
    "    formatted_sample = format_training_sample(sample)\n",
    "    formatted_samples.append(formatted_sample)\n",
    "\n",
    "print(f\"‚úÖ Formatted {len(formatted_samples):,} training samples\")\n",
    "\n",
    "# Show formatted example\n",
    "print(\"\\nüìù Formatted Training Example:\")\n",
    "print(formatted_samples[0]['text'][:500] + \"...\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Formatting training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 921/921 [00:00<00:00, 72455.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Formatted 921 training samples\n",
      "\n",
      "üìù Formatted Training Example:\n",
      "<|im_start|>system\n",
      "You are a cybersecurity expert specializing in MITRE ATT&CK framework. Your task is to analyze threat intelligence descriptions and identify the corresponding MITRE ATT&CK techniques.\n",
      "\n",
      "Given a description of adversary behavior, identify the most relevant MITRE ATT&CK technique and provide:\n",
      "1. Technique ID (e.g., T1055.011)\n",
      "2. Technique Name\n",
      "3. Matrix (enterprise/mobile/ics)\n",
      "\n",
      "Respond in JSON format.<|im_end|>\n",
      "<|im_start|>user\n",
      "Analyze this threat behavior and identify the MITRE ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 5. Setup Qwen Model and Tokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-08T07:19:22.048637Z",
     "start_time": "2025-08-08T07:15:01.064027Z"
    }
   },
   "source": [
    "# Setup device with MPS support\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(f\"üîß Using device: CUDA\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "    print(f\"üîß Using device: MPS (Apple Silicon)\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(f\"üîß Using device: CPU\")\n",
    "\n",
    "print(f\"üì± Selected device: {device}\")\n",
    "\n",
    "# Load tokenizer\n",
    "print(\"üìù Loading tokenizer...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    trust_remote_code=True,\n",
    "    padding_side=\"right\"\n",
    ")\n",
    "\n",
    "# Add padding token if not exists\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    print(\"üîß Set pad_token = eos_token\")\n",
    "\n",
    "print(f\"‚úÖ Tokenizer loaded\")\n",
    "print(f\"üìä Vocab size: {len(tokenizer):,}\")\n",
    "\n",
    "# Load model with MPS support\n",
    "print(\"ü§ñ Loading model...\")\n",
    "\n",
    "# Set appropriate dtype based on device (FIXED for MPS)\n",
    "if torch.cuda.is_available():\n",
    "    torch_dtype = torch.float16  # FP16 for CUDA\n",
    "    device_map = \"auto\"\n",
    "elif torch.backends.mps.is_available():\n",
    "    torch_dtype = torch.float32  # FP32 for MPS (safest option)\n",
    "    device_map = None  # MPS doesn't support device_map=\"auto\"\n",
    "else:\n",
    "    torch_dtype = torch.float32  # FP32 for CPU\n",
    "    device_map = None\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    trust_remote_code=True,\n",
    "    torch_dtype=torch_dtype,\n",
    "    device_map=device_map,\n",
    "    low_cpu_mem_usage=True\n",
    ")\n",
    "\n",
    "# Move to MPS if needed (device_map=\"auto\" doesn't work with MPS)\n",
    "if torch.backends.mps.is_available() and not torch.cuda.is_available():\n",
    "    model = model.to(\"mps\")\n",
    "    print(\"üçé Model moved to MPS device\")\n",
    "\n",
    "print(f\"‚úÖ Model loaded\")\n",
    "print(f\"üìä Model parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "print(f\"üéØ Trainable parameters: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß Using device: MPS (Apple Silicon)\n",
      "üì± Selected device: mps\n",
      "üìù Loading tokenizer...\n",
      "‚úÖ Tokenizer loaded\n",
      "üìä Vocab size: 151,665\n",
      "ü§ñ Loading model...\n",
      "üçé Model moved to MPS device\n",
      "‚úÖ Model loaded\n",
      "üìä Model parameters: 1,543,714,304\n",
      "üéØ Trainable parameters: 1,543,714,304\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 6. Create Dataset and Start Training\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-08T07:19:22.052776Z",
     "start_time": "2025-08-08T07:15:12.694741Z"
    }
   },
   "source": [
    "# Create train/validation split and start training\n",
    "print(\"üìä Creating train/validation split...\")\n",
    "train_samples, val_samples = train_test_split(\n",
    "    formatted_samples, \n",
    "    test_size=0.1, \n",
    "    random_state=42,\n",
    "    stratify=[sample['text'].split('\"matrix\": \"')[1].split('\"')[0] for sample in formatted_samples]\n",
    ")\n",
    "\n",
    "print(f\"üìö Training samples: {len(train_samples):,}\")\n",
    "print(f\"üîç Validation samples: {len(val_samples):,}\")\n",
    "\n",
    "# Ready to train message\n",
    "print(\"‚úÖ Setup completed!\")\n",
    "print(\"üöÄ You can now run training by executing the trainer.train() command\")\n",
    "print(\"‚ö†Ô∏è  Note: eval_strategy parameter has been fixed in TrainingArguments\")\n",
    "print(\"üçé MPS (Apple Silicon) support added for Mac users\")\n",
    "\n",
    "# Device info summary\n",
    "if torch.cuda.is_available():\n",
    "    print(\"üéÆ Training will use CUDA GPU acceleration\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    print(\"üçé Training will use MPS (Apple Silicon) acceleration\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Training will use CPU (slower)\")\n",
    "\n",
    "# Memory management tip for MPS (UPDATED)\n",
    "if torch.backends.mps.is_available() and not torch.cuda.is_available():\n",
    "    print(\"\\nüí° MPS Tips (UPDATED):\")\n",
    "    print(\"   ‚Ä¢ Using FP32 precision (BF16 not supported in TrainingArguments)\")\n",
    "    print(\"   ‚Ä¢ Reduce batch size if you encounter memory issues\")\n",
    "    print(\"   ‚Ä¢ Use torch.mps.empty_cache() to clear memory\")\n",
    "    print(\"   ‚Ä¢ Training will be slower than FP16 but more stable\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Creating train/validation split...\n",
      "üìö Training samples: 828\n",
      "üîç Validation samples: 93\n",
      "‚úÖ Setup completed!\n",
      "üöÄ You can now run training by executing the trainer.train() command\n",
      "‚ö†Ô∏è  Note: eval_strategy parameter has been fixed in TrainingArguments\n",
      "üçé MPS (Apple Silicon) support added for Mac users\n",
      "üçé Training will use MPS (Apple Silicon) acceleration\n",
      "\n",
      "üí° MPS Tips (UPDATED):\n",
      "   ‚Ä¢ Using FP32 precision (BF16 not supported in TrainingArguments)\n",
      "   ‚Ä¢ Reduce batch size if you encounter memory issues\n",
      "   ‚Ä¢ Use torch.mps.empty_cache() to clear memory\n",
      "   ‚Ä¢ Training will be slower than FP16 but more stable\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 7. Training with MPS Support\n",
    "\n",
    "### üçé **MPS (Apple Silicon) Optimizations (FIXED):**\n",
    "\n",
    "- **FP32 precision** for MPS compatibility (BF16 not supported in TrainingArguments)\n",
    "- **Manual device placement** (device_map=\"auto\" not supported on MPS)\n",
    "- **Memory management** with `torch.mps.empty_cache()`\n",
    "- **Optimized batch size** for Apple Silicon memory constraints\n",
    "\n",
    "### üîß **Training Configuration (FIXED):**\n",
    "- **CUDA**: FP16 precision + device_map=\"auto\"\n",
    "- **MPS**: FP32 precision + manual device placement  \n",
    "- **CPU**: FP32 precision fallback\n",
    "\n",
    "### ‚ö†Ô∏è **MPS Limitations:**\n",
    "- BF16 not supported in HuggingFace TrainingArguments for MPS\n",
    "- Using FP32 for stability and compatibility\n",
    "- Slightly slower than FP16 but more reliable\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-08T07:19:22.053308Z",
     "start_time": "2025-08-08T07:15:12.719803Z"
    }
   },
   "source": [
    "# Optional: Start training (uncomment to run)\n",
    "# Uncomment the lines below to start training\n",
    "\n",
    "\"\"\"\n",
    "# Clear memory cache before training\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "elif torch.backends.mps.is_available():\n",
    "    torch.mps.empty_cache()\n",
    "\n",
    "# Create tokenizer function\n",
    "def tokenize_function(examples):\n",
    "    tokenized = tokenizer(\n",
    "        examples[\"text\"],\n",
    "        truncation=True,\n",
    "        padding=False,\n",
    "        max_length=MAX_LENGTH,\n",
    "        return_tensors=None\n",
    "    )\n",
    "    tokenized[\"labels\"] = tokenized[\"input_ids\"].copy()\n",
    "    return tokenized\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = Dataset.from_list(train_samples)\n",
    "val_dataset = Dataset.from_list(val_samples)\n",
    "\n",
    "# Tokenize\n",
    "train_dataset = train_dataset.map(tokenize_function, batched=True, remove_columns=[\"text\"])\n",
    "val_dataset = val_dataset.map(tokenize_function, batched=True, remove_columns=[\"text\"])\n",
    "\n",
    "# Data collator\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)\n",
    "\n",
    "# Initialize trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n",
    "# Start training\n",
    "print(\"üöÄ Starting training...\")\n",
    "training_result = trainer.train()\n",
    "\n",
    "print(\"üéâ Training completed!\")\n",
    "print(f\"üìä Final loss: {training_result.training_loss:.4f}\")\n",
    "\"\"\"\n",
    "\n",
    "print(\"üìù Training code is ready!\")\n",
    "print(\"üîì Uncomment the code above to start training\")\n",
    "print(\"‚ö° Optimized for MPS (Apple Silicon) and CUDA\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìù Training code is ready!\n",
      "üîì Uncomment the code above to start training\n",
      "‚ö° Optimized for MPS (Apple Silicon) and CUDA\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-08T07:19:22.053466Z",
     "start_time": "2025-08-08T07:15:12.733064Z"
    }
   },
   "source": [
    "# CORRECTED Training Arguments - Run this if you get TypeError\n",
    "print(\"üîß Creating CORRECTED training arguments...\")\n",
    "\n",
    "# Model configuration\n",
    "MODEL_NAME = \"Qwen/Qwen2.5-1.5B-Instruct\"\n",
    "MAX_LENGTH = 2048\n",
    "BATCH_SIZE = 4\n",
    "LEARNING_RATE = 2e-5\n",
    "NUM_EPOCHS = 3\n",
    "WARMUP_STEPS = 100\n",
    "\n",
    "# Create output directory\n",
    "timestamp = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "output_dir = f\"../models/qwen-ttp-classification-{timestamp}\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "print(f\"üìÅ Output directory: {output_dir}\")\n",
    "\n",
    "# CORRECTED Training arguments (eval_strategy NOT evaluation_strategy)\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    overwrite_output_dir=True,\n",
    "    \n",
    "    # Training parameters\n",
    "    num_train_epochs=NUM_EPOCHS,\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    per_device_eval_batch_size=BATCH_SIZE,\n",
    "    gradient_accumulation_steps=1,\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    weight_decay=0.01,\n",
    "    warmup_steps=WARMUP_STEPS,\n",
    "    \n",
    "    # Optimization (MPS compatible)\n",
    "    fp16=torch.cuda.is_available(),  # Only FP16 on CUDA\n",
    "    bf16=False,  # Disabled for MPS compatibility\n",
    "    dataloader_pin_memory=False,\n",
    "    gradient_checkpointing=True,\n",
    "    \n",
    "    # Logging and saving\n",
    "    logging_dir=f\"{output_dir}/logs\",\n",
    "    logging_steps=10,\n",
    "    save_steps=100,\n",
    "    save_total_limit=3,\n",
    "    eval_steps=100,\n",
    "    eval_strategy=\"steps\",  # CORRECT: eval_strategy (NOT evaluation_strategy)\n",
    "    \n",
    "    # Other settings\n",
    "    remove_unused_columns=False,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    "    greater_is_better=False,\n",
    "    \n",
    "    # Report\n",
    "    report_to=None,\n",
    "    run_name=f\"qwen-ttp-classification-{timestamp}\"\n",
    ")\n",
    "\n",
    "print(\"‚úÖ CORRECTED Training arguments configured!\")\n",
    "print(f\"üéØ Batch size: {BATCH_SIZE}\")\n",
    "print(f\"üìà Learning rate: {LEARNING_RATE}\")\n",
    "print(f\"üîÑ Epochs: {NUM_EPOCHS}\")\n",
    "print(f\"üî• FP16 (CUDA only): {training_args.fp16}\")\n",
    "print(f\"üçé BF16 (Disabled): {training_args.bf16}\")\n",
    "print(f\"üíæ Gradient checkpointing: {training_args.gradient_checkpointing}\")\n",
    "print(f\"‚úÖ FIXED: eval_strategy (NOT evaluation_strategy)\")\n",
    "\n",
    "# Show device-specific precision\n",
    "if torch.cuda.is_available():\n",
    "    print(\"‚ö° Using FP16 precision for CUDA training\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    print(\"üçé Using FP32 precision for MPS training\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Using FP32 precision for CPU training\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß Creating CORRECTED training arguments...\n",
      "üìÅ Output directory: ../models/qwen-ttp-classification-2025-08-08_14-15-12\n",
      "‚úÖ CORRECTED Training arguments configured!\n",
      "üéØ Batch size: 4\n",
      "üìà Learning rate: 2e-05\n",
      "üîÑ Epochs: 3\n",
      "üî• FP16 (CUDA only): False\n",
      "üçé BF16 (Disabled): False\n",
      "üíæ Gradient checkpointing: True\n",
      "‚úÖ FIXED: eval_strategy (NOT evaluation_strategy)\n",
      "üçé Using FP32 precision for MPS training\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# TTP Classification Training with Qwen Model\n",
    "\n",
    "## Overview\n",
    "This notebook implements TTP (Tactics, Techniques, and Procedures) classification training using Qwen model with MITRE ATT&CK framework.\n",
    "\n",
    "### Task Description\n",
    "- **Input**: Threat intelligence text descriptions\n",
    "- **Output**: MITRE ATT&CK technique classification (T1xxx format)\n",
    "- **Model**: Qwen/Qwen2.5-1.5B-Instruct (fine-tuned)\n",
    "\n",
    "### Dataset Statistics\n",
    "- **Total samples**: 921 training examples\n",
    "- **Enterprise Matrix**: 691 techniques (222 main + 469 sub-techniques)\n",
    "- **Mobile Matrix**: 135 techniques (89 main + 46 sub-techniques)\n",
    "- **ICS Matrix**: 95 techniques (95 main + 0 sub-techniques)\n",
    "\n",
    "### Key Steps\n",
    "1. Load and prepare MITRE ATT&CK training data\n",
    "2. Setup Qwen model for fine-tuning\n",
    "3. Create training and validation splits\n",
    "4. Fine-tune model for TTP classification\n",
    "5. Evaluate model performance\n",
    "6. Test on real threat intelligence data\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 1. Environment Setup and Dependencies\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-08T07:19:22.053575Z",
     "start_time": "2025-08-08T07:15:12.743215Z"
    }
   },
   "source": [
    "import json\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Any, Tuple\n",
    "import logging\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Transformers and training\n",
    "from transformers import (\n",
    "    AutoTokenizer, \n",
    "    AutoModelForCausalLM,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    DataCollatorForLanguageModeling\n",
    ")\n",
    "from datasets import Dataset, DatasetDict\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "print(\"üìö Dependencies loaded successfully!\")\n",
    "print(f\"üî• PyTorch version: {torch.__version__}\")\n",
    "print(f\"ü§ñ CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"üéÆ GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"üíæ GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìö Dependencies loaded successfully!\n",
      "üî• PyTorch version: 2.8.0\n",
      "ü§ñ CUDA available: False\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 2. Load MITRE ATT&CK Training Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-08T07:19:22.053684Z",
     "start_time": "2025-08-08T07:15:12.755115Z"
    }
   },
   "source": [
    "# Load merged MITRE ATT&CK dataset\n",
    "dataset_path = \"../data/TTP-classification/merged_mitre_attack_dataset.json\"\n",
    "\n",
    "print(\"üìÇ Loading MITRE ATT&CK dataset...\")\n",
    "with open(dataset_path, 'r', encoding='utf-8') as f:\n",
    "    mitre_data = json.load(f)\n",
    "\n",
    "# Extract training samples\n",
    "training_samples = mitre_data['dataset']\n",
    "print(f\"‚úÖ Loaded {len(training_samples):,} training samples\")\n",
    "\n",
    "# Analyze dataset structure\n",
    "print(\"\\nüìä Dataset Analysis:\")\n",
    "matrices = {'enterprise': 0, 'mobile': 0, 'ics': 0}\n",
    "techniques_count = 0\n",
    "sub_techniques_count = 0\n",
    "technique_ids = set()\n",
    "\n",
    "for sample in training_samples:\n",
    "    technique = sample['output']['techniques'][0]\n",
    "    matrix = technique['matrix']\n",
    "    technique_id = technique['id']\n",
    "    \n",
    "    matrices[matrix] += 1\n",
    "    technique_ids.add(technique_id)\n",
    "    \n",
    "    if '.' in technique_id:\n",
    "        sub_techniques_count += 1\n",
    "    else:\n",
    "        techniques_count += 1\n",
    "\n",
    "print(f\"  ‚Ä¢ Enterprise: {matrices['enterprise']:,} samples\")\n",
    "print(f\"  ‚Ä¢ Mobile: {matrices['mobile']:,} samples\")\n",
    "print(f\"  ‚Ä¢ ICS: {matrices['ics']:,} samples\")\n",
    "print(f\"  ‚Ä¢ Techniques: {techniques_count:,} samples\")\n",
    "print(f\"  ‚Ä¢ Sub-techniques: {sub_techniques_count:,} samples\")\n",
    "print(f\"  ‚Ä¢ Unique technique IDs: {len(technique_ids):,}\")\n",
    "\n",
    "# Show sample data\n",
    "print(\"\\nüìù Sample Training Example:\")\n",
    "sample = training_samples[0]\n",
    "print(f\"Instruction: {sample['instruction'][:100]}...\")\n",
    "print(f\"Technique ID: {sample['output']['techniques'][0]['id']}\")\n",
    "print(f\"Technique Name: {sample['output']['techniques'][0]['name']}\")\n",
    "print(f\"Matrix: {sample['output']['techniques'][0]['matrix']}\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Loading MITRE ATT&CK dataset...\n",
      "‚úÖ Loaded 921 training samples\n",
      "\n",
      "üìä Dataset Analysis:\n",
      "  ‚Ä¢ Enterprise: 691 samples\n",
      "  ‚Ä¢ Mobile: 135 samples\n",
      "  ‚Ä¢ ICS: 95 samples\n",
      "  ‚Ä¢ Techniques: 406 samples\n",
      "  ‚Ä¢ Sub-techniques: 515 samples\n",
      "  ‚Ä¢ Unique technique IDs: 921\n",
      "\n",
      "üìù Sample Training Example:\n",
      "Instruction: Adversaries may inject malicious code into process via Extra Window Memory (EWM) in order to evade p...\n",
      "Technique ID: T1055.011\n",
      "Technique Name: Extra Window Memory Injection\n",
      "Matrix: enterprise\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 3. Prepare Training Data Format\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-08T07:19:22.053770Z",
     "start_time": "2025-08-08T07:15:12.780138Z"
    }
   },
   "source": [
    "def format_training_sample(sample: Dict[str, Any]) -> Dict[str, str]:\n",
    "    \"\"\"\n",
    "    Format training sample for instruction tuning\n",
    "    \n",
    "    Input format:\n",
    "    {\n",
    "        \"instruction\": \"Adversary behavior description...\",\n",
    "        \"output\": {\n",
    "            \"techniques\": [{\n",
    "                \"id\": \"T1055.011\",\n",
    "                \"name\": \"Extra Window Memory Injection\",\n",
    "                \"description\": \"...\",\n",
    "                \"matrix\": \"enterprise\"\n",
    "            }]\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    Output format for instruction tuning:\n",
    "    {\n",
    "        \"text\": \"<|im_start|>system\\nYou are a cybersecurity expert...\\n<|im_end|>\\n<|im_start|>user\\n...\\n<|im_end|>\\n<|im_start|>assistant\\n...\\n<|im_end|>\"\n",
    "    }\n",
    "    \"\"\"\n",
    "    instruction = sample['instruction']\n",
    "    technique = sample['output']['techniques'][0]\n",
    "    \n",
    "    # Create system prompt\n",
    "    system_prompt = \"\"\"You are a cybersecurity expert specializing in MITRE ATT&CK framework. Your task is to analyze threat intelligence descriptions and identify the corresponding MITRE ATT&CK techniques.\n",
    "\n",
    "Given a description of adversary behavior, identify the most relevant MITRE ATT&CK technique and provide:\n",
    "1. Technique ID (e.g., T1055.011)\n",
    "2. Technique Name\n",
    "3. Matrix (enterprise/mobile/ics)\n",
    "\n",
    "Respond in JSON format.\"\"\"\n",
    "    \n",
    "    # Create user input\n",
    "    user_input = f\"Analyze this threat behavior and identify the MITRE ATT&CK technique:\\n\\n{instruction}\"\n",
    "    \n",
    "    # Create assistant response\n",
    "    assistant_response = json.dumps({\n",
    "        \"technique_id\": technique['id'],\n",
    "        \"technique_name\": technique['name'],\n",
    "        \"matrix\": technique['matrix'],\n",
    "        \"description\": technique['description']\n",
    "    }, ensure_ascii=False)\n",
    "    \n",
    "    # Format for Qwen chat template\n",
    "    formatted_text = f\"\"\"<|im_start|>system\n",
    "{system_prompt}<|im_end|>\n",
    "<|im_start|>user\n",
    "{user_input}<|im_end|>\n",
    "<|im_start|>assistant\n",
    "{assistant_response}<|im_end|>\"\"\"\n",
    "    \n",
    "    return {\"text\": formatted_text}\n",
    "\n",
    "# Format all training samples\n",
    "print(\"üîÑ Formatting training data...\")\n",
    "formatted_samples = []\n",
    "for sample in tqdm(training_samples):\n",
    "    formatted_sample = format_training_sample(sample)\n",
    "    formatted_samples.append(formatted_sample)\n",
    "\n",
    "print(f\"‚úÖ Formatted {len(formatted_samples):,} training samples\")\n",
    "\n",
    "# Show formatted example\n",
    "print(\"\\nüìù Formatted Training Example:\")\n",
    "print(formatted_samples[0]['text'][:500] + \"...\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Formatting training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 921/921 [00:00<00:00, 219598.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Formatted 921 training samples\n",
      "\n",
      "üìù Formatted Training Example:\n",
      "<|im_start|>system\n",
      "You are a cybersecurity expert specializing in MITRE ATT&CK framework. Your task is to analyze threat intelligence descriptions and identify the corresponding MITRE ATT&CK techniques.\n",
      "\n",
      "Given a description of adversary behavior, identify the most relevant MITRE ATT&CK technique and provide:\n",
      "1. Technique ID (e.g., T1055.011)\n",
      "2. Technique Name\n",
      "3. Matrix (enterprise/mobile/ics)\n",
      "\n",
      "Respond in JSON format.<|im_end|>\n",
      "<|im_start|>user\n",
      "Analyze this threat behavior and identify the MITRE ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 4. Setup Qwen Model and Tokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-08T07:19:22.053897Z",
     "start_time": "2025-08-08T07:15:12.794515Z"
    }
   },
   "source": [
    "# Model configuration\n",
    "MODEL_NAME = \"Qwen/Qwen2.5-1.5B-Instruct\"\n",
    "MAX_LENGTH = 2048\n",
    "BATCH_SIZE = 4\n",
    "LEARNING_RATE = 2e-5\n",
    "NUM_EPOCHS = 3\n",
    "WARMUP_STEPS = 100\n",
    "\n",
    "print(f\"ü§ñ Setting up model: {MODEL_NAME}\")\n",
    "\n",
    "# Setup device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"üîß Using device: {device}\")\n",
    "\n",
    "# Load tokenizer\n",
    "print(\"üìù Loading tokenizer...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    trust_remote_code=True,\n",
    "    padding_side=\"right\"\n",
    ")\n",
    "\n",
    "# Add padding token if not exists\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    print(\"üîß Set pad_token = eos_token\")\n",
    "\n",
    "print(f\"‚úÖ Tokenizer loaded\")\n",
    "print(f\"üìä Vocab size: {len(tokenizer):,}\")\n",
    "print(f\"üîë Special tokens: {tokenizer.special_tokens_map}\")\n",
    "\n",
    "# Load model\n",
    "print(\"ü§ñ Loading model...\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    trust_remote_code=True,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\",\n",
    "    low_cpu_mem_usage=True\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Model loaded\")\n",
    "print(f\"üìä Model parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "print(f\"üéØ Trainable parameters: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ Setting up model: Qwen/Qwen2.5-1.5B-Instruct\n",
      "üîß Using device: cpu\n",
      "üìù Loading tokenizer...\n",
      "‚úÖ Tokenizer loaded\n",
      "üìä Vocab size: 151,665\n",
      "üîë Special tokens: {'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}\n",
      "ü§ñ Loading model...\n",
      "‚úÖ Model loaded\n",
      "üìä Model parameters: 1,543,714,304\n",
      "üéØ Trainable parameters: 1,543,714,304\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 5. Create Dataset and Data Loaders\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-08T07:19:22.054007Z",
     "start_time": "2025-08-08T07:15:20.002698Z"
    }
   },
   "source": [
    "def tokenize_function(examples):\n",
    "    \"\"\"\n",
    "    Tokenize training examples\n",
    "    \"\"\"\n",
    "    # Tokenize the text\n",
    "    tokenized = tokenizer(\n",
    "        examples[\"text\"],\n",
    "        truncation=True,\n",
    "        padding=False,\n",
    "        max_length=MAX_LENGTH,\n",
    "        return_tensors=None\n",
    "    )\n",
    "    \n",
    "    # For causal language modeling, labels are the same as input_ids\n",
    "    tokenized[\"labels\"] = tokenized[\"input_ids\"].copy()\n",
    "    \n",
    "    return tokenized\n",
    "\n",
    "# Create train/validation split\n",
    "print(\"üìä Creating train/validation split...\")\n",
    "train_samples, val_samples = train_test_split(\n",
    "    formatted_samples, \n",
    "    test_size=0.1, \n",
    "    random_state=42,\n",
    "    stratify=[sample['text'].split('\"matrix\": \"')[1].split('\"')[0] for sample in formatted_samples]\n",
    ")\n",
    "\n",
    "print(f\"üìö Training samples: {len(train_samples):,}\")\n",
    "print(f\"üîç Validation samples: {len(val_samples):,}\")\n",
    "\n",
    "# Create HuggingFace datasets\n",
    "print(\"üîÑ Creating datasets...\")\n",
    "train_dataset = Dataset.from_list(train_samples)\n",
    "val_dataset = Dataset.from_list(val_samples)\n",
    "\n",
    "# Tokenize datasets\n",
    "print(\"üî§ Tokenizing datasets...\")\n",
    "train_dataset = train_dataset.map(\n",
    "    tokenize_function,\n",
    "    batched=True,\n",
    "    remove_columns=[\"text\"],\n",
    "    desc=\"Tokenizing train data\"\n",
    ")\n",
    "\n",
    "val_dataset = val_dataset.map(\n",
    "    tokenize_function,\n",
    "    batched=True,\n",
    "    remove_columns=[\"text\"],\n",
    "    desc=\"Tokenizing validation data\"\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Datasets prepared\")\n",
    "print(f\"üìä Train dataset: {len(train_dataset):,} samples\")\n",
    "print(f\"üìä Validation dataset: {len(val_dataset):,} samples\")\n",
    "\n",
    "# Check tokenization\n",
    "sample_tokens = train_dataset[0]\n",
    "print(f\"\\nüìù Sample tokenization:\")\n",
    "print(f\"Input IDs length: {len(sample_tokens['input_ids'])}\")\n",
    "print(f\"Attention mask length: {len(sample_tokens['attention_mask'])}\")\n",
    "print(f\"Labels length: {len(sample_tokens['labels'])}\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Creating train/validation split...\n",
      "üìö Training samples: 828\n",
      "üîç Validation samples: 93\n",
      "üîÑ Creating datasets...\n",
      "üî§ Tokenizing datasets...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Tokenizing train data:   0%|          | 0/828 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b66895436fdd4c1ba31576c1dc07cf55"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Tokenizing validation data:   0%|          | 0/93 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6e719e15a69746c0934bab02d432d9ac"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Datasets prepared\n",
      "üìä Train dataset: 828 samples\n",
      "üìä Validation dataset: 93 samples\n",
      "\n",
      "üìù Sample tokenization:\n",
      "Input IDs length: 368\n",
      "Attention mask length: 368\n",
      "Labels length: 368\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 6. Setup Training Configuration\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-08T07:19:22.054188Z",
     "start_time": "2025-08-08T07:15:20.288954Z"
    }
   },
   "source": [
    "# Create output directory\n",
    "timestamp = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "output_dir = f\"../models/qwen-ttp-classification-{timestamp}\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "print(f\"üìÅ Output directory: {output_dir}\")\n",
    "\n",
    "# Training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    overwrite_output_dir=True,\n",
    "    \n",
    "    # Training parameters\n",
    "    num_train_epochs=NUM_EPOCHS,\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    per_device_eval_batch_size=BATCH_SIZE,\n",
    "    gradient_accumulation_steps=1,\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    weight_decay=0.01,\n",
    "    warmup_steps=WARMUP_STEPS,\n",
    "    \n",
    "    # Optimization\n",
    "    fp16=True,\n",
    "    dataloader_pin_memory=False,\n",
    "    gradient_checkpointing=True,\n",
    "    \n",
    "    # Logging and saving\n",
    "    logging_dir=f\"{output_dir}/logs\",\n",
    "    logging_steps=10,\n",
    "    save_steps=100,\n",
    "    save_total_limit=3,\n",
    "    eval_steps=100,\n",
    "    eval_strategy=\"steps\",  # FIXED: was evaluation_strategy\n",
    "\n",
    "    # Other settings\n",
    "    remove_unused_columns=False,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    "    greater_is_better=False,\n",
    "    \n",
    "    # Report\n",
    "    report_to=None,  # Disable wandb/tensorboard\n",
    "    run_name=f\"qwen-ttp-classification-{timestamp}\"\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Training arguments configured\")\n",
    "print(f\"üéØ Batch size: {BATCH_SIZE}\")\n",
    "print(f\"üìà Learning rate: {LEARNING_RATE}\")\n",
    "print(f\"üîÑ Epochs: {NUM_EPOCHS}\")\n",
    "print(f\"üî• FP16: {training_args.fp16}\")\n",
    "print(f\"üíæ Gradient checkpointing: {training_args.gradient_checkpointing}\")\n",
    "\n",
    "# Data collator\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer,\n",
    "    mlm=False,  # No masking for causal LM\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Data collator configured\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÅ Output directory: ../models/qwen-ttp-classification-2025-08-08_14-15-20\n",
      "‚úÖ Training arguments configured\n",
      "üéØ Batch size: 4\n",
      "üìà Learning rate: 2e-05\n",
      "üîÑ Epochs: 3\n",
      "üî• FP16: True\n",
      "üíæ Gradient checkpointing: True\n",
      "‚úÖ Data collator configured\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 7. Initialize Trainer and Start Training\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-08T07:19:22.054294Z",
     "start_time": "2025-08-08T07:15:20.307348Z"
    }
   },
   "source": [
    "# Initialize trainer\n",
    "print(\"üèÉ‚Äç‚ôÇÔ∏è Initializing trainer...\")\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Trainer initialized\")\n",
    "\n",
    "# Start training\n",
    "print(\"\\nüöÄ Starting training...\")\n",
    "print(f\"üìä Total training samples: {len(train_dataset):,}\")\n",
    "print(f\"üìä Total validation samples: {len(val_dataset):,}\")\n",
    "print(f\"‚è±Ô∏è Estimated training time: ~{(len(train_dataset) // BATCH_SIZE) * NUM_EPOCHS // 60} minutes\")\n",
    "\n",
    "# Clear cache before training\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "# Train the model\n",
    "training_result = trainer.train()\n",
    "\n",
    "print(\"\\nüéâ Training completed!\")\n",
    "print(f\"üìä Final training loss: {training_result.training_loss:.4f}\")\n",
    "print(f\"‚è±Ô∏è Training time: {training_result.training_time:.2f} seconds\")\n",
    "\n",
    "# Save the final model\n",
    "print(\"üíæ Saving final model...\")\n",
    "trainer.save_model()\n",
    "tokenizer.save_pretrained(output_dir)\n",
    "\n",
    "print(f\"‚úÖ Model saved to: {output_dir}\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ‚Äç‚ôÇÔ∏è Initializing trainer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/lt/y_3sh6vn2mb68907rlw4xvww0000gn/T/ipykernel_11776/2074198674.py:3: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "fp16 mixed precision requires a GPU (not 'mps').",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[15], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# Initialize trainer\u001B[39;00m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124müèÉ‚Äç‚ôÇÔ∏è Initializing trainer...\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m----> 3\u001B[0m trainer \u001B[38;5;241m=\u001B[39m \u001B[43mTrainer\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m      4\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      5\u001B[0m \u001B[43m    \u001B[49m\u001B[43margs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtraining_args\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      6\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtrain_dataset\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrain_dataset\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      7\u001B[0m \u001B[43m    \u001B[49m\u001B[43meval_dataset\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mval_dataset\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      8\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtokenizer\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtokenizer\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      9\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdata_collator\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdata_collator\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     10\u001B[0m \u001B[43m)\u001B[49m\n\u001B[1;32m     12\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m‚úÖ Trainer initialized\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     14\u001B[0m \u001B[38;5;66;03m# Start training\u001B[39;00m\n",
      "File \u001B[0;32m~/Documents/UIT/2nd/NLP/LLM-TKIG/.venv/lib/python3.12/site-packages/transformers/utils/deprecation.py:172\u001B[0m, in \u001B[0;36mdeprecate_kwarg.<locals>.wrapper.<locals>.wrapped_func\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    168\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m minimum_action \u001B[38;5;129;01min\u001B[39;00m (Action\u001B[38;5;241m.\u001B[39mNOTIFY, Action\u001B[38;5;241m.\u001B[39mNOTIFY_ALWAYS) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_torchdynamo_compiling():\n\u001B[1;32m    169\u001B[0m     \u001B[38;5;66;03m# DeprecationWarning is ignored by default, so we use FutureWarning instead\u001B[39;00m\n\u001B[1;32m    170\u001B[0m     warnings\u001B[38;5;241m.\u001B[39mwarn(message, \u001B[38;5;167;01mFutureWarning\u001B[39;00m, stacklevel\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m)\n\u001B[0;32m--> 172\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/UIT/2nd/NLP/LLM-TKIG/.venv/lib/python3.12/site-packages/transformers/trainer.py:465\u001B[0m, in \u001B[0;36mTrainer.__init__\u001B[0;34m(self, model, args, data_collator, train_dataset, eval_dataset, processing_class, model_init, compute_loss_func, compute_metrics, callbacks, optimizers, optimizer_cls_and_kwargs, preprocess_logits_for_metrics)\u001B[0m\n\u001B[1;32m    463\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mis_in_train \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[1;32m    464\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel \u001B[38;5;241m=\u001B[39m model\n\u001B[0;32m--> 465\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcreate_accelerator_and_postprocess\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    467\u001B[0m \u001B[38;5;66;03m# memory metrics - must set up as early as possible\u001B[39;00m\n\u001B[1;32m    468\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_memory_tracker \u001B[38;5;241m=\u001B[39m TrainerMemoryTracker(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs\u001B[38;5;241m.\u001B[39mskip_memory_metrics)\n",
      "File \u001B[0;32m~/Documents/UIT/2nd/NLP/LLM-TKIG/.venv/lib/python3.12/site-packages/transformers/trainer.py:5208\u001B[0m, in \u001B[0;36mTrainer.create_accelerator_and_postprocess\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   5205\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mRequires accelerate>1.3.0 to use Tensor Parallelism.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m   5207\u001B[0m \u001B[38;5;66;03m# create accelerator object\u001B[39;00m\n\u001B[0;32m-> 5208\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39maccelerator \u001B[38;5;241m=\u001B[39m \u001B[43mAccelerator\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   5209\u001B[0m \u001B[38;5;66;03m# some Trainer classes need to use `gather` instead of `gather_for_metrics`, thus we store a flag\u001B[39;00m\n\u001B[1;32m   5210\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgather_function \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39maccelerator\u001B[38;5;241m.\u001B[39mgather_for_metrics\n",
      "File \u001B[0;32m~/Documents/UIT/2nd/NLP/LLM-TKIG/.venv/lib/python3.12/site-packages/accelerate/accelerator.py:567\u001B[0m, in \u001B[0;36mAccelerator.__init__\u001B[0;34m(self, device_placement, split_batches, mixed_precision, gradient_accumulation_steps, cpu, dataloader_config, deepspeed_plugin, fsdp_plugin, torch_tp_plugin, megatron_lm_plugin, rng_types, log_with, project_dir, project_config, gradient_accumulation_plugin, step_scheduler_with_optimizer, kwargs_handlers, dynamo_backend, dynamo_plugin, deepspeed_plugins)\u001B[0m\n\u001B[1;32m    556\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnative_amp \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m    557\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdevice\u001B[38;5;241m.\u001B[39mtype \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m (\n\u001B[1;32m    558\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mxpu\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    559\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcuda\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    565\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msdaa\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    566\u001B[0m ) \u001B[38;5;129;01mor\u001B[39;00m is_torch_xla_available(check_is_tpu\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m):\n\u001B[0;32m--> 567\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfp16 mixed precision requires a GPU (not \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdevice\u001B[38;5;241m.\u001B[39mtype\u001B[38;5;132;01m!r}\u001B[39;00m\u001B[38;5;124m).\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    568\u001B[0m kwargs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mscaler_handler\u001B[38;5;241m.\u001B[39mto_kwargs() \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mscaler_handler \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m {}\n\u001B[1;32m    570\u001B[0m \u001B[38;5;66;03m# FSDP2 doesn't use ShardedGradScaler, don't want to modify `get_grad_scaler`, rather create a simple utility\u001B[39;00m\n",
      "\u001B[0;31mValueError\u001B[0m: fp16 mixed precision requires a GPU (not 'mps')."
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 8. Model Evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "print(\"üìä Evaluating model...\")\n",
    "eval_result = trainer.evaluate()\n",
    "\n",
    "print(\"\\nüìà Evaluation Results:\")\n",
    "for key, value in eval_result.items():\n",
    "    print(f\"  {key}: {value:.4f}\")\n",
    "\n",
    "# Save evaluation results\n",
    "eval_file = os.path.join(output_dir, \"evaluation_results.json\")\n",
    "with open(eval_file, 'w') as f:\n",
    "    json.dump(eval_result, f, indent=2)\n",
    "\n",
    "print(f\"‚úÖ Evaluation results saved to: {eval_file}\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 9. Test Model Inference\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_ttp_classification(model, tokenizer, threat_description: str) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Test TTP classification on a threat description\n",
    "    \"\"\"\n",
    "    system_prompt = \"\"\"You are a cybersecurity expert specializing in MITRE ATT&CK framework. Your task is to analyze threat intelligence descriptions and identify the corresponding MITRE ATT&CK techniques.\n",
    "\n",
    "Given a description of adversary behavior, identify the most relevant MITRE ATT&CK technique and provide:\n",
    "1. Technique ID (e.g., T1055.011)\n",
    "2. Technique Name\n",
    "3. Matrix (enterprise/mobile/ics)\n",
    "\n",
    "Respond in JSON format.\"\"\"\n",
    "    \n",
    "    user_input = f\"Analyze this threat behavior and identify the MITRE ATT&CK technique:\\n\\n{threat_description}\"\n",
    "    \n",
    "    # Format input\n",
    "    prompt = f\"\"\"<|im_start|>system\n",
    "{system_prompt}<|im_end|>\n",
    "<|im_start|>user\n",
    "{user_input}<|im_end|>\n",
    "<|im_start|>assistant\n",
    "\"\"\"\n",
    "    \n",
    "    # Tokenize\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=1024)\n",
    "    inputs = {k: v.to(model.device) for k, v in inputs.items()}\n",
    "    \n",
    "    # Generate response\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=256,\n",
    "            temperature=0.1,\n",
    "            do_sample=True,\n",
    "            pad_token_id=tokenizer.eos_token_id\n",
    "        )\n",
    "    \n",
    "    # Decode response\n",
    "    full_response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    assistant_response = full_response.split(\"<|im_start|>assistant\\n\")[-1]\n",
    "    \n",
    "    return {\n",
    "        \"input\": threat_description,\n",
    "        \"response\": assistant_response,\n",
    "        \"full_prompt\": prompt\n",
    "    }\n",
    "\n",
    "# Test examples\n",
    "test_cases = [\n",
    "    \"Adversaries may inject malicious code into processes in order to evade process-based defenses or elevate privileges.\",\n",
    "    \"Attackers send phishing emails with malicious attachments to gain initial access to the target system.\",\n",
    "    \"The malware establishes persistence by creating scheduled tasks that execute at system startup.\",\n",
    "    \"Adversaries may abuse elevation control mechanisms to gain higher-level permissions on a system.\"\n",
    "]\n",
    "\n",
    "print(\"üß™ Testing model inference...\")\n",
    "for i, test_case in enumerate(test_cases, 1):\n",
    "    print(f\"\\nüìù Test Case {i}:\")\n",
    "    print(f\"Input: {test_case}\")\n",
    "    \n",
    "    result = test_ttp_classification(model, tokenizer, test_case)\n",
    "    print(f\"Output: {result['response']}\")\n",
    "    print(\"-\" * 80)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 10. Save Training Summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training summary\n",
    "training_summary = {\n",
    "    \"model_name\": MODEL_NAME,\n",
    "    \"training_timestamp\": timestamp,\n",
    "    \"output_directory\": output_dir,\n",
    "    \"dataset_info\": {\n",
    "        \"total_samples\": len(training_samples),\n",
    "        \"train_samples\": len(train_dataset),\n",
    "        \"val_samples\": len(val_dataset),\n",
    "        \"unique_techniques\": len(technique_ids),\n",
    "        \"matrix_distribution\": matrices\n",
    "    },\n",
    "    \"training_config\": {\n",
    "        \"batch_size\": BATCH_SIZE,\n",
    "        \"learning_rate\": LEARNING_RATE,\n",
    "        \"num_epochs\": NUM_EPOCHS,\n",
    "        \"max_length\": MAX_LENGTH,\n",
    "        \"warmup_steps\": WARMUP_STEPS\n",
    "    },\n",
    "    \"training_results\": {\n",
    "        \"final_loss\": training_result.training_loss,\n",
    "        \"training_time_seconds\": training_result.training_time\n",
    "    },\n",
    "    \"evaluation_results\": eval_result\n",
    "}\n",
    "\n",
    "# Save summary\n",
    "summary_file = os.path.join(output_dir, \"training_summary.json\")\n",
    "with open(summary_file, 'w', encoding='utf-8') as f:\n",
    "    json.dump(training_summary, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"üìÑ Training summary saved to: {summary_file}\")\n",
    "\n",
    "# Display summary\n",
    "print(\"\\nüìä Training Summary:\")\n",
    "print(f\"  Model: {MODEL_NAME}\")\n",
    "print(f\"  Training samples: {len(train_dataset):,}\")\n",
    "print(f\"  Validation samples: {len(val_dataset):,}\")\n",
    "print(f\"  Unique techniques: {len(technique_ids):,}\")\n",
    "print(f\"  Final training loss: {training_result.training_loss:.4f}\")\n",
    "print(f\"  Final validation loss: {eval_result['eval_loss']:.4f}\")\n",
    "print(f\"  Training time: {training_result.training_time:.1f} seconds\")\n",
    "print(f\"  Model saved to: {output_dir}\")\n",
    "\n",
    "print(\"\\nüéâ TTP Classification training completed successfully!\")\n",
    "print(f\"üìÅ All artifacts saved to: {output_dir}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
