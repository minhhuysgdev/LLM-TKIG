{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# TTP Classification Training with Qwen Model\n",
    "\n",
    "## Overview\n",
    "This notebook implements TTP (Tactics, Techniques, and Procedures) classification training using Qwen model with MITRE ATT&CK framework.\n",
    "\n",
    "### Task Description\n",
    "- **Input**: Threat intelligence text descriptions\n",
    "- **Output**: MITRE ATT&CK technique classification (T1xxx format)\n",
    "- **Model**: Qwen/Qwen2.5-1.5B-Instruct (fine-tuned)\n",
    "\n",
    "### Dataset Statistics\n",
    "- **Total samples**: 921 training examples\n",
    "- **Enterprise Matrix**: 691 techniques (222 main + 469 sub-techniques)\n",
    "- **Mobile Matrix**: 135 techniques (89 main + 46 sub-techniques)\n",
    "- **ICS Matrix**: 95 techniques (95 main + 0 sub-techniques)\n",
    "\n",
    "### Key Steps\n",
    "1. Load and prepare MITRE ATT&CK training data\n",
    "2. Setup Qwen model for fine-tuning\n",
    "3. Create training and validation splits\n",
    "4. Fine-tune model for TTP classification\n",
    "5. Evaluate model performance\n",
    "6. Test on real threat intelligence data\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## 1. Environment Setup and Dependencies\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-23T14:48:31.972098Z",
     "start_time": "2025-08-23T14:48:31.964179Z"
    }
   },
   "source": [
    "import json\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Any, Tuple\n",
    "import logging\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Transformers and training\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForCausalLM,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    DataCollatorForLanguageModeling\n",
    ")\n",
    "from datasets import Dataset, DatasetDict\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "print(\"üìö Dependencies loaded successfully!\")\n",
    "print(f\"üî• PyTorch version: {torch.__version__}\")\n",
    "print(f\"ü§ñ CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"üéÆ GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"üíæ GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìö Dependencies loaded successfully!\n",
      "üî• PyTorch version: 2.8.0\n",
      "ü§ñ CUDA available: False\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## 2. Load MITRE ATT&CK Training Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-23T14:48:31.990390Z",
     "start_time": "2025-08-23T14:48:31.980046Z"
    }
   },
   "source": [
    "# Load merged MITRE ATT&CK dataset\n",
    "dataset_path = \"../data/TTP-classification/merged_mitre_attack_dataset.json\"\n",
    "\n",
    "print(\"üìÇ Loading MITRE ATT&CK dataset...\")\n",
    "with open(dataset_path, 'r', encoding='utf-8') as f:\n",
    "    mitre_data = json.load(f)\n",
    "\n",
    "# Extract training samples\n",
    "training_samples = mitre_data['dataset']\n",
    "print(f\"‚úÖ Loaded {len(training_samples):,} training samples\")\n",
    "\n",
    "# Analyze dataset structure\n",
    "print(\"\\nüìä Dataset Analysis:\")\n",
    "matrices = {'enterprise': 0, 'mobile': 0, 'ics': 0}\n",
    "techniques_count = 0\n",
    "sub_techniques_count = 0\n",
    "technique_ids = set()\n",
    "\n",
    "for sample in training_samples:\n",
    "    technique = sample['output']['techniques'][0]\n",
    "    matrix = technique['matrix']\n",
    "    technique_id = technique['id']\n",
    "\n",
    "    matrices[matrix] += 1\n",
    "    technique_ids.add(technique_id)\n",
    "\n",
    "    if '.' in technique_id:\n",
    "        sub_techniques_count += 1\n",
    "    else:\n",
    "        techniques_count += 1\n",
    "\n",
    "print(f\"  ‚Ä¢ Enterprise: {matrices['enterprise']:,} samples\")\n",
    "print(f\"  ‚Ä¢ Mobile: {matrices['mobile']:,} samples\")\n",
    "print(f\"  ‚Ä¢ ICS: {matrices['ics']:,} samples\")\n",
    "print(f\"  ‚Ä¢ Techniques: {techniques_count:,} samples\")\n",
    "print(f\"  ‚Ä¢ Sub-techniques: {sub_techniques_count:,} samples\")\n",
    "print(f\"  ‚Ä¢ Unique technique IDs: {len(technique_ids):,}\")\n",
    "\n",
    "# Show sample data\n",
    "print(\"\\nüìù Sample Training Example:\")\n",
    "sample = training_samples[0]\n",
    "print(f\"Instruction: {sample['instruction'][:100]}...\")\n",
    "print(f\"Technique ID: {sample['output']['techniques'][0]['id']}\")\n",
    "print(f\"Technique Name: {sample['output']['techniques'][0]['name']}\")\n",
    "print(f\"Matrix: {sample['output']['techniques'][0]['matrix']}\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Loading MITRE ATT&CK dataset...\n",
      "‚úÖ Loaded 921 training samples\n",
      "\n",
      "üìä Dataset Analysis:\n",
      "  ‚Ä¢ Enterprise: 691 samples\n",
      "  ‚Ä¢ Mobile: 135 samples\n",
      "  ‚Ä¢ ICS: 95 samples\n",
      "  ‚Ä¢ Techniques: 406 samples\n",
      "  ‚Ä¢ Sub-techniques: 515 samples\n",
      "  ‚Ä¢ Unique technique IDs: 921\n",
      "\n",
      "üìù Sample Training Example:\n",
      "Instruction: Adversaries may inject malicious code into process via Extra Window Memory (EWM) in order to evade p...\n",
      "Technique ID: T1055.011\n",
      "Technique Name: Extra Window Memory Injection\n",
      "Matrix: enterprise\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## 3. Prepare Training Data Format\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-23T14:48:32.013542Z",
     "start_time": "2025-08-23T14:48:32.003727Z"
    }
   },
   "source": [
    "def format_training_sample(sample: Dict[str, Any]) -> Dict[str, str]:\n",
    "    \"\"\"\n",
    "    Format training sample for instruction tuning\n",
    "\n",
    "    Input format:\n",
    "    {\n",
    "        \"instruction\": \"Adversary behavior description...\",\n",
    "        \"output\": {\n",
    "            \"techniques\": [{\n",
    "                \"id\": \"T1055.011\",\n",
    "                \"name\": \"Extra Window Memory Injection\",\n",
    "                \"description\": \"...\",\n",
    "                \"matrix\": \"enterprise\"\n",
    "            }]\n",
    "        }\n",
    "    }\n",
    "\n",
    "    Output format for instruction tuning:\n",
    "    {\n",
    "        \"text\": \"<|im_start|>system\\nYou are a cybersecurity expert...\\n<|im_end|>\\n<|im_start|>user\\n...\\n<|im_end|>\\n<|im_start|>assistant\\n...\\n<|im_end|>\"\n",
    "    }\n",
    "    \"\"\"\n",
    "    instruction = sample['instruction']\n",
    "    technique = sample['output']['techniques'][0]\n",
    "\n",
    "    # Create system prompt\n",
    "    system_prompt = \"\"\"You are a cybersecurity expert specializing in MITRE ATT&CK framework. Your task is to analyze threat intelligence descriptions and identify the corresponding MITRE ATT&CK techniques.\n",
    "\n",
    "Given a description of adversary behavior, identify the most relevant MITRE ATT&CK technique and provide:\n",
    "1. Technique ID (e.g., T1055.011)\n",
    "2. Technique Name\n",
    "3. Matrix (enterprise/mobile/ics)\n",
    "\n",
    "Respond in JSON format.\"\"\"\n",
    "\n",
    "    # Create user input\n",
    "    user_input = f\"Analyze this threat behavior and identify the MITRE ATT&CK technique:\\n\\n{instruction}\"\n",
    "\n",
    "    # Create assistant response\n",
    "    assistant_response = json.dumps({\n",
    "        \"technique_id\": technique['id'],\n",
    "        \"technique_name\": technique['name'],\n",
    "        \"matrix\": technique['matrix'],\n",
    "        \"description\": technique['description']\n",
    "    }, ensure_ascii=False)\n",
    "\n",
    "    # Format for Qwen chat template\n",
    "    formatted_text = f\"\"\"<|im_start|>system\n",
    "{system_prompt}<|im_end|>\n",
    "<|im_start|>user\n",
    "{user_input}<|im_end|>\n",
    "<|im_start|>assistant\n",
    "{assistant_response}<|im_end|>\"\"\"\n",
    "\n",
    "    return {\"text\": formatted_text}\n",
    "\n",
    "# Format all training samples\n",
    "print(\"üîÑ Formatting training data...\")\n",
    "formatted_samples = []\n",
    "for sample in tqdm(training_samples):\n",
    "    formatted_sample = format_training_sample(sample)\n",
    "    formatted_samples.append(formatted_sample)\n",
    "\n",
    "print(f\"‚úÖ Formatted {len(formatted_samples):,} training samples\")\n",
    "\n",
    "# Show formatted example\n",
    "print(\"\\nüìù Formatted Training Example:\")\n",
    "print(formatted_samples[0]['text'][:500] + \"...\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Formatting training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 921/921 [00:00<00:00, 217778.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Formatted 921 training samples\n",
      "\n",
      "üìù Formatted Training Example:\n",
      "<|im_start|>system\n",
      "You are a cybersecurity expert specializing in MITRE ATT&CK framework. Your task is to analyze threat intelligence descriptions and identify the corresponding MITRE ATT&CK techniques.\n",
      "\n",
      "Given a description of adversary behavior, identify the most relevant MITRE ATT&CK technique and provide:\n",
      "1. Technique ID (e.g., T1055.011)\n",
      "2. Technique Name\n",
      "3. Matrix (enterprise/mobile/ics)\n",
      "\n",
      "Respond in JSON format.<|im_end|>\n",
      "<|im_start|>user\n",
      "Analyze this threat behavior and identify the MITRE ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## 4. Setup Qwen Model and Tokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-23T14:48:37.944608Z",
     "start_time": "2025-08-23T14:48:32.030453Z"
    }
   },
   "source": [
    "# Model configuration\n",
    "MODEL_NAME = \"Qwen/Qwen2.5-1.5B-Instruct\"\n",
    "MAX_LENGTH = 2048\n",
    "BATCH_SIZE = 4\n",
    "LEARNING_RATE = 2e-5\n",
    "NUM_EPOCHS = 3\n",
    "WARMUP_STEPS = 100\n",
    "\n",
    "print(f\"ü§ñ Setting up model: {MODEL_NAME}\")\n",
    "\n",
    "import torch\n",
    "# Setup device\n",
    "# Setup device ∆∞u ti√™n: CUDA > MPS > CPU\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(f\"üîß Using device: {device}\")\n",
    "# Load tokenizer\n",
    "print(\"üìù Loading tokenizer...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    trust_remote_code=True,\n",
    "    padding_side=\"right\"\n",
    ")\n",
    "\n",
    "# Add padding token if not exists\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    print(\"üîß Set pad_token = eos_token\")\n",
    "\n",
    "print(f\"‚úÖ Tokenizer loaded\")\n",
    "print(f\"üìä Vocab size: {len(tokenizer):,}\")\n",
    "print(f\"üîë Special tokens: {tokenizer.special_tokens_map}\")\n",
    "\n",
    "# Load model\n",
    "print(\"ü§ñ Loading model...\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    trust_remote_code=True,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\",\n",
    "    low_cpu_mem_usage=True\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Model loaded\")\n",
    "print(f\"üìä Model parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "print(f\"üéØ Trainable parameters: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ Setting up model: Qwen/Qwen2.5-1.5B-Instruct\n",
      "üîß Using device: mps\n",
      "üìù Loading tokenizer...\n",
      "‚úÖ Tokenizer loaded\n",
      "üìä Vocab size: 151,665\n",
      "üîë Special tokens: {'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}\n",
      "ü§ñ Loading model...\n",
      "‚úÖ Model loaded\n",
      "üìä Model parameters: 1,543,714,304\n",
      "üéØ Trainable parameters: 1,543,714,304\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## 5. Create Dataset and Data Loaders\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-23T14:48:38.541900Z",
     "start_time": "2025-08-23T14:48:37.997177Z"
    }
   },
   "source": [
    "def tokenize_function(examples):\n",
    "    \"\"\"\n",
    "    Tokenize training examples\n",
    "    \"\"\"\n",
    "    # Tokenize the text\n",
    "    tokenized = tokenizer(\n",
    "        examples[\"text\"],\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",  # S·ª¨A L·ªñI: Pad to max length\n",
    "        max_length=MAX_LENGTH,\n",
    "        return_tensors=None\n",
    "    )\n",
    "\n",
    "    # For causal language modeling, labels are the same as input_ids\n",
    "    tokenized[\"labels\"] = tokenized[\"input_ids\"].copy()\n",
    "\n",
    "    return tokenized\n",
    "\n",
    "# Create train/validation split\n",
    "print(\"üìä Creating train/validation split...\")\n",
    "train_samples, val_samples = train_test_split(\n",
    "    formatted_samples,\n",
    "    test_size=0.1,\n",
    "    random_state=42,\n",
    "    stratify=[sample['text'].split('\"matrix\": \"')[1].split('\"')[0] for sample in formatted_samples]\n",
    ")\n",
    "\n",
    "print(f\"üìö Training samples: {len(train_samples):,}\")\n",
    "print(f\"üîç Validation samples: {len(val_samples):,}\")\n",
    "\n",
    "# Create HuggingFace datasets\n",
    "print(\"üîÑ Creating datasets...\")\n",
    "train_dataset = Dataset.from_list(train_samples)\n",
    "val_dataset = Dataset.from_list(val_samples)\n",
    "\n",
    "# Tokenize datasets\n",
    "print(\"üî§ Tokenizing datasets...\")\n",
    "train_dataset = train_dataset.map(\n",
    "    tokenize_function,\n",
    "    batched=True,\n",
    "    remove_columns=[\"text\"],\n",
    "    desc=\"Tokenizing train data\"\n",
    ")\n",
    "\n",
    "val_dataset = val_dataset.map(\n",
    "    tokenize_function,\n",
    "    batched=True,\n",
    "    remove_columns=[\"text\"],\n",
    "    desc=\"Tokenizing validation data\"\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Datasets prepared\")\n",
    "print(f\"üìä Train dataset: {len(train_dataset):,} samples\")\n",
    "print(f\"üìä Validation dataset: {len(val_dataset):,} samples\")\n",
    "\n",
    "# Check tokenization\n",
    "sample_tokens = train_dataset[0]\n",
    "print(f\"\\nüìù Sample tokenization:\")\n",
    "print(f\"Input IDs length: {len(sample_tokens['input_ids'])}\")\n",
    "print(f\"Attention mask length: {len(sample_tokens['attention_mask'])}\")\n",
    "print(f\"Labels length: {len(sample_tokens['labels'])}\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Creating train/validation split...\n",
      "üìö Training samples: 828\n",
      "üîç Validation samples: 93\n",
      "üîÑ Creating datasets...\n",
      "üî§ Tokenizing datasets...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Tokenizing train data:   0%|          | 0/828 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "df08b2132440433298f11e38bd7a135a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Tokenizing validation data:   0%|          | 0/93 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "608b989f2ba546e9a6f450a37560bca6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Datasets prepared\n",
      "üìä Train dataset: 828 samples\n",
      "üìä Validation dataset: 93 samples\n",
      "\n",
      "üìù Sample tokenization:\n",
      "Input IDs length: 2048\n",
      "Attention mask length: 2048\n",
      "Labels length: 2048\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## 6. Setup Training Configuration\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-23T14:48:38.557529Z",
     "start_time": "2025-08-23T14:48:38.547905Z"
    }
   },
   "source": [
    "# Create output directory\n",
    "timestamp = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "output_dir = f\"../models/qwen-ttp-classification-{timestamp}\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "print(f\"üìÅ Output directory: {output_dir}\")\n",
    "\n",
    "# Training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    overwrite_output_dir=True,\n",
    "\n",
    "    # Training parameters\n",
    "    num_train_epochs=NUM_EPOCHS,\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    per_device_eval_batch_size=BATCH_SIZE,\n",
    "    gradient_accumulation_steps=1,\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    weight_decay=0.01,\n",
    "    warmup_steps=WARMUP_STEPS,\n",
    "\n",
    "    # Optimization\n",
    "    fp16=True,\n",
    "    dataloader_pin_memory=False,\n",
    "    gradient_checkpointing=True,\n",
    "\n",
    "    # Logging and saving\n",
    "    logging_dir=f\"{output_dir}/logs\",\n",
    "    logging_steps=10,\n",
    "    save_steps=100,\n",
    "    save_total_limit=3,\n",
    "    eval_steps=100,\n",
    "    eval_strategy=\"steps\",  # FIXED: was evaluation_strategy\n",
    "\n",
    "    # Other settings\n",
    "    remove_unused_columns=False,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    "    greater_is_better=False,\n",
    "\n",
    "    # Report\n",
    "    report_to=None,  # Disable wandb/tensorboard\n",
    "    run_name=f\"qwen-ttp-classification-{timestamp}\"\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Training arguments configured\")\n",
    "print(f\"üéØ Batch size: {BATCH_SIZE}\")\n",
    "print(f\"üìà Learning rate: {LEARNING_RATE}\")\n",
    "print(f\"üîÑ Epochs: {NUM_EPOCHS}\")\n",
    "print(f\"üî• FP16: {training_args.fp16}\")\n",
    "print(f\"üíæ Gradient checkpointing: {training_args.gradient_checkpointing}\")\n",
    "\n",
    "# Data collator\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer,\n",
    "    mlm=False,  # No masking for causal LM\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Data collator configured\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÅ Output directory: ../models/qwen-ttp-classification-2025-08-23_21-48-38\n",
      "‚úÖ Training arguments configured\n",
      "üéØ Batch size: 4\n",
      "üìà Learning rate: 2e-05\n",
      "üîÑ Epochs: 3\n",
      "üî• FP16: True\n",
      "üíæ Gradient checkpointing: True\n",
      "‚úÖ Data collator configured\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## 7. Initialize Trainer and Start Training\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-23T14:48:38.669085Z",
     "start_time": "2025-08-23T14:48:38.577760Z"
    }
   },
   "source": [
    "# ‚úÖ CODE ƒê√É S·ª¨A HO√ÄN CH·ªàNH CHO MPS (APPLE SILICON)\n",
    "print(\"üîß Initializing MPS-compatible training...\")\n",
    "\n",
    "import torch\n",
    "from transformers import TrainingArguments, Trainer, DataCollatorForLanguageModeling\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "# Clear memory\n",
    "if torch.backends.mps.is_available():\n",
    "    torch.mps.empty_cache()\n",
    "    print(\"üßπ MPS cache cleared\")\n",
    "\n",
    "# Configuration\n",
    "MODEL_NAME = \"Qwen/Qwen2.5-7B-Instruct\"\n",
    "BATCH_SIZE = 2  # Smaller for MPS\n",
    "LEARNING_RATE = 2e-5\n",
    "NUM_EPOCHS = 3\n",
    "WARMUP_STEPS = 100\n",
    "\n",
    "# Create output directory\n",
    "timestamp = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "output_dir = f\"../models/qwen-ttp-mps-{timestamp}\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "print(f\"üìÅ Output: {output_dir}\")\n",
    "\n",
    "# ‚úÖ MPS-COMPATIBLE TrainingArguments (S·ª¨A L·ªñI)\n",
    "training_args_mps = TrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    overwrite_output_dir=True,\n",
    "\n",
    "    # Training params\n",
    "    num_train_epochs=NUM_EPOCHS,\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    per_device_eval_batch_size=BATCH_SIZE,\n",
    "    gradient_accumulation_steps=2,  # TƒÉng ƒë·ªÉ b√π ƒë·∫Øp batch nh·ªè\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    weight_decay=0.01,\n",
    "    warmup_steps=WARMUP_STEPS,\n",
    "\n",
    "    # ‚ö†Ô∏è QUAN TR·ªåNG: MPS settings\n",
    "    fp16=False,              # PH·∫¢I False cho MPS\n",
    "    bf16=False,              # PH·∫¢I False cho MPS\n",
    "    dataloader_pin_memory=False,\n",
    "    gradient_checkpointing=True,\n",
    "\n",
    "    # Logging\n",
    "    logging_steps=10,\n",
    "    save_steps=100,\n",
    "    eval_steps=100,\n",
    "    eval_strategy=\"steps\",   # S·ª¨A: kh√¥ng ph·∫£i evaluation_strategy\n",
    "    save_total_limit=3,\n",
    "\n",
    "    # Evaluation\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    "    greater_is_better=False,\n",
    "\n",
    "    # Disable external services\n",
    "    report_to=None,\n",
    "    dataloader_num_workers=0,  # Single thread cho MPS\n",
    ")\n",
    "\n",
    "# ‚úÖ Data collator (S·ª¨A L·ªñI)\n",
    "data_collator_mps = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer,\n",
    "    mlm=False\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Configuration created!\")\n",
    "print(f\"üî• FP16: {training_args_mps.fp16} (ph·∫£i False)\")\n",
    "print(f\"üçé BF16: {training_args_mps.bf16} (ph·∫£i False)\")\n",
    "\n",
    "# ‚úÖ Initialize Trainer (S·ª¨A L·ªñI - KH√îNG c√≥ accelerator argument)\n",
    "print(\"\\nüèÉ‚Äç‚ôÇÔ∏è Creating trainer...\")\n",
    "\n",
    "os.environ[\"ACCELERATE_MIXED_PRECISION\"] = \"no\"\n",
    "os.environ[\"ACCELERATE_DISABLE_RICH\"] = \"1\"\n",
    "\n",
    "# Kh·ªüi t·∫°o trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args_mps,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator_mps,\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Trainer initialized successfully!\")\n",
    "print(\"üçé Ready for MPS training!\")\n",
    "print(f\"üìä Batch size: {BATCH_SIZE}\")\n",
    "print(f\"üîÑ Effective batch: {BATCH_SIZE * 2} (v·ªõi gradient accumulation)\")\n",
    "print(f\"üìà Learning rate: {LEARNING_RATE}\")\n",
    "\n",
    "# ‚úÖ B√¢y gi·ªù c√≥ th·ªÉ b·∫Øt ƒë·∫ßu training\n",
    "print(\"\\nüöÄ Ready to train! Run: trainer.train()\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß Initializing MPS-compatible training...\n",
      "üßπ MPS cache cleared\n",
      "üìÅ Output: ../models/qwen-ttp-mps-2025-08-23_21-48-38\n",
      "‚úÖ Configuration created!\n",
      "üî• FP16: False (ph·∫£i False)\n",
      "üçé BF16: False (ph·∫£i False)\n",
      "\n",
      "üèÉ‚Äç‚ôÇÔ∏è Creating trainer...\n",
      "‚úÖ Trainer initialized successfully!\n",
      "üçé Ready for MPS training!\n",
      "üìä Batch size: 2\n",
      "üîÑ Effective batch: 4 (v·ªõi gradient accumulation)\n",
      "üìà Learning rate: 2e-05\n",
      "\n",
      "üöÄ Ready to train! Run: trainer.train()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/lt/y_3sh6vn2mb68907rlw4xvww0000gn/T/ipykernel_73160/224522789.py:81: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## 9. Test Model Inference\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-23T14:48:53.336068Z",
     "start_time": "2025-08-23T14:48:38.674206Z"
    }
   },
   "source": [
    "def test_ttp_classification(model, tokenizer, threat_description: str) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Test TTP classification on a threat description\n",
    "    \"\"\"\n",
    "    system_prompt = \"\"\"You are a cybersecurity expert specializing in MITRE ATT&CK framework. Your task is to analyze threat intelligence descriptions and identify the corresponding MITRE ATT&CK techniques.\n",
    "\n",
    "Given a description of adversary behavior, identify the most relevant MITRE ATT&CK technique and provide:\n",
    "1. Technique ID (e.g., T1055.011)\n",
    "2. Technique Name\n",
    "3. Matrix (enterprise/mobile/ics)\n",
    "\n",
    "Respond in JSON format.\"\"\"\n",
    "\n",
    "    user_input = f\"Analyze this threat behavior and identify the MITRE ATT&CK technique:\\n\\n{threat_description}\"\n",
    "\n",
    "    # Format input\n",
    "    prompt = f\"\"\"<|im_start|>system\n",
    "{system_prompt}<|im_end|>\n",
    "<|im_start|>user\n",
    "{user_input}<|im_end|>\n",
    "<|im_start|>assistant\n",
    "\"\"\"\n",
    "\n",
    "    # Tokenize\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=1024)\n",
    "    inputs = {k: v.to(model.device) for k, v in inputs.items()}\n",
    "\n",
    "    # Generate response\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=256,\n",
    "            temperature=0.1,\n",
    "            do_sample=True,\n",
    "            pad_token_id=tokenizer.eos_token_id\n",
    "        )\n",
    "\n",
    "    # Decode response\n",
    "    full_response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    assistant_response = full_response.split(\"<|im_start|>assistant\\n\")[-1]\n",
    "\n",
    "    return {\n",
    "        \"input\": threat_description,\n",
    "        \"response\": assistant_response,\n",
    "        \"full_prompt\": prompt\n",
    "    }\n",
    "\n",
    "# Test examples\n",
    "test_cases = [\n",
    "    \"Adversaries may inject malicious code into processes in order to evade process-based defenses or elevate privileges.\",\n",
    "    \"Attackers send phishing emails with malicious attachments to gain initial access to the target system.\",\n",
    "    \"The malware establishes persistence by creating scheduled tasks that execute at system startup.\",\n",
    "    \"Adversaries may abuse elevation control mechanisms to gain higher-level permissions on a system.\"\n",
    "]\n",
    "\n",
    "print(\"üß™ Testing model inference...\")\n",
    "for i, test_case in enumerate(test_cases, 1):\n",
    "    print(f\"\\nüìù Test Case {i}:\")\n",
    "    print(f\"Input: {test_case}\")\n",
    "\n",
    "    result = test_ttp_classification(model, tokenizer, test_case)\n",
    "    print(f\"Output: {result['response']}\")\n",
    "    print(\"-\" * 80)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß™ Testing model inference...\n",
      "\n",
      "üìù Test Case 1:\n",
      "Input: Adversaries may inject malicious code into processes in order to evade process-based defenses or elevate privileges.\n",
      "Output: system\n",
      "You are a cybersecurity expert specializing in MITRE ATT&CK framework. Your task is to analyze threat intelligence descriptions and identify the corresponding MITRE ATT&CK techniques.\n",
      "\n",
      "Given a description of adversary behavior, identify the most relevant MITRE ATT&CK technique and provide:\n",
      "1. Technique ID (e.g., T1055.011)\n",
      "2. Technique Name\n",
      "3. Matrix (enterprise/mobile/ics)\n",
      "\n",
      "Respond in JSON format.\n",
      "user\n",
      "Analyze this threat behavior and identify the MITRE ATT&CK technique:\n",
      "\n",
      "Adversaries may inject malicious code into processes in order to evade process-based defenses or elevate privileges.\n",
      "assistant\n",
      "```json\n",
      "{\n",
      "  \"TechniqueID\": \"T1078\",\n",
      "  \"TechniqueName\": \"Elevate Privileges via Process Injection\",\n",
      "  \"Matrix\": \"enterprise\"\n",
      "}\n",
      "```\n",
      "\n",
      "Explanation:\n",
      "- **TechniqueID**: `T1078` - This technique involves elevating privileges by injecting malicious code into legitimate processes.\n",
      "- **TechniqueName**: `Elevate Privileges via Process Injection` - This describes how adversaries can manipulate system processes to gain elevated privileges without directly compromising the integrity of the operating system.\n",
      "- **Matrix**: `enterprise` - This indicates that this technique is applicable across enterprise environments where traditional security measures might be less effective due to the nature of process injection.\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "üìù Test Case 2:\n",
      "Input: Attackers send phishing emails with malicious attachments to gain initial access to the target system.\n",
      "Output: system\n",
      "You are a cybersecurity expert specializing in MITRE ATT&CK framework. Your task is to analyze threat intelligence descriptions and identify the corresponding MITRE ATT&CK techniques.\n",
      "\n",
      "Given a description of adversary behavior, identify the most relevant MITRE ATT&CK technique and provide:\n",
      "1. Technique ID (e.g., T1055.011)\n",
      "2. Technique Name\n",
      "3. Matrix (enterprise/mobile/ics)\n",
      "\n",
      "Respond in JSON format.\n",
      "user\n",
      "Analyze this threat behavior and identify the MITRE ATT&CK technique:\n",
      "\n",
      "Attackers send phishing emails with malicious attachments to gain initial access to the target system.\n",
      "assistant\n",
      "```json\n",
      "{\n",
      "  \"TechniqueID\": \"T1047\",\n",
      "  \"TechniqueName\": \"Create Phishing Campaigns\",\n",
      "  \"Matrix\": \"enterprise\"\n",
      "}\n",
      "```\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "üìù Test Case 3:\n",
      "Input: The malware establishes persistence by creating scheduled tasks that execute at system startup.\n",
      "Output: system\n",
      "You are a cybersecurity expert specializing in MITRE ATT&CK framework. Your task is to analyze threat intelligence descriptions and identify the corresponding MITRE ATT&CK techniques.\n",
      "\n",
      "Given a description of adversary behavior, identify the most relevant MITRE ATT&CK technique and provide:\n",
      "1. Technique ID (e.g., T1055.011)\n",
      "2. Technique Name\n",
      "3. Matrix (enterprise/mobile/ics)\n",
      "\n",
      "Respond in JSON format.\n",
      "user\n",
      "Analyze this threat behavior and identify the MITRE ATT&CK technique:\n",
      "\n",
      "The malware establishes persistence by creating scheduled tasks that execute at system startup.\n",
      "assistant\n",
      "```json\n",
      "{\n",
      "  \"TechniqueID\": \"T1078\",\n",
      "  \"TechniqueName\": \"Create Scheduled Tasks\",\n",
      "  \"Matrix\": \"enterprise\"\n",
      "}\n",
      "```\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "üìù Test Case 4:\n",
      "Input: Adversaries may abuse elevation control mechanisms to gain higher-level permissions on a system.\n",
      "Output: system\n",
      "You are a cybersecurity expert specializing in MITRE ATT&CK framework. Your task is to analyze threat intelligence descriptions and identify the corresponding MITRE ATT&CK techniques.\n",
      "\n",
      "Given a description of adversary behavior, identify the most relevant MITRE ATT&CK technique and provide:\n",
      "1. Technique ID (e.g., T1055.011)\n",
      "2. Technique Name\n",
      "3. Matrix (enterprise/mobile/ics)\n",
      "\n",
      "Respond in JSON format.\n",
      "user\n",
      "Analyze this threat behavior and identify the MITRE ATT&CK technique:\n",
      "\n",
      "Adversaries may abuse elevation control mechanisms to gain higher-level permissions on a system.\n",
      "assistant\n",
      "```json\n",
      "{\n",
      "  \"TechniqueID\": \"T1078\",\n",
      "  \"TechniqueName\": \"Elevation of Privilege\",\n",
      "  \"Matrix\": \"enterprise\"\n",
      "}\n",
      "```\n",
      "\n",
      "Explanation:\n",
      "- **TechniqueID**: `T1078` corresponds to the MITRE ATT&CK technique for Elevation of Privilege.\n",
      "- **TechniqueName**: This technique involves gaining elevated privileges by exploiting vulnerabilities or misconfigurations that allow an attacker to escalate their access level within a system.\n",
      "- **Matrix**: The technique is categorized under enterprise, which means it applies to both Windows and Linux environments.\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 11. Batch TTP Classification from File and Relationship Analysis\n",
    "\n",
    "This section loads a threat intelligence file, runs batch TTP classification with the (fine-tuned) Qwen model, extracts hash values, and analyzes relationships between:\n",
    "- Threat types (labels/categories in your data)\n",
    "- Techniques (MITRE ATT&CK technique IDs)\n",
    "- Hash values (MD5/SHA1/SHA256)\n",
    "\n",
    "Outputs:\n",
    "- Predictions dataset (`CSV` + `JSONL`)\n",
    "- Relationship edge list (`JSON`)\n",
    "- Knowledge graph export (`.gexf` for Gephi/NetworkX)\n",
    "\n",
    "Notes:\n",
    "- Techniques are labeled strictly by technique `id` (e.g., `T1055.011`).\n",
    "- The loader is schema-flexible; configure field mappings if needed.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-23T14:48:53.406993Z",
     "start_time": "2025-08-23T14:48:53.394745Z"
    }
   },
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import uuid\n",
    "from datetime import datetime\n",
    "from typing import Dict, Any, List, Tuple, Optional\n",
    "\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Field mappings (adjust to your data schema)\n",
    "FIELD_MAP = {\n",
    "    \"id\": [\"id\", \"_id\", \"uuid\"],\n",
    "    \"threat_type\": [\"threat_type\", \"type\", \"category\", \"topic\"],\n",
    "    \"title\": [\"title\", \"headline\"],\n",
    "    \"text\": [\"text\", \"content\", \"description\", \"body\"],\n",
    "    \"hashes\": [\"hashes\", \"artifacts.hashes\", \"ioc.hashes\", \"ioc\"],\n",
    "}\n",
    "\n",
    "# Output directory\n",
    "REL_TIMESTAMP = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "REL_OUT_DIR = f\"../models/ttp_batch_analysis_{REL_TIMESTAMP}\"\n",
    "os.makedirs(REL_OUT_DIR, exist_ok=True)\n",
    "\n",
    "HASH_REGEX = re.compile(r\"\\b([A-Fa-f0-9]{32}|[A-Fa-f0-9]{40}|[A-Fa-f0-9]{64})\\b\")  # MD5|SHA1|SHA256\n",
    "\n",
    "\n",
    "def _coerce_text(raw: Any) -> str:\n",
    "    \"\"\"Coerce list/dict/other into a single plain text string.\"\"\"\n",
    "    if raw is None:\n",
    "        return \"\"\n",
    "    if isinstance(raw, str):\n",
    "        return raw\n",
    "    if isinstance(raw, list):\n",
    "        return \" \".join([str(x) for x in raw if isinstance(x, (str, int, float))])\n",
    "    if isinstance(raw, dict):\n",
    "        return \" \".join([str(v) for v in raw.values() if isinstance(v, (str, int, float))])\n",
    "    return str(raw)\n",
    "\n",
    "def _first_present(d: Dict[str, Any], keys: List[str], default: Any = None):\n",
    "    for k in keys:\n",
    "        # support dotted paths like 'artifacts.hashes'\n",
    "        node = d\n",
    "        valid = True\n",
    "        for part in k.split('.'):\n",
    "            if isinstance(node, dict) and part in node:\n",
    "                node = node[part]\n",
    "            else:\n",
    "                valid = False\n",
    "                break\n",
    "        if valid:\n",
    "            return node\n",
    "    return default\n",
    "\n",
    "\n",
    "def _extract_hashes(record: Dict[str, Any]) -> List[str]:\n",
    "    # Try mapped fields first\n",
    "    hashes_field = _first_present(record, FIELD_MAP[\"hashes\"], default=None)\n",
    "    found: List[str] = []\n",
    "    if isinstance(hashes_field, list):\n",
    "        for x in hashes_field:\n",
    "            if isinstance(x, str) and HASH_REGEX.fullmatch(x):\n",
    "                found.append(x.lower())\n",
    "            elif isinstance(x, dict):\n",
    "                for v in x.values():\n",
    "                    if isinstance(v, str) and HASH_REGEX.fullmatch(v):\n",
    "                        found.append(v.lower())\n",
    "    elif isinstance(hashes_field, dict):\n",
    "        for v in hashes_field.values():\n",
    "            if isinstance(v, str) and HASH_REGEX.fullmatch(v):\n",
    "                found.append(v.lower())\n",
    "            elif isinstance(v, list):\n",
    "                for x in v:\n",
    "                    if isinstance(x, str) and HASH_REGEX.fullmatch(x):\n",
    "                        found.append(x.lower())\n",
    "    # Fallback: scan text (coerce list/dict to string)\n",
    "    raw_text = _first_present(record, FIELD_MAP[\"text\"], default=\"\")\n",
    "    text = _coerce_text(raw_text)\n",
    "    found += [h.lower() for h in HASH_REGEX.findall(text)]\n",
    "    # Normalize unique\n",
    "    uniq = sorted(set(found))\n",
    "    return uniq\n",
    "\n",
    "\n",
    "def _make_prompt(threat_text: str) -> str:\n",
    "    system_prompt = (\n",
    "        \"You are a cybersecurity expert specializing in MITRE ATT&CK framework. \"\n",
    "        \"Your task is to analyze threat intelligence descriptions and identify the corresponding MITRE ATT&CK techniques.\\n\\n\"\n",
    "        \"Given a description of adversary behavior, identify the most relevant MITRE ATT&CK technique and provide:\\n\"\n",
    "        \"1. Technique ID (e.g., T1055.011)\\n\"\n",
    "        \"2. Technique Name\\n\"\n",
    "        \"3. Matrix (enterprise/mobile/ics)\\n\\n\"\n",
    "        \"Respond in JSON format.\"\n",
    "    )\n",
    "    user_input = f\"Analyze this threat behavior and identify the MITRE ATT&CK technique:\\n\\n{threat_text}\"\n",
    "    return (\n",
    "        f\"<|im_start|>system\\n{system_prompt}<|im_end|>\\n\"\n",
    "        f\"<|im_start|>user\\n{user_input}<|im_end|>\\n\"\n",
    "        f\"<|im_start|>assistant\\n\"\n",
    "    )\n",
    "\n",
    "\n",
    "def classify_one(text_value: str) -> Tuple[Optional[str], Optional[str], Optional[str], str]:\n",
    "    \"\"\"Run model inference; return (technique_id, technique_name, matrix, raw_response).\"\"\"\n",
    "    if not text_value or not isinstance(text_value, str):\n",
    "        return None, None, None, \"\"\n",
    "\n",
    "    prompt = _make_prompt(text_value)\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=1024)\n",
    "    inputs = {k: v.to(model.device) for k, v in inputs.items()}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=128,\n",
    "            temperature=0.0,\n",
    "            do_sample=False,\n",
    "            pad_token_id=tokenizer.eos_token_id,\n",
    "        )\n",
    "\n",
    "    full_response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    assistant_response = full_response.split(\"<|im_start|>assistant\\n\")[-1]\n",
    "\n",
    "    # Try to parse JSON\n",
    "    tech_id = tech_name = matrix = None\n",
    "    try:\n",
    "        # Extract JSON block if wrapped\n",
    "        json_match = re.search(r\"\\{[\\s\\S]*\\}\", assistant_response)\n",
    "        if json_match:\n",
    "            data = json.loads(json_match.group(0))\n",
    "        else:\n",
    "            data = json.loads(assistant_response)\n",
    "        tech_id = (data.get(\"technique_id\") or data.get(\"id\") or \"\").strip() or None\n",
    "        tech_name = (data.get(\"technique_name\") or data.get(\"name\") or \"\").strip() or None\n",
    "        matrix = (data.get(\"matrix\") or \"\").strip() or None\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    # Ensure technique id label format\n",
    "    if tech_id and not re.match(r\"^T\\d{4}(?:\\.\\d{3})?$\", tech_id):\n",
    "        tech_id = None\n",
    "\n",
    "    return tech_id, tech_name, matrix, assistant_response\n",
    "\n",
    "\n",
    "def load_records(input_path: str) -> List[Dict[str, Any]]:\n",
    "    if input_path.endswith(\".jsonl\"):\n",
    "        rows = []\n",
    "        with open(input_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            for line in f:\n",
    "                if line.strip():\n",
    "                    rows.append(json.loads(line))\n",
    "        return rows\n",
    "    elif input_path.endswith(\".json\"):\n",
    "        with open(input_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            data = json.load(f)\n",
    "        # try top-level list or known keys\n",
    "        if isinstance(data, list):\n",
    "            return data\n",
    "        for key in [\"data\", \"items\", \"records\", \"dataset\", \"documents\"]:\n",
    "            if key in data and isinstance(data[key], list):\n",
    "                return data[key]\n",
    "        # fallback: single object\n",
    "        return [data]\n",
    "    elif input_path.endswith(\".csv\"):\n",
    "        df = pd.read_csv(input_path)\n",
    "        return df.to_dict(orient=\"records\")\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported file type: {input_path}\")\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 19
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "### 11.2 Build extended relationships JSON (per-record)\n",
    "\n",
    "This step:\n",
    "- Extracts multiple techniques from `content` using the model (top-k list)\n",
    "- Creates `extended_relationships` as requested\n",
    "- Produces a JSON file under `data/TTP-classification/`"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-23T14:48:53.429623Z",
     "start_time": "2025-08-23T14:48:53.427554Z"
    }
   },
   "source": [
    "# Quick test overrides\n",
    "TOP_K = 3  # limit techniques per record\n",
    "print(f\"TOP_K overridden to: {TOP_K}\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOP_K overridden to: 3\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-23T14:48:53.464983Z",
     "start_time": "2025-08-23T14:48:53.456289Z"
    }
   },
   "source": [
    "from typing import Iterable\n",
    "\n",
    "# Settings for multi-technique extraction\n",
    "TOP_K = 6  # max techniques to extract per record\n",
    "SAVE_JSON_PATH = \"../data/TTP-classification/extended_relationships_output.json\"\n",
    "\n",
    "# Local fallback in case _coerce_text wasn't executed in earlier cells\n",
    "try:\n",
    "    _coerce_text\n",
    "except NameError:\n",
    "    def _coerce_text(raw):\n",
    "        if raw is None:\n",
    "            return \"\"\n",
    "        if isinstance(raw, str):\n",
    "            return raw\n",
    "        if isinstance(raw, list):\n",
    "            return \" \".join(str(x) for x in raw if isinstance(x, (str, int, float)))\n",
    "        if isinstance(raw, dict):\n",
    "            return \" \".join(str(v) for v in raw.values() if isinstance(v, (str, int, float)))\n",
    "        return str(raw)\n",
    "\n",
    "def classify_multiple_techniques(threat_text: str, top_k: int = TOP_K) -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Query the model to extract up to top_k techniques from text.\n",
    "    Returns list of {id, name, description, matrix} using technique ids as labels.\n",
    "    \"\"\"\n",
    "    if not threat_text or not isinstance(threat_text, str):\n",
    "        return []\n",
    "\n",
    "    system_prompt = (\n",
    "        \"You are a cybersecurity expert specializing in MITRE ATT&CK framework. \"\n",
    "        \"Read the text and return a JSON object with a 'techniques' array listing up to N relevant techniques. \"\n",
    "        \"Each technique must include: id, name, description, matrix. Use MITRE technique ids strictly (e.g., T1218, T1218.011).\"\n",
    "    )\n",
    "    user_input = (\n",
    "        \"Extract up to N MITRE ATT&CK techniques from the following content. \"\n",
    "        f\"N={top_k}. Return JSON with key 'techniques'.\\n\\nContent:\\n{threat_text}\"\n",
    "    )\n",
    "\n",
    "    prompt = (\n",
    "        f\"<|im_start|>system\\n{system_prompt}<|im_end|>\\n\"\n",
    "        f\"<|im_start|>user\\n{user_input}<|im_end|>\\n\"\n",
    "        f\"<|im_start|>assistant\\n\"\n",
    "    )\n",
    "\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=2048)\n",
    "    inputs = {k: v.to(model.device) for k, v in inputs.items()}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=512,\n",
    "            do_sample=False,  # T·∫Øt sampling\n",
    "            num_beams=1,      # S·ª≠ d·ª•ng greedy decoding\n",
    "            pad_token_id=tokenizer.eos_token_id,\n",
    "        )\n",
    "\n",
    "    resp = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    content = resp.split(\"<|im_start|>assistant\\n\")[-1]\n",
    "\n",
    "    # Parse JSON\n",
    "    techniques: List[Dict[str, Any]] = []\n",
    "    try:\n",
    "        json_match = re.search(r\"\\{[\\s\\S]*\\}\", content)\n",
    "        data = json.loads(json_match.group(0) if json_match else content)\n",
    "        items = data.get(\"techniques\") or data\n",
    "        if isinstance(items, dict) and \"techniques\" in items:\n",
    "            items = items[\"techniques\"]\n",
    "        if isinstance(items, list):\n",
    "            for t in items[:top_k]:\n",
    "                tid = (t.get(\"id\") or t.get(\"technique_id\") or \"\").strip()\n",
    "                if not re.match(r\"^T\\d{4}(?:\\.\\d{3})?$\", tid):\n",
    "                    continue\n",
    "                techniques.append({\n",
    "                    \"id\": tid,\n",
    "                    \"name\": t.get(\"name\"),\n",
    "                    \"description\": t.get(\"description\"),\n",
    "                    \"matrix\": t.get(\"matrix\"),\n",
    "                })\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    # Deduplicate by id\n",
    "    seen = set()\n",
    "    uniq: List[Dict[str, Any]] = []\n",
    "    for t in techniques:\n",
    "        if t[\"id\"] in seen:\n",
    "            continue\n",
    "        seen.add(t[\"id\"])\n",
    "        uniq.append(t)\n",
    "    return uniq\n",
    "\n",
    "def build_extended_relationships(record: Dict[str, Any], techniques: List[Dict[str, Any]]) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Construct extended_relationships.relationships using the requested format:\n",
    "    [ [subject, predicate, object], ... ]\n",
    "    - Map high-level threat types/entities to technique ids\n",
    "    - Also include 'associated_with' links from the main threat label to all techniques\n",
    "    \"\"\"\n",
    "    title = _first_present(record, FIELD_MAP[\"title\"], default=None)\n",
    "    link = record.get(\"link\") or record.get(\"url\")\n",
    "    raw_content = _first_present(record, FIELD_MAP[\"text\"], default=\"\")\n",
    "    content_text = _coerce_text(raw_content)\n",
    "\n",
    "    # Use existing entity extraction section if present\n",
    "    extraction = record.get(\"extraction\") or {}\n",
    "    ents = extraction.get(\"entities\") or []\n",
    "\n",
    "    # Collect subjects from entities and threat_type field\n",
    "    subjects: List[str] = []\n",
    "    if ents:\n",
    "        for item in ents:\n",
    "            if isinstance(item, (list, tuple)) and len(item) >= 2:\n",
    "                subjects.append(str(item[0]))\n",
    "    tt = _first_present(record, FIELD_MAP[\"threat_type\"], default=None)\n",
    "    if tt:\n",
    "        subjects.append(str(tt))\n",
    "\n",
    "    subjects = [s for s in {s.strip(): None for s in subjects}.keys() if s]\n",
    "\n",
    "    # Relationships\n",
    "    rels: List[List[str]] = []\n",
    "    # Example mapping rules: ransomware uses T1486 etc. We simply create generic relations here.\n",
    "    for subj in subjects:\n",
    "        for t in techniques:\n",
    "            rels.append([subj, \"associated_with\", t[\"id\"]])\n",
    "    # Add specific 'uses' if subject text suggests usage verbs in content\n",
    "    verbs = [\"use\", \"uses\", \"abuse\", \"abuses\", \"leverage\", \"leverages\", \"employ\", \"employs\"]\n",
    "    text_lower = content_text.lower() if isinstance(content_text, str) else _coerce_text(content_text).lower()\n",
    "    if any(v in text_lower for v in verbs):\n",
    "        for subj in subjects:\n",
    "            for t in techniques:\n",
    "                rels.append([subj, \"uses\", t[\"id\"]])\n",
    "\n",
    "    return {\n",
    "        \"title\": title,\n",
    "        \"link\": link,\n",
    "        \"content\": content_text,\n",
    "        \"extraction\": extraction or None,\n",
    "        \"ttp_classification\": {\n",
    "            \"instruction\": None,\n",
    "            \"input\": None,\n",
    "            \"output\": {\"techniques\": techniques},\n",
    "        },\n",
    "        \"extended_relationships\": {\"relationships\": rels},\n",
    "    }\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-23T14:48:53.509691Z",
     "start_time": "2025-08-23T14:48:53.486046Z"
    }
   },
   "source": [
    "import os, json\n",
    "from tqdm import tqdm\n",
    "from typing import Dict, Any, List\n",
    "\n",
    "SRC_ENTITY_JSON = \"../data/raw/merged_threat_intelligence.json\"\n",
    "DST_DIR = \"../data/TTP-classification/qwen-ttp-classifiation/\"\n",
    "os.makedirs(DST_DIR, exist_ok=True)\n",
    "\n",
    "print(f\"üìÇ Loading entity-extraction file: {SRC_ENTITY_JSON}\")\n",
    "with open(SRC_ENTITY_JSON, \"r\", encoding=\"utf-8\") as f:\n",
    "    entity_records = json.load(f)\n",
    "print(f\"‚úÖ Loaded {len(entity_records)} records\")\n",
    "\n",
    "# H√†m x·ª≠ l√Ω 1 batch\n",
    "def process_batch(records: List[Dict[str, Any]], batch_id: int):\n",
    "    augmented: List[Dict[str, Any]] = []\n",
    "\n",
    "    for rec in tqdm(records, desc=f\"Batch {batch_id}\"):\n",
    "        title = rec.get(\"title\")\n",
    "        link = rec.get(\"link\") or rec.get(\"url\")\n",
    "        content_text = _coerce_text(rec.get(\"content\"))\n",
    "\n",
    "        # classify techniques\n",
    "        techniques = classify_multiple_techniques(content_text, top_k=TOP_K if 'TOP_K' in globals() else 6)\n",
    "\n",
    "        # entities ‚Üí subjects\n",
    "        extraction = rec.get(\"extraction\") or {}\n",
    "        ents = extraction.get(\"entities\") or []\n",
    "        subjects = []\n",
    "        for item in ents:\n",
    "            if isinstance(item, (list, tuple)) and len(item) >= 2:\n",
    "                subjects.append(str(item[0]))\n",
    "        threat_type = rec.get(\"threat_type\")\n",
    "        if threat_type:\n",
    "            subjects.append(str(threat_type))\n",
    "        subjects = [s for s in {s.strip(): None for s in subjects}.keys() if s]\n",
    "\n",
    "        # detect relationships\n",
    "        rels: List[List[str]] = []\n",
    "        verbs = [\"use\", \"uses\", \"abuse\", \"abuses\", \"leverage\", \"leverages\", \"employ\", \"employs\"]\n",
    "        if any(v in content_text.lower() for v in verbs):\n",
    "            for subj in subjects:\n",
    "                for t in (techniques or [])[:1]:\n",
    "                    rels.append([subj, \"uses\", t[\"id\"]])\n",
    "\n",
    "        rels = [list(x) for x in dict.fromkeys(tuple(r) for r in rels)]\n",
    "\n",
    "        # add results\n",
    "        out = dict(rec)\n",
    "        out[\"ttp_classification\"] = {\n",
    "            \"instruction\": None,\n",
    "            \"input\": None,\n",
    "            \"output\": {\"techniques\": techniques},\n",
    "        }\n",
    "        out[\"extended_relationships\"] = {\"relationships\": rels}\n",
    "        augmented.append(out)\n",
    "\n",
    "    # Save batch\n",
    "    dst_file = os.path.join(DST_DIR, f\"extended_relationships_batch_{batch_id}.json\")\n",
    "    with open(dst_file, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(augmented, f, ensure_ascii=False, indent=2)\n",
    "    print(f\"üíæ Written batch {batch_id}: {dst_file}\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Loading entity-extraction file: ../data/raw/merged_threat_intelligence.json\n",
      "‚úÖ Loaded 427 records\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-23T14:48:53.530545Z",
     "start_time": "2025-08-23T14:48:53.527609Z"
    }
   },
   "source": [
    "BATCH_SIZE = 50\n",
    "total = len(entity_records)\n",
    "\n",
    "# Chia danh s√°ch th√†nh nhi·ªÅu batch, m·ªói batch 50 record\n",
    "batches = [entity_records[i:i+BATCH_SIZE] for i in range(0, total, BATCH_SIZE)]\n",
    "\n",
    "print(f\"üìä T·ªïng s·ªë batch: {len(batches)}, m·ªói batch {BATCH_SIZE} records\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä T·ªïng s·ªë batch: 9, m·ªói batch 50 records\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-23T14:49:09.924779Z",
     "start_time": "2025-08-23T14:48:53.555790Z"
    }
   },
   "source": [
    "process_batch(batches[0], batch_id=1)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 1:   0%|          | 0/50 [00:00<?, ?it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Batch 1:   0%|          | 0/50 [00:15<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[24], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mprocess_batch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbatches\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_id\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[22], line 24\u001B[0m, in \u001B[0;36mprocess_batch\u001B[0;34m(records, batch_id)\u001B[0m\n\u001B[1;32m     21\u001B[0m content_text \u001B[38;5;241m=\u001B[39m _coerce_text(rec\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcontent\u001B[39m\u001B[38;5;124m\"\u001B[39m))\n\u001B[1;32m     23\u001B[0m \u001B[38;5;66;03m# classify techniques\u001B[39;00m\n\u001B[0;32m---> 24\u001B[0m techniques \u001B[38;5;241m=\u001B[39m \u001B[43mclassify_multiple_techniques\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcontent_text\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtop_k\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mTOP_K\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mTOP_K\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mglobals\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;241;43m6\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m     26\u001B[0m \u001B[38;5;66;03m# entities ‚Üí subjects\u001B[39;00m\n\u001B[1;32m     27\u001B[0m extraction \u001B[38;5;241m=\u001B[39m rec\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mextraction\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;129;01mor\u001B[39;00m {}\n",
      "Cell \u001B[0;32mIn[21], line 50\u001B[0m, in \u001B[0;36mclassify_multiple_techniques\u001B[0;34m(threat_text, top_k)\u001B[0m\n\u001B[1;32m     47\u001B[0m inputs \u001B[38;5;241m=\u001B[39m {k: v\u001B[38;5;241m.\u001B[39mto(model\u001B[38;5;241m.\u001B[39mdevice) \u001B[38;5;28;01mfor\u001B[39;00m k, v \u001B[38;5;129;01min\u001B[39;00m inputs\u001B[38;5;241m.\u001B[39mitems()}\n\u001B[1;32m     49\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mno_grad():\n\u001B[0;32m---> 50\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgenerate\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     51\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     52\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmax_new_tokens\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m512\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     53\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdo_sample\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# T·∫Øt sampling\u001B[39;49;00m\n\u001B[1;32m     54\u001B[0m \u001B[43m        \u001B[49m\u001B[43mnum_beams\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m      \u001B[49m\u001B[38;5;66;43;03m# S·ª≠ d·ª•ng greedy decoding\u001B[39;49;00m\n\u001B[1;32m     55\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpad_token_id\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtokenizer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43meos_token_id\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     56\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     58\u001B[0m resp \u001B[38;5;241m=\u001B[39m tokenizer\u001B[38;5;241m.\u001B[39mdecode(outputs[\u001B[38;5;241m0\u001B[39m], skip_special_tokens\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m     59\u001B[0m content \u001B[38;5;241m=\u001B[39m resp\u001B[38;5;241m.\u001B[39msplit(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m<|im_start|>assistant\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m]\n",
      "File \u001B[0;32m~/Documents/UIT/2nd/NLP/LLM-TKIG/.venv/lib/python3.12/site-packages/torch/utils/_contextlib.py:120\u001B[0m, in \u001B[0;36mcontext_decorator.<locals>.decorate_context\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    117\u001B[0m \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mwraps(func)\n\u001B[1;32m    118\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mdecorate_context\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m    119\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m ctx_factory():\n\u001B[0;32m--> 120\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/UIT/2nd/NLP/LLM-TKIG/.venv/lib/python3.12/site-packages/transformers/generation/utils.py:2548\u001B[0m, in \u001B[0;36mGenerationMixin.generate\u001B[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, use_model_defaults, custom_generate, **kwargs)\u001B[0m\n\u001B[1;32m   2536\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_contrastive_search(\n\u001B[1;32m   2537\u001B[0m         input_ids,\n\u001B[1;32m   2538\u001B[0m         logits_processor\u001B[38;5;241m=\u001B[39mprepared_logits_processor,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   2543\u001B[0m         \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mmodel_kwargs,\n\u001B[1;32m   2544\u001B[0m     )\n\u001B[1;32m   2546\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m generation_mode \u001B[38;5;129;01min\u001B[39;00m (GenerationMode\u001B[38;5;241m.\u001B[39mSAMPLE, GenerationMode\u001B[38;5;241m.\u001B[39mGREEDY_SEARCH):\n\u001B[1;32m   2547\u001B[0m     \u001B[38;5;66;03m# 11. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001B[39;00m\n\u001B[0;32m-> 2548\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_sample\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   2549\u001B[0m \u001B[43m        \u001B[49m\u001B[43minput_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2550\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlogits_processor\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mprepared_logits_processor\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2551\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstopping_criteria\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mprepared_stopping_criteria\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2552\u001B[0m \u001B[43m        \u001B[49m\u001B[43mgeneration_config\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgeneration_config\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2553\u001B[0m \u001B[43m        \u001B[49m\u001B[43msynced_gpus\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msynced_gpus\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2554\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstreamer\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstreamer\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2555\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mmodel_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2556\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   2558\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m generation_mode \u001B[38;5;129;01min\u001B[39;00m (GenerationMode\u001B[38;5;241m.\u001B[39mBEAM_SAMPLE, GenerationMode\u001B[38;5;241m.\u001B[39mBEAM_SEARCH):\n\u001B[1;32m   2559\u001B[0m     \u001B[38;5;66;03m# 11. run beam sample\u001B[39;00m\n\u001B[1;32m   2560\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_beam_search(\n\u001B[1;32m   2561\u001B[0m         input_ids,\n\u001B[1;32m   2562\u001B[0m         logits_processor\u001B[38;5;241m=\u001B[39mprepared_logits_processor,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   2566\u001B[0m         \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mmodel_kwargs,\n\u001B[1;32m   2567\u001B[0m     )\n",
      "File \u001B[0;32m~/Documents/UIT/2nd/NLP/LLM-TKIG/.venv/lib/python3.12/site-packages/transformers/generation/utils.py:3510\u001B[0m, in \u001B[0;36mGenerationMixin._sample\u001B[0;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, **model_kwargs)\u001B[0m\n\u001B[1;32m   3508\u001B[0m     is_prefill \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[1;32m   3509\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 3510\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[43mmodel_forward\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mmodel_inputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreturn_dict\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[1;32m   3512\u001B[0m \u001B[38;5;66;03m# synced_gpus: don't waste resources running the code we don't need; kwargs must be updated before skipping\u001B[39;00m\n\u001B[1;32m   3513\u001B[0m model_kwargs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_update_model_kwargs_for_generation(\n\u001B[1;32m   3514\u001B[0m     outputs,\n\u001B[1;32m   3515\u001B[0m     model_kwargs,\n\u001B[1;32m   3516\u001B[0m     is_encoder_decoder\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39mis_encoder_decoder,\n\u001B[1;32m   3517\u001B[0m )\n",
      "File \u001B[0;32m~/Documents/UIT/2nd/NLP/LLM-TKIG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1773\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1771\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1772\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1773\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/UIT/2nd/NLP/LLM-TKIG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1784\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1779\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1780\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1781\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1782\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1783\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1784\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1786\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1787\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[0;32m~/Documents/UIT/2nd/NLP/LLM-TKIG/.venv/lib/python3.12/site-packages/transformers/utils/generic.py:959\u001B[0m, in \u001B[0;36mcan_return_tuple.<locals>.wrapper\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    957\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m return_dict_passed \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    958\u001B[0m     return_dict \u001B[38;5;241m=\u001B[39m return_dict_passed\n\u001B[0;32m--> 959\u001B[0m output \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    960\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m return_dict \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(output, \u001B[38;5;28mtuple\u001B[39m):\n\u001B[1;32m    961\u001B[0m     output \u001B[38;5;241m=\u001B[39m output\u001B[38;5;241m.\u001B[39mto_tuple()\n",
      "File \u001B[0;32m~/Documents/UIT/2nd/NLP/LLM-TKIG/.venv/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py:455\u001B[0m, in \u001B[0;36mQwen2ForCausalLM.forward\u001B[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, cache_position, logits_to_keep, **kwargs)\u001B[0m\n\u001B[1;32m    423\u001B[0m \u001B[38;5;129m@can_return_tuple\u001B[39m\n\u001B[1;32m    424\u001B[0m \u001B[38;5;129m@auto_docstring\u001B[39m\n\u001B[1;32m    425\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mforward\u001B[39m(\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    436\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs: Unpack[TransformersKwargs],\n\u001B[1;32m    437\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m CausalLMOutputWithPast:\n\u001B[1;32m    438\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    439\u001B[0m \u001B[38;5;124;03m    Example:\u001B[39;00m\n\u001B[1;32m    440\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    453\u001B[0m \u001B[38;5;124;03m    \"Hey, are you conscious? Can you talk to me?\\nI'm not conscious, but I can talk to you.\"\u001B[39;00m\n\u001B[1;32m    454\u001B[0m \u001B[38;5;124;03m    ```\"\"\"\u001B[39;00m\n\u001B[0;32m--> 455\u001B[0m     outputs: BaseModelOutputWithPast \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    456\u001B[0m \u001B[43m        \u001B[49m\u001B[43minput_ids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minput_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    457\u001B[0m \u001B[43m        \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    458\u001B[0m \u001B[43m        \u001B[49m\u001B[43mposition_ids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mposition_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    459\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpast_key_values\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpast_key_values\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    460\u001B[0m \u001B[43m        \u001B[49m\u001B[43minputs_embeds\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs_embeds\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    461\u001B[0m \u001B[43m        \u001B[49m\u001B[43muse_cache\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muse_cache\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    462\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcache_position\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcache_position\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    463\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    464\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    466\u001B[0m     hidden_states \u001B[38;5;241m=\u001B[39m outputs\u001B[38;5;241m.\u001B[39mlast_hidden_state\n\u001B[1;32m    467\u001B[0m     \u001B[38;5;66;03m# Only compute necessary logits, and do not upcast them to float if we are not computing the loss\u001B[39;00m\n",
      "File \u001B[0;32m~/Documents/UIT/2nd/NLP/LLM-TKIG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1773\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1771\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1772\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1773\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/UIT/2nd/NLP/LLM-TKIG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1784\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1779\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1780\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1781\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1782\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1783\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1784\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1786\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1787\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[0;32m~/Documents/UIT/2nd/NLP/LLM-TKIG/.venv/lib/python3.12/site-packages/transformers/utils/generic.py:1083\u001B[0m, in \u001B[0;36mcheck_model_inputs.<locals>.wrapper\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1080\u001B[0m                 module\u001B[38;5;241m.\u001B[39mforward \u001B[38;5;241m=\u001B[39m make_capture_wrapper(module, original_forward, key, specs\u001B[38;5;241m.\u001B[39mindex)\n\u001B[1;32m   1081\u001B[0m                 monkey_patched_layers\u001B[38;5;241m.\u001B[39mappend((module, original_forward))\n\u001B[0;32m-> 1083\u001B[0m outputs \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1084\u001B[0m \u001B[38;5;66;03m# Restore original forward methods\u001B[39;00m\n\u001B[1;32m   1085\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m module, original_forward \u001B[38;5;129;01min\u001B[39;00m monkey_patched_layers:\n",
      "File \u001B[0;32m~/Documents/UIT/2nd/NLP/LLM-TKIG/.venv/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py:384\u001B[0m, in \u001B[0;36mQwen2Model.forward\u001B[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, cache_position, **kwargs)\u001B[0m\n\u001B[1;32m    381\u001B[0m position_embeddings \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrotary_emb(hidden_states, position_ids)\n\u001B[1;32m    383\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m decoder_layer \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlayers[: \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39mnum_hidden_layers]:\n\u001B[0;32m--> 384\u001B[0m     hidden_states \u001B[38;5;241m=\u001B[39m \u001B[43mdecoder_layer\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    385\u001B[0m \u001B[43m        \u001B[49m\u001B[43mhidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    386\u001B[0m \u001B[43m        \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcausal_mask_mapping\u001B[49m\u001B[43m[\u001B[49m\u001B[43mdecoder_layer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mattention_type\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    387\u001B[0m \u001B[43m        \u001B[49m\u001B[43mposition_ids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mposition_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    388\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpast_key_values\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpast_key_values\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    389\u001B[0m \u001B[43m        \u001B[49m\u001B[43muse_cache\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muse_cache\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    390\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcache_position\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcache_position\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    391\u001B[0m \u001B[43m        \u001B[49m\u001B[43mposition_embeddings\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mposition_embeddings\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    392\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    393\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    395\u001B[0m hidden_states \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnorm(hidden_states)\n\u001B[1;32m    396\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m BaseModelOutputWithPast(\n\u001B[1;32m    397\u001B[0m     last_hidden_state\u001B[38;5;241m=\u001B[39mhidden_states,\n\u001B[1;32m    398\u001B[0m     past_key_values\u001B[38;5;241m=\u001B[39mpast_key_values \u001B[38;5;28;01mif\u001B[39;00m use_cache \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m    399\u001B[0m )\n",
      "File \u001B[0;32m~/Documents/UIT/2nd/NLP/LLM-TKIG/.venv/lib/python3.12/site-packages/transformers/modeling_layers.py:94\u001B[0m, in \u001B[0;36mGradientCheckpointingLayer.__call__\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m     91\u001B[0m         logger\u001B[38;5;241m.\u001B[39mwarning_once(message)\n\u001B[1;32m     93\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_gradient_checkpointing_func(partial(\u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__call__\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs), \u001B[38;5;241m*\u001B[39margs)\n\u001B[0;32m---> 94\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__call__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/UIT/2nd/NLP/LLM-TKIG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1773\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1771\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1772\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1773\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/UIT/2nd/NLP/LLM-TKIG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1784\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1779\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1780\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1781\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1782\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1783\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1784\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1786\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1787\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[0;32m~/Documents/UIT/2nd/NLP/LLM-TKIG/.venv/lib/python3.12/site-packages/transformers/utils/deprecation.py:172\u001B[0m, in \u001B[0;36mdeprecate_kwarg.<locals>.wrapper.<locals>.wrapped_func\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    168\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m minimum_action \u001B[38;5;129;01min\u001B[39;00m (Action\u001B[38;5;241m.\u001B[39mNOTIFY, Action\u001B[38;5;241m.\u001B[39mNOTIFY_ALWAYS) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_torchdynamo_compiling():\n\u001B[1;32m    169\u001B[0m     \u001B[38;5;66;03m# DeprecationWarning is ignored by default, so we use FutureWarning instead\u001B[39;00m\n\u001B[1;32m    170\u001B[0m     warnings\u001B[38;5;241m.\u001B[39mwarn(message, \u001B[38;5;167;01mFutureWarning\u001B[39;00m, stacklevel\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m)\n\u001B[0;32m--> 172\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/UIT/2nd/NLP/LLM-TKIG/.venv/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py:249\u001B[0m, in \u001B[0;36mQwen2DecoderLayer.forward\u001B[0;34m(self, hidden_states, attention_mask, position_ids, past_key_values, use_cache, cache_position, position_embeddings, **kwargs)\u001B[0m\n\u001B[1;32m    247\u001B[0m residual \u001B[38;5;241m=\u001B[39m hidden_states\n\u001B[1;32m    248\u001B[0m hidden_states \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpost_attention_layernorm(hidden_states)\n\u001B[0;32m--> 249\u001B[0m hidden_states \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmlp\u001B[49m\u001B[43m(\u001B[49m\u001B[43mhidden_states\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    250\u001B[0m hidden_states \u001B[38;5;241m=\u001B[39m residual \u001B[38;5;241m+\u001B[39m hidden_states\n\u001B[1;32m    251\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m hidden_states\n",
      "File \u001B[0;32m~/Documents/UIT/2nd/NLP/LLM-TKIG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1773\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1771\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1772\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1773\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/UIT/2nd/NLP/LLM-TKIG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1784\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1779\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1780\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1781\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1782\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1783\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1784\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1786\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1787\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[0;32m~/Documents/UIT/2nd/NLP/LLM-TKIG/.venv/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py:46\u001B[0m, in \u001B[0;36mQwen2MLP.forward\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m     45\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, x):\n\u001B[0;32m---> 46\u001B[0m     down_proj \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdown_proj\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mact_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgate_proj\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mup_proj\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     47\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m down_proj\n",
      "File \u001B[0;32m~/Documents/UIT/2nd/NLP/LLM-TKIG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1773\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1771\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1772\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1773\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/UIT/2nd/NLP/LLM-TKIG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1784\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1779\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1780\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1781\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1782\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1783\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1784\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1786\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1787\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[0;32m~/Documents/UIT/2nd/NLP/LLM-TKIG/.venv/lib/python3.12/site-packages/torch/nn/modules/linear.py:124\u001B[0m, in \u001B[0;36mLinear.forward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    121\u001B[0m         bound \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m \u001B[38;5;241m/\u001B[39m math\u001B[38;5;241m.\u001B[39msqrt(fan_in) \u001B[38;5;28;01mif\u001B[39;00m fan_in \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;241m0\u001B[39m\n\u001B[1;32m    122\u001B[0m         init\u001B[38;5;241m.\u001B[39muniform_(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbias, \u001B[38;5;241m-\u001B[39mbound, bound)\n\u001B[0;32m--> 124\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[1;32m    125\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m F\u001B[38;5;241m.\u001B[39mlinear(\u001B[38;5;28minput\u001B[39m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mweight, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbias)\n\u001B[1;32m    127\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mextra_repr\u001B[39m(\u001B[38;5;28mself\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28mstr\u001B[39m:\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Batch 2 (records 50‚Äì99):\n",
    "process_batch(batches[1], batch_id=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Batch 3 (records 100‚Äì149):\n",
    "process_batch(batches[1], batch_id=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Batch 4 (records 150 ‚Äì 199):\n",
    "process_batch(batches[1], batch_id=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Batch 5 (records 200 ‚Äì 249):\n",
    "process_batch(batches[1], batch_id=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Batch 6 (records 250 ‚Äì 299):\n",
    "process_batch(batches[1], batch_id=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Batch 7 (records 300 ‚Äì 349):\n",
    "process_batch(batches[1], batch_id=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Batch 8 (records 350 ‚Äì 399):\n",
    "process_batch(batches[1], batch_id=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Batch 9 (records 400 ‚Äì 426):\n",
    "process_batch(batches[1], batch_id=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_batch_files():\n",
    "    \"\"\"\n",
    "    Merge t·∫•t c·∫£ c√°c file extended_relationships_batch_{batch_id}.json th√†nh m·ªôt file duy nh·∫•t\n",
    "    \"\"\"\n",
    "    import os\n",
    "    import json\n",
    "    from glob import glob\n",
    "    \n",
    "    # ƒê∆∞·ªùng d·∫´n th∆∞ m·ª•c ch·ª©a c√°c file batch\n",
    "    batch_dir = \"../data/TTP-classification/qwen-ttp-classifiation/\"\n",
    "    \n",
    "    # Pattern ƒë·ªÉ t√¨m t·∫•t c·∫£ c√°c file batch\n",
    "    pattern = os.path.join(batch_dir, \"extended_relationships_batch_*.json\")\n",
    "    \n",
    "    # T√¨m t·∫•t c·∫£ c√°c file batch\n",
    "    batch_files = sorted(glob(pattern))\n",
    "    print(f\"üîç T√¨m th·∫•y {len(batch_files)} file batch\")\n",
    "    \n",
    "    # Merge data\n",
    "    merged_data = []\n",
    "    for batch_file in batch_files:\n",
    "        print(f\"üìñ ƒêang ƒë·ªçc file: {os.path.basename(batch_file)}\")\n",
    "        try:\n",
    "            with open(batch_file, 'r', encoding='utf-8') as f:\n",
    "                batch_data = json.load(f)\n",
    "                merged_data.extend(batch_data)\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå L·ªói khi ƒë·ªçc file {batch_file}: {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    print(f\"‚úÖ T·ªïng s·ªë records sau khi merge: {len(merged_data)}\")\n",
    "    \n",
    "    # T·∫°o t√™n file output v·ªõi timestamp\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    output_file = os.path.join(batch_dir, f\"merged_extended_relationships_{timestamp}.json\")\n",
    "    \n",
    "    # L∆∞u file merged\n",
    "    try:\n",
    "        with open(output_file, 'w', encoding='utf-8') as f:\n",
    "            json.dump(merged_data, f, ensure_ascii=False, indent=2)\n",
    "        print(f\"üíæ ƒê√£ l∆∞u file merged: {output_file}\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå L·ªói khi l∆∞u file merged: {str(e)}\")\n",
    "    \n",
    "    return output_file, merged_data\n",
    "\n",
    "# Ch·∫°y h√†m merge\n",
    "output_file, merged_data = merge_batch_files()\n",
    "\n",
    "# In th·ªëng k√™\n",
    "print(\"\\nüìä Th·ªëng k√™ sau khi merge:\")\n",
    "print(f\"‚Ä¢ S·ªë l∆∞·ª£ng records: {len(merged_data)}\")\n",
    "print(f\"‚Ä¢ S·ªë l∆∞·ª£ng records c√≥ TTP classification: {sum(1 for r in merged_data if r.get('ttp_classification'))}\")\n",
    "print(f\"‚Ä¢ S·ªë l∆∞·ª£ng records c√≥ extended relationships: {sum(1 for r in merged_data if r.get('extended_relationships'))}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
